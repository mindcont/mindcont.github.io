<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Solve intelligence, use it to make the world a better place."><title>CNN 基本公式分析 | 项脊轩</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-74386502-3','auto');ga('send','pageview');</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">CNN 基本公式分析</h1><a id="logo" href="/.">项脊轩</a><p class="description">项脊轩，旧南阁子也</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/books/"><i class="fa fa-book"> 书单</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">CNN 基本公式分析</h1><div class="post-meta">Sep 18, 2016<span> | </span><span class="category"><a href="/categories/深度学习/">深度学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a data-disqus-identifier="2016/09/18/cnn/" href="/2016/09/18/cnn/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#基本操作"><span class="toc-number">1.</span> <span class="toc-text">基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#一维卷积"><span class="toc-number">1.1.</span> <span class="toc-text">一维卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二维卷积"><span class="toc-number">1.2.</span> <span class="toc-text">二维卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#三维卷积"><span class="toc-number">1.3.</span> <span class="toc-text">三维卷积</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积的BP"><span class="toc-number">2.</span> <span class="toc-text">卷积的BP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pooling层BP"><span class="toc-number">3.</span> <span class="toc-text">pooling层BP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#im2col"><span class="toc-number">4.</span> <span class="toc-text">im2col</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#code"><span class="toc-number">5.</span> <span class="toc-text">code</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#来源"><span class="toc-number">6.</span> <span class="toc-text">来源</span></a></li></ol></div></div><div class="post-content"><p>之前工作里写过CNN，一眨眼，快到一年了。写CNN的过程，使我有了很大的成长，对BP的理解也深刻了许多。之前写得文档里，只是针对论文做了一个解析，现在放出一些关键的推导过程，也稍微回顾一下。关于训练模型里的一些trick，很多时候是需要尝试的，我突然发现：其实也很需要想象力！</p>
<a id="more"></a>
<p>注：很多图片是之前做的PPT截图，如果用mathjex重复打公式和排版了，比较费时间，所以直接截图了。</p>
<p><strong>卷积神经网络</strong><br>卷积神经网络(convolutional neural network)是利用模型特性来处理掉输入的波动而获得不变性特征，由LeCun提出，目前广泛的应用于图像数据。</p>
<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p>卷积操作主要是f(x)g(x)在重合区域的积分。</p>
<h3 id="一维卷积"><a href="#一维卷积" class="headerlink" title="一维卷积"></a>一维卷积</h3><p>如下图所示，是一维卷积。类似于点积，<strong>y = x*w</strong>,下图的w=[1,0,-1]。这里引入了一个概念<strong>局部接受野</strong>(local receptive fields)和<strong>权值共享</strong>(weight sharing)。为了方便表述，灰色的是隐含层i，黄色是下一层隐含层i+1。对于传统的神经网络而言，i+1层的一个神经元是接收了i层所有神经元节点的加权求和得到的，而这里，则仅接收i层神经元局部输入的加权得到，也就是局部接受野的概念。而权值共享，指的是对于i+1层的每一个神经元用的权重w是同一个。原来是7个输入5个输出的话，那么需要w是<code>7*5=35</code>个参数，如果使用局部接受野，输入变为了3，则需要w是<code>3*5=15</code>个参数。如果再使用权值共享，那么就变成了3个参数！使得整个网络的参数大为减少。<br><img src="/images/research/caffe/cnn/cnn_1d_conv.png" alt=""><br>当然，i层可以对应多个i+1层，也就是每一个共享的w得到一个i+1层，多个共享的w就得到了多个i+1层，这个数一般称之为feature map数。这样可以学习到更多的特征。<br><strong>这样能够更好的表达局部特征！而通过不断的深度，使得局部特征聚合为高级特征</strong></p>
<h3 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h3><p><img src="/images/research/caffe/cnn/cnn_Convolution_schematic.gif" alt=""><br>这里不细说，下面会细说。</p>
<h3 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h3><p><img src="/images/research/caffe/cnn/cnn_3d_conv.png" alt=""><br>目前多数都是采用3d卷积，本质跟2d卷积一样。就是维度增加了，对应的输入变为了4维，而w也是4维的，这样卷积求和得到输出。</p>
<p>除了卷积之外，cnn还有一个核心的概念，子抽样(subsampling)，一般用pooling来表示。pooling的种类有很多种，主要是用一个特征来表达一个局部特征，这样使得参数大为减少。常见的有max pooling和mean pooling，L2 pooling。max pooling就是用局部特征的最大值来表达这个区域的特征。其他依次类推。如下图所示：<br><img src="/images/research/caffe/cnn/cnn_Pooling_schematic.gif" alt=""></p>
<p>另外，对于图像里的一些其他操作，比如stride，表示卷积每次的移动步长，pad表示对图像进行阔边，防止在卷积操作中丢失边界特征。</p>
<h2 id="卷积的BP"><a href="#卷积的BP" class="headerlink" title="卷积的BP"></a>卷积的BP</h2><p>卷积的BP推导可以概括为3个卷积。具体如下：<br>这里我们以2d卷积为例子，3d卷积的话，就是在2d上增加一个循环就可以了。<br>如下图所示：<br><img src="/images/research/caffe/cnn/cnn_2d_conv.png" alt=""></p>
<p>这是一个forward过程，就是第二部分提到的卷积操作。这里仅用大O里面加个x表示卷积，<strong>注意后者是卷积核</strong>，也就是filter或者说weight。</p>
<p>那么误差反馈就比较容易，首先是得到了上层传递过来的delta，之后对输入的x求导得到dx用于反馈误差。之后对w求导，得到dw，用于更新梯度。<br>这个比较简单，因为本质都是点积，只需要对应的求导再加和就可以了。如下图所示：<br><img src="/images/research/caffe/cnn/cnn_dx.png" alt=""><br>对应的求解，发现这个操作类似于卷积。但是对于<code>x_{0,0}</code>的求解，需要对delta进行阔边以方便直接使用卷积操作。如下图所示:<br><img src="/images/research/caffe/cnn/cnn_dx_border.png" alt=""></p>
<p>接下来是对w求导，得到更新梯度。计算也是一样的，找到w参与的点积计算，拿到导数合并一下就可以了。如下图所示，我们发现同样可以用卷积操作来表示：<br><img src="/images/research/caffe/cnn/cnn_dw.png" alt=""></p>
<p>那么我们可以联系到线性回归，以方便我们记忆了：<br><img src="/images/research/caffe/cnn/cnn_bp.png" alt=""></p>
<p>以上就是关于卷积BP的推导和证明了。图片是在ppt里编辑好之后截图过来的，因为直接写一堆公式的话，感觉容易乱。<br>此外，我们看到也能看到对于<code>5*5</code>的卷积操作，其实是可以用2个<code>3*3</code>的卷积操作来代替，同时还能达到层数更多的效果。目前通过可视化来看，深度学习的特征是层级式的，特征由低级不断的汇总为高级特征。</p>
<h2 id="pooling层BP"><a href="#pooling层BP" class="headerlink" title="pooling层BP"></a>pooling层BP</h2><p>对于pooling层，如何进行BP操作呢？pooling层比卷积层简单的地方是，pooling是没有参数的，所以只需要得到dx之后用于误差传递就可以了。对于mean pooling，其实相当于卷积都是均值，比如2*2的pooling，那么w就相当于[[0.25, 0.25],[0.25, 0.25]]，我们直接套用卷积的公式就可以了。而对于L2 pooling等等类似的pooling，其实是可以拆分成平方操作，sum pooling，再开方的三个操作分别传递误差就可以，而sum pooling也可以套用卷积操作。唯一不一样的是max pooling，没有固定的卷积核，所以需要循环一下，对于输入最大的点进行求导。pooling 如下图所示：<br><img src="/images/research/caffe/cnn/cnn_pool.png" alt=""></p>
<p>从max 和 mean等操作也可以看到，pooling的不同。<br>pooling的本质是一种局部特征的表达。max pooling的是用图像某一区域像素值的最大值来表示该区域的特征，而mean pool是用图像某一区域像素值的均值来表示该区域的特征。这两个pooling操作都提高了提取特征的不变性，而特征提取的误差主要来自两个方面：</p>
<ul>
<li>邻域大小受限造成的估计值方差增大；</li>
<li>卷积层参数误差造成估计均值的偏移。</li>
</ul>
<p>一般来说，mean-pooling能减小第一种误差，更多的保留图像的背景信息，max-pooling能减小第二种误差(导数不影响其他点)，更多的保留纹理信息。在图像处理中，使用max pooling多于mean pooling。</p>
<h2 id="im2col"><a href="#im2col" class="headerlink" title="im2col"></a>im2col</h2><p>实际在计算的卷积的时候，通常可以使用一些卷积操作库。在类比线性回归的时候，也容易想到，如果把二维的卷积核w转为一维的话，操作会不会更快？因为在误差反馈的时候，不需要再重复的循环。因此，有一种方式是把二维图像转为一维向量进行计算的方式。如下图所示：<br><img src="/images/research/caffe/cnn/cnn_im2col.png" alt=""><br>简单的说，就是把操作转为向量的形式。那么计算就和线性回归一样了，如下：<br><img src="/images/research/caffe/cnn/cnn_im2col_2.png" alt=""><br>对于误差反馈，我们还需要把反馈的误差，再转回到二维图像的形式，也就是col2im，如下图所示：<br><img src="/images/research/caffe/cnn/cnn_col2im.png" alt=""><br>转换的时候，是不断的累加的。</p>
<h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><p>自己写了一个kitnet的神经网络库，最近比较忙，很多优化算法和layer还没实现。这里简单的给一下卷积的部分code。网上有很多好的代码值得参考和学习，这里就是配合上面的截图，给关键的几个函数。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvLayer</span>(<span class="title">ParamLayer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, shape, pad_w=<span class="number">0</span>, pad_h=<span class="number">0</span>, stride=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 name=<span class="string">"ConvLayer"</span>, init_method=<span class="string">"random"</span>, debug=<span class="number">0</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        shape (input_channel, filter_size, filter_size, output_channel)</span></span><br><span class="line"><span class="string">        c: channel</span></span><br><span class="line"><span class="string">        f: filter_size</span></span><br><span class="line"><span class="string">        b: batch_size</span></span><br><span class="line"><span class="string">        w: width</span></span><br><span class="line"><span class="string">        h: height</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span></span><br><span class="line">        <span class="keyword">super</span>(ConvLayer, <span class="keyword">self</span>).__init_<span class="number">_</span>(name, shape, init_method)</span><br><span class="line">        <span class="keyword">self</span>.in_channel = shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">self</span>.filter_h = shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">self</span>.filter_w = shape[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">self</span>.out_channel = shape[<span class="number">3</span>]</span><br><span class="line">        <span class="keyword">self</span>.indx = <span class="keyword">self</span>.filter_h * <span class="keyword">self</span>.filter_w * <span class="keyword">self</span>.in_channel</span><br><span class="line">        <span class="keyword">self</span>.pad_h = pad_h</span><br><span class="line">        <span class="keyword">self</span>.pad_w = pad_w</span><br><span class="line">        <span class="keyword">self</span>.stride = stride</span><br><span class="line">        <span class="keyword">self</span>.debug = debug</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(<span class="keyword">self</span>, x)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        x shape: (batch_size, channel, height, weight)</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span></span><br><span class="line">        <span class="comment"># get the output shape</span></span><br><span class="line">        <span class="keyword">self</span>.batch_size, in_channel, in_h, in_w = x.shape</span><br><span class="line">        assert in_channel == <span class="keyword">self</span>.in_channel</span><br><span class="line">        out_h = (in_h + <span class="number">2</span> * <span class="keyword">self</span>.pad_h - <span class="keyword">self</span>.filter_h) / <span class="keyword">self</span>.stride + <span class="number">1</span></span><br><span class="line">        out_w = (in_w + <span class="number">2</span> * <span class="keyword">self</span>.pad_w - <span class="keyword">self</span>.filter_w) / <span class="keyword">self</span>.stride + <span class="number">1</span></span><br><span class="line">        assert out_h % <span class="number">1</span> == <span class="number">0</span></span><br><span class="line">        assert out_w % <span class="number">1</span> == <span class="number">0</span></span><br><span class="line">        out_h, out_w = int(out_h), int(out_w)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># pad input array</span></span><br><span class="line">        x_padded = np.pad(x, ((<span class="number">0</span>,<span class="number">0</span>), (<span class="number">0</span>,<span class="number">0</span>), (<span class="keyword">self</span>.pad_h, <span class="keyword">self</span>.pad_h),</span><br><span class="line">                              (<span class="keyword">self</span>.pad_w, <span class="keyword">self</span>.pad_w)), <span class="string">'constant'</span>)</span><br><span class="line">        <span class="keyword">self</span>.h_padded, <span class="keyword">self</span>.w_padded = x_padded.shape[<span class="number">2</span>], x_padded.shape[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># im2col, (out_h*out_w*batch_size, filter_h*filter_w*in_channel)</span></span><br><span class="line">        x_cols = None</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="keyword">self</span>.filter_h, <span class="keyword">self</span>.h_padded+<span class="number">1</span>, <span class="keyword">self</span>.stride)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="keyword">self</span>.filter_w, <span class="keyword">self</span>.w_padded+<span class="number">1</span>, <span class="keyword">self</span>.stride)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> xrange(<span class="keyword">self</span>.batch_size)<span class="symbol">:</span></span><br><span class="line">                    tmp = x_padded[n, <span class="symbol">:</span>, i-<span class="keyword">self</span>.<span class="symbol">filter_h:</span>i, j-<span class="keyword">self</span>.<span class="symbol">filter_w:</span>j]</span><br><span class="line">                    field = tmp.reshape((<span class="number">1</span>, <span class="keyword">self</span>.indx))</span><br><span class="line">                    <span class="keyword">if</span> x_cols is <span class="symbol">None:</span></span><br><span class="line">                        x_cols = field</span><br><span class="line">                    <span class="symbol">else:</span></span><br><span class="line">                        x_cols = np.vstack((x_cols, field))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">self</span>.input = x_cols</span><br><span class="line">        <span class="comment"># weight2col, (indx, out_channel)</span></span><br><span class="line">        <span class="keyword">self</span>.w_cols = <span class="keyword">self</span>.W.reshape(<span class="keyword">self</span>.indx, <span class="keyword">self</span>.out_channel)</span><br><span class="line">        <span class="comment"># output_col shape, out_h*out_w*batch_size, out_channel</span></span><br><span class="line">        <span class="keyword">self</span>.output_col = np.dot(<span class="keyword">self</span>.input, <span class="keyword">self</span>.w_cols) + <span class="keyword">self</span>.b</span><br><span class="line">        <span class="comment"># output shape, (batch_size, channel, height, weight)</span></span><br><span class="line">        <span class="keyword">self</span>.output = <span class="keyword">self</span>.output_col.reshape(<span class="keyword">self</span>.batch_size, out_h,</span><br><span class="line">                                              out_w, <span class="keyword">self</span>.out_channel)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.<span class="symbol">debug:</span></span><br><span class="line">            print <span class="string">"x_cols.shape = "</span>, x_cols.shape</span><br><span class="line">            print <span class="string">"w_cols.shape = "</span>, <span class="keyword">self</span>.w_cols.shape</span><br><span class="line">            print <span class="string">"output.shape = "</span>, <span class="keyword">self</span>.output.shape</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(<span class="keyword">self</span>, delta)</span></span><span class="symbol">:</span></span><br><span class="line">        assert delta.size == <span class="keyword">self</span>.output.size</span><br><span class="line">        delta_cols = delta.reshape(<span class="keyword">self</span>.output_col.shape)</span><br><span class="line">        <span class="comment"># grad_x_cols, (out_h*out_w*batch_size, indx)</span></span><br><span class="line">        grad_x_cols = np.dot(delta_cols, <span class="keyword">self</span>.w_cols.T)</span><br><span class="line">        <span class="comment"># get the grad</span></span><br><span class="line">        grad_w = np.dot(<span class="keyword">self</span>.input.T, delta_cols)</span><br><span class="line">        grad_b = np.sum(delta_cols, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">self</span>.grad =[grad_w.reshape(<span class="keyword">self</span>.W.shape), grad_b.reshape(<span class="keyword">self</span>.b.shape)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># col2im: convert back from x_cols to x</span></span><br><span class="line">        <span class="comment"># (batch_size, channel, height, weight)</span></span><br><span class="line">        dx_padded = np.zeros((<span class="keyword">self</span>.batch_size, <span class="keyword">self</span>.in_channel,</span><br><span class="line">                              <span class="keyword">self</span>.h_padded, <span class="keyword">self</span>.w_padded))</span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        tmp_shape = (<span class="number">1</span>, <span class="keyword">self</span>.in_channel, <span class="keyword">self</span>.filter_h, <span class="keyword">self</span>.filter_w)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="keyword">self</span>.filter_h, <span class="keyword">self</span>.h_padded+<span class="number">1</span>, <span class="keyword">self</span>.stride)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="keyword">self</span>.filter_w, <span class="keyword">self</span>.w_padded+<span class="number">1</span>, <span class="keyword">self</span>.stride)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> xrange(<span class="keyword">self</span>.batch_size)<span class="symbol">:</span></span><br><span class="line">                    tmp = grad_x_cols[idx,<span class="symbol">:</span>].reshape(tmp_shape)</span><br><span class="line">                    dx_padded[<span class="symbol">n:</span>n+<span class="number">1</span>, <span class="symbol">:</span>,</span><br><span class="line">                              i - <span class="keyword">self</span>.<span class="symbol">filter_h:</span>i,</span><br><span class="line">                              j - <span class="keyword">self</span>.<span class="symbol">filter_w:</span>j] += tmp</span><br><span class="line">                    idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.pad_h == <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.delta = dx_padded</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">self</span>.delta = dx_padded[<span class="symbol">:</span>, <span class="symbol">:</span>, <span class="keyword">self</span>.<span class="symbol">pad_h:</span>-<span class="keyword">self</span>.pad_h,</span><br><span class="line">                                   <span class="keyword">self</span>.<span class="symbol">pad_w:</span>-<span class="keyword">self</span>.pad_w]</span><br><span class="line">        <span class="comment"># debug</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.<span class="symbol">debug:</span></span><br><span class="line">            print <span class="string">"grad_w.shape = "</span>, <span class="keyword">self</span>.grad[<span class="number">0</span>].shape</span><br><span class="line">            print <span class="string">"delta.shape = "</span>, <span class="keyword">self</span>.delta.shape</span><br></pre></td></tr></table></figure>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>文章：<a href="http://www.datakit.cn/blog/2016/03/23/bp_cnn.html" target="_blank" rel="noopener">CNN基本公式分析</a><br>来源：<a href="http://www.datakit.cn/" target="_blank" rel="noopener">http://www.datakit.cn/</a></p>
</div><div class="tags"></div><div class="post-nav"><a href="/2016/10/27/ubuntu-necessary-install-software/" class="pre">ubuntu 装机必备</a><a href="/2016/08/18/git-commands/" class="next">Git 常用指令</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'micro-era';
var disqus_identifier = '2016/09/18/cnn/';
var disqus_title = 'CNN 基本公式分析';
var disqus_url = 'http://blog.mindcont.com/2016/09/18/cnn/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/next/config.json',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//micro-era.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://blog.mindcont.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/物联/">物联</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔日记/">随笔日记</a><span class="category-list-count">4</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/caffe/" style="font-size: 15px;">caffe</a> <a href="/tags/coding/" style="font-size: 15px;">coding</a> <a href="/tags/openwrt/" style="font-size: 15px;">openwrt</a> <a href="/tags/opencv/" style="font-size: 15px;">opencv</a> <a href="/tags/matlab/" style="font-size: 15px;">matlab</a> <a href="/tags/kinect/" style="font-size: 15px;">kinect</a> <a href="/tags/ros/" style="font-size: 15px;">ros</a> <a href="/tags/树莓派/" style="font-size: 15px;">树莓派</a> <a href="/tags/ubuntu/" style="font-size: 15px;">ubuntu</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/03/raspberrypi-homebridge/">玩转树莓派第一弹：HomeBridge控制LED灯</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/20/my-movie-review/">我的影评</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/09/interview-diary/">求职笔记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//micro-era.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://memect.com/" title="好东西传送门" target="_blank">好东西传送门</a><ul></ul><a href="https://prism-break.org/zh-CN/all/" title="粉碎棱镜" target="_blank">粉碎棱镜</a><ul></ul><a href="https://www.daoon.com/" title="道卬" target="_blank">道卬</a><ul></ul><a href="https://www.ted.com/" title="TED | 值得传播的思想" target="_blank">TED | 值得传播的思想</a></div><div class="widget"><div class="widget-title"> <i class="fa fa-audio-description"> 推广链接</i></div><br/><a href="https://www.vultr.com/?ref=7173488" target="_black"> <img src="https://www.vultr.com/media/banner_3.png" width="192px"/></a><br/><a href="https://portal.qiniu.com/signup?code=3lc7blnku8d3m" target="_black"><img src="https://www.qiniu.com/assets/logo-b5caafe0363dace7b5c0a00be38a4829444918c4322a6168714522ee19dcb1c1.png" width="192px"/></a><div class="widget-title"> <i class="fa fa-weixin"> 微信公众号</i></div><img src="/images/resources/pay/wechat-platform.jpg" width="128px"/></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">项脊轩.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a><br><a href="https://mindcont.com"><img src="https://mindcont.com/bigdata/static/img/copyright.svg"/></a> <img src="https://mindcont.com/bigdata/static/img/build-with-love.svg"/></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>