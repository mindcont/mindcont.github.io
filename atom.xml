<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>微纪元</title>
  <subtitle>根据同名科幻小说改编</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.mindcont.com/"/>
  <updated>2016-09-04T15:43:50.556Z</updated>
  <id>http://blog.mindcont.com/</id>
  
  <author>
    <name>mindcont</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Caffe 入门指南</title>
    <link href="http://blog.mindcont.com/2016/09/04/caffe-guide-book/"/>
    <id>http://blog.mindcont.com/2016/09/04/caffe-guide-book/</id>
    <published>2016-09-04T15:43:46.000Z</published>
    <updated>2016-09-04T15:43:50.556Z</updated>
    
    <content type="html">&lt;p&gt;&lt;img src=&quot;/images/caffe.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://caffe.berkeleyvision.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe&lt;/a&gt;是一个清晰而高效的深度学习的框架，其作者是博士毕业于UC Berkeley的&lt;a href=&quot;http://daggerfs.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;贾扬清&lt;/a&gt;，目前在Google工作。&lt;br&gt;&lt;a href=&quot;http://caffe.berkeleyvision.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe&lt;/a&gt;是纯粹的C++/CUDA架构，支持命令行、Python和MATLAB接口；可以在CPU和GPU54直接无缝切换：&lt;br&gt;&lt;figure class=&quot;highlight less&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;Caffe&lt;/span&gt;::set_mode(&lt;span class=&quot;attribute&quot;&gt;Caffe&lt;/span&gt;::GPU);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Caffe的优势&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上手快：模型与相应优化都是以文本形式而非代码形式给出。&lt;/li&gt;
&lt;li&gt;Caffe给出了模型的定义、最优化设置以及预训练的权重，方便立即上手。&lt;/li&gt;
&lt;li&gt;速度快：能够运行最棒的模型与海量的数据。&lt;/li&gt;
&lt;li&gt;Caffe与cuDNN结合使用，测试AlexNet模型，在K40上处理每张图片只需要1.17ms.&lt;/li&gt;
&lt;li&gt;模块化：方便扩展到新的任务和设置上。&lt;/li&gt;
&lt;li&gt;可以使用Caffe提供的各层类型来定义自己的模型。&lt;/li&gt;
&lt;li&gt;开放性：公开的代码和参考模型用于再现。&lt;/li&gt;
&lt;li&gt;社区好：可以通过BSD-2参与开发与讨论。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;入门篇&quot;&gt;&lt;a href=&quot;#入门篇&quot; class=&quot;headerlink&quot; title=&quot;入门篇&quot;&gt;&lt;/a&gt;入门篇&lt;/h2&gt;&lt;p&gt;前期入门主要根据自己的机器（nvidia显卡）完成Caffe 的安装，运行 &lt;a href=&quot;http://caffe.berkeleyvision.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe官网&lt;/a&gt;和  &lt;a href=&quot;https://github.com/bvlc/caffe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github&lt;/a&gt; repo 上的&lt;strong&gt;例程&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h3&gt;&lt;p&gt;安装请仔细阅读下面的中文教程，&lt;strong&gt;编译中遇到的错误&lt;/strong&gt;请在 github issues用英文仔细查看错误原因。而且大部分都是&lt;strong&gt;环境依赖，路径错误&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.mindcont.com/2016/07/20/ubuntu1404-caffe-r3-cuda7-5-mkl/&quot;&gt;Ubuntu 14.04 64bit + Caffe rc3 + CUDA 7.5 + Intel MKL 配置说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://caffe.berkeleyvision.org/installation.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/bvlc/caffe/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;issues&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;例程&quot;&gt;&lt;a href=&quot;#例程&quot; class=&quot;headerlink&quot; title=&quot;例程&quot;&gt;&lt;/a&gt;例程&lt;/h3&gt;&lt;p&gt;配合官方文档 例如mnist 手写体识别，其文档在 $CAFFE_ROOT/examples/mnist/Readme.md ，运行并理解其流程。尤其以下面几个最为重要，当细细品味。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;例程名&lt;/th&gt;
&lt;th&gt;实现&lt;/th&gt;
&lt;th&gt;学习意义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;LeNet MNIST&lt;/td&gt;
&lt;td&gt;手写数字识别&lt;/td&gt;
&lt;td&gt;理解模型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CaffeNet C++ Classification example&lt;/td&gt;
&lt;td&gt;c++ 代码实现图片分类&lt;/td&gt;
&lt;td&gt;理解如何用c++ 调用caffe&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fine-tuning for style recognition&lt;/td&gt;
&lt;td&gt;根据自己数据集微调模型&lt;/td&gt;
&lt;td&gt;迁移学习，构建自己数据集，微调模型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Web demo&lt;/td&gt;
&lt;td&gt;基于web 网页的图片分类&lt;/td&gt;
&lt;td&gt;如何构建 client /server&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;入门书籍&quot;&gt;&lt;a href=&quot;#入门书籍&quot; class=&quot;headerlink&quot; title=&quot;入门书籍&quot;&gt;&lt;/a&gt;入门书籍&lt;/h3&gt;&lt;p&gt;如果链接失效，可以访问 &lt;a href=&quot;ftp://mindcont.com/Book&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ftp://mindcont.com/Book&lt;/a&gt; 获取。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://pan.baidu.com/s/1c0Ri2Py#path=%252FCaffeCN%25E7%25BF%25BB%25E8%25AF%2591&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe 官方教程中译本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://book.douban.com/subject/26825082/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;深度学习21天实战Caffe-赵永科&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;ftp://mindcont.com/Book/caffe学习笔记.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;薛开宇-caffe学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://pan.baidu.com/s/1hq8IoHe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;贾扬清-DIY Deep Learning for Vision-  a Hands-On Tutorial with Caffe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;答疑社区&quot;&gt;&lt;a href=&quot;#答疑社区&quot; class=&quot;headerlink&quot; title=&quot;答疑社区&quot;&gt;&lt;/a&gt;答疑社区&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://caffecn.cn/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe 中文社区&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;Caffe 深度学习交流2群 534492004&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gitter.im/BVLC/caffe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe 讨论组&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://valser.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Valse 视觉与学习青年研讨会&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;VALSE-D群 481109645&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://valser.org/article-86-1.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;历次VALSE Webinar活动的录像&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;进阶篇&quot;&gt;&lt;a href=&quot;#进阶篇&quot; class=&quot;headerlink&quot; title=&quot;进阶篇&quot;&gt;&lt;/a&gt;进阶篇&lt;/h2&gt;&lt;h3 id=&quot;CS231N-课程&quot;&gt;&lt;a href=&quot;#CS231N-课程&quot; class=&quot;headerlink&quot; title=&quot;CS231N 课程&quot;&gt;&lt;/a&gt;CS231N 课程&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://cs231n.stanford.edu/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CS231n: Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/intelligentunit?topic=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88Deep%20Learning%EF%BC%89&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;智能单元-深度学习-cs231n 中文笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://pan.baidu.com/s/1pKsTivp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;视频和课件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cs231n.stanford.edu/project.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;课程资源&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;数据集&quot;&gt;&lt;a href=&quot;#数据集&quot; class=&quot;headerlink&quot; title=&quot;数据集&quot;&gt;&lt;/a&gt;数据集&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.sigvc.org/bbs/forum.php?mod=viewthread&amp;amp;tid=72&amp;amp;highlight=%B4%FA%C2%EB&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CV codes代码&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://host.robots.ox.ac.uk/pascal/VOC/voc2007/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;The PASCAL VOC Challenge 2007&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://host.robots.ox.ac.uk/pascal/VOC/voc2012/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;The PASCAL VOC Challenge 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://mscoco.org/dataset/#download&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;COCO - Common Objects in Context&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2016/download-images-8r28#det&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ILSVRC2016 Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2015/download-images-3j16.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ILSVRC2015 Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2014/download-images-5jj5.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ILSVRC2014 Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2012/nonpub-downloads&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ILSVRC2012 Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2010/download-all-nonpub&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ILSVRC2010 Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;人脸&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cs.tau.ac.il/~wolf/ytfaces/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;youtube人脸&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://biometrics.idealtest.org/dbDetailForUser.do?id=8&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;三维人脸&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/freesum/article/details/7370823&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文本类&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/wangyaninglm/article/details/38707257&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;数字图像处理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/maxiemei/article/details/17281767&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;机器视觉中常用的数据测试集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/huashiyiqike/p/3778035.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;常用图像数据集：标注、检索&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/fuleying/p/3895817.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;花卉&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/xianghang123/p/3773086.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;100+诡异的数据集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;博客&quot;&gt;&lt;a href=&quot;#博客&quot; class=&quot;headerlink&quot; title=&quot;博客&quot;&gt;&lt;/a&gt;博客&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/louyihang-loves-baiyan/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;楼燚(yì)航的blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/liumaolincycle/article/category/5705161&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;liumaolincycle的博客&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/denny402&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;denny的学习专栏&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;微调网络&quot;&gt;&lt;a href=&quot;#微调网络&quot; class=&quot;headerlink&quot; title=&quot;微调网络&quot;&gt;&lt;/a&gt;微调网络&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;待续&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/louyihang-loves-baiyan/p/5038758.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;楼燚(yì)航的blog-Caffe fine-tuning 微调网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/sinat_30071459/article/details/51613304&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;小咸鱼_-基于caffe的图像分类(1)——制作train.txt和val.txt文件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;可视化&quot;&gt;&lt;a href=&quot;#可视化&quot; class=&quot;headerlink&quot; title=&quot;可视化&quot;&gt;&lt;/a&gt;可视化&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;待续&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;扩展新layer&quot;&gt;&lt;a href=&quot;#扩展新layer&quot; class=&quot;headerlink&quot; title=&quot;扩展新layer&quot;&gt;&lt;/a&gt;扩展新layer&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/sunshine_in_moon/article/details/51453951&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Sunshine_in_Moon的专栏-Caffe扩展新层&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;高级篇&quot;&gt;&lt;a href=&quot;#高级篇&quot; class=&quot;headerlink&quot; title=&quot;高级篇&quot;&gt;&lt;/a&gt;高级篇&lt;/h2&gt;&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考&quot;&gt;&lt;/a&gt;参考&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://daggerfs.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Yangqing Jia (贾扬清)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://image-net.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Image Net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者:&lt;a href=&quot;https://github.com/mindcont&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mindcont&lt;/a&gt;  2016-08-22 第一次编辑&lt;br&gt;&lt;strong&gt;转载注明出处 &lt;a href=&quot;http://blog.mindcont.com/2016/08/22/caffe-guide-book/&quot;&gt;http://blog.mindcont.com/2016/08/22/caffe-guide-book/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/caffe.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.mindcont.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Caffe" scheme="http://blog.mindcont.com/tags/Caffe/"/>
    
  </entry>
  
  <entry>
    <title>马克卢布： 时代光影</title>
    <link href="http://blog.mindcont.com/2016/09/04/Historic-Photos-by-Marc-Riboud/"/>
    <id>http://blog.mindcont.com/2016/09/04/Historic-Photos-by-Marc-Riboud/</id>
    <published>2016-09-04T15:00:46.000Z</published>
    <updated>2016-09-04T15:40:51.589Z</updated>
    
    <content type="html">&lt;p&gt;吕布出生于法国里昂，并在那里读中学，十四岁的时候（1937年）他第一次拍摄照片。1943年到1945年，他积极从事于法国抵抗运动，1945年到1948年，吕布在中央理工学习工程。1951年前，吕布在里昂的工厂内当一名工程师，此后他成为一名自由摄影师，1952年，吕布前往巴黎，与玛格南图片社的创始人亨利·卡蒂尔-布雷松、罗伯特·卡帕会面。吕布擅长通过高超的构图，把握生活中的精彩瞬间。吕布经常使用莱卡M6旁轴胶片相机与35毫米镜头拍摄。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Historic_Photos/Marc_Riboud.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;1957年他成为首个被允许进入新中国拍摄的西方摄影师，他曾先后22次访问中国，跨越“毛时代”，“邓时代”以及新时代，他用冷静而饱含善意的纪实摄影作品，记录中国社会的变迁，让无数西方人看到了最真实的中国面孔。1968年、1972年以及1976年，他对北越作了数次新闻报道，而后游历世界各地，但主要在亚洲、非洲以及美国。&lt;/p&gt;
&lt;p&gt;吕布见证了战争的残暴（在越战中他曾对越南和美国都做过拍摄）、文化的倒退（中国毛泽东时期的文化大革命）。但是吕布将镜头对准了日常生活的脚步，展现世界的各个层面，包括孩童在巴黎每天的嬉戏。&lt;/p&gt;
&lt;p&gt;成名作《埃菲尔铁塔上的油漆工》1953&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/Marc_Riboud_3.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;1957年，马克.吕布从香港坐火车到广州，拍摄的关于中国的第一张照片&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/first_china.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;96岁的齐白石，于获国际和平奖后不久，北京1957&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/qibaishi_1957.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;街头穿着大氅的“贵族”，北京1957&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/guizu_1957.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;胸口碎大石，北京1957&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/suidashi_1957.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;正在修建的长江大桥，武汉1957&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/changjiang_1957.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;纤夫，重庆1957&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/qianfu_1957.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;周恩来，1965，后来八九十年代马克于街头拍摄大爷大妈时，有时候会被驱赶，他就会拿出这张照片，解围百试不爽&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/enlai_1965.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;古玩店窗口，北京1965&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/guwandian_1965.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;那时候“运动”要开始了，只有中央美院还会有裸体模特，1965&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/yangmei_1965.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;“运动”开始了，女生不准留长发，也不准穿花花绿绿的衣服 上海芭蕾舞学校学生，桌上是语录1971&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/balei_1971.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;抓拍的邓小平跨过门槛，那时候的中国也刚跨过门槛，北京1982&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/menkan_1982.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;西藏1985&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/xizang_1985.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;平遥2001&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/pingyao_2001.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;毕加索1952&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/bijiasuo.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;赫鲁晓夫1960&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/heluxiaofu.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;罗素1962&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/luosu.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;卡斯特罗1963&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/kasiteluo.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;列侬1964&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/lienong.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;铁托1964&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/tietuo.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;存在主义和第二性 让·保罗·萨特与西蒙娜·德·波伏娃1967&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/cunzaizhuyi.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;甘地夫人1971&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/gandi.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;贝聿铭1978 美籍华人建筑师，1983年普利茲克獎得主，被譽為「現代主義建築的最後大師」&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/beijinming.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2016年8.30，大师去了另外一个世界。&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/Marc_Riboud_2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者：未央之歌Peking&lt;br&gt;链接：&lt;a href=&quot;http://www.zhihu.com/question/23523696/answer/120121636&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.zhihu.com/question/23523696/answer/120121636&lt;/a&gt;&lt;br&gt;来源：知乎&lt;br&gt;著作权归作者所有，转载请联系作者获得授权。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;吕布出生于法国里昂，并在那里读中学，十四岁的时候（1937年）他第一次拍摄照片。1943年到1945年，他积极从事于法国抵抗运动，1945年到1948年，吕布在中央理工学习工程。1951年前，吕布在里昂的工厂内当一名工程师，此后他成为一名自由摄影师，1952年，吕布前往巴黎
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>肖全：80 90我们这一代</title>
    <link href="http://blog.mindcont.com/2016/09/04/Historic-Photos-by-XiaoQuan/"/>
    <id>http://blog.mindcont.com/2016/09/04/Historic-Photos-by-XiaoQuan/</id>
    <published>2016-09-04T14:22:00.000Z</published>
    <updated>2016-09-04T14:56:58.675Z</updated>
    
    <content type="html">&lt;p&gt;&lt;img src=&quot;/images/Historic_Photos/xiaoquan.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;他叫肖全，历经十余年拍摄了《我们这一代》，几乎网罗了八九十年代的各路文化精英。这些今天占据中国文艺领域半壁江山的大腕们，在青涩生长的年纪以一种难得一见的随性姿态走进了肖全的镜头，成就了肖全在摄影圈的地位。&lt;/p&gt;
&lt;p&gt;他是“中国最好的人像摄影师”，拍谁就是谁这辈子最好的照片。——-江湖有这样的传说&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;北岛&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/beidao.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;顾城和谢烨&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/gucheng_xiehua.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;窦唯&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/douwei.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;贾平凹&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/jiapingwa.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;刘震云&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/liuzhenyun.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;余华&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/yuhua.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;陈丹青&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/chendanqing.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;史铁生&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/shitiesheng.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;三毛&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/sanmao.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;崔健&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/cuijian.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;唐朝乐队&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/tangchaoyuedui.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;姜文&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/jiangwen.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;杨丽萍&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/yangliping.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;易知难&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/yizhinan.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;杨乐乐&lt;br&gt;&lt;img src=&quot;/images/Historic_Photos/yanglele.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者：未央之歌Peking&lt;br&gt;链接：&lt;a href=&quot;http://www.zhihu.com/question/23523696/answer/120121636&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.zhihu.com/question/23523696/answer/120121636&lt;/a&gt;&lt;br&gt;来源：知乎&lt;br&gt;著作权归作者所有，转载请联系作者获得授权。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/Historic_Photos/xiaoquan.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;他叫肖全，历经十余年拍摄了《我们这一代》，几乎网罗了八九十年代的各路文化精英。这些今天占据中国文艺领域半壁江山的大腕们，在青涩生长的年纪以一种难得一
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Git 常用指令</title>
    <link href="http://blog.mindcont.com/2016/08/18/git-commands/"/>
    <id>http://blog.mindcont.com/2016/08/18/git-commands/</id>
    <published>2016-08-18T13:08:09.000Z</published>
    <updated>2016-08-22T09:43:39.632Z</updated>
    
    <content type="html">&lt;p&gt;Git 是由 Linux 之父 Linus Tovalds 为了更好地管理linux内核开发而创立的分布式版本控制／软件配置管理软件。&lt;strong&gt;简单来说，Git 是一个管理你的「代码的历史记录」的工具。&lt;/strong&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;/images/github.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;运行平台&lt;/th&gt;
&lt;th&gt;环境&lt;/th&gt;
&lt;th&gt;链接&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Microsoft Windows [版本 10.0.10240]&lt;/td&gt;
&lt;td&gt;GitHub Desktop (3.1.1.4)&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://desktop.github.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://desktop.github.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ubuntu [版本14.04]&lt;/td&gt;
&lt;td&gt;GitKraken&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.gitkraken.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.gitkraken.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;常用命令&quot;&gt;&lt;a href=&quot;#常用命令&quot; class=&quot;headerlink&quot; title=&quot;常用命令&quot;&gt;&lt;/a&gt;常用命令&lt;/h2&gt;&lt;h3 id=&quot;创建新仓库&quot;&gt;&lt;a href=&quot;#创建新仓库&quot; class=&quot;headerlink&quot; title=&quot;创建新仓库&quot;&gt;&lt;/a&gt;创建新仓库&lt;/h3&gt;&lt;p&gt;创建新文件夹，打开，然后执行&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;git&lt;/span&gt; init&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;以创建新的 git 仓库。&lt;/p&gt;
&lt;h3 id=&quot;拉取远程仓库&quot;&gt;&lt;a href=&quot;#拉取远程仓库&quot; class=&quot;headerlink&quot; title=&quot;拉取远程仓库&quot;&gt;&lt;/a&gt;拉取远程仓库&lt;/h3&gt;&lt;p&gt;执行如下命令以创建一个远程仓库的克隆版本：&lt;br&gt;&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git clone username&lt;span class=&quot;variable&quot;&gt;@host&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:/path/to/repository&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;举个实例&lt;br&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cd /home/pi&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;https&lt;/span&gt;://github.com/mindcont/caffe.git&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;工作流&quot;&gt;&lt;a href=&quot;#工作流&quot; class=&quot;headerlink&quot; title=&quot;工作流&quot;&gt;&lt;/a&gt;工作流&lt;/h3&gt;&lt;p&gt;你的本地仓库由 git 维护的三棵“树”组成。第一个是你的 &lt;strong&gt;工作目录&lt;/strong&gt;，它持有实际文件；第二个是 &lt;strong&gt;缓存区（Index）&lt;/strong&gt;，它像个缓存区域，临时保存你的改动；最后是 &lt;strong&gt;HEAD&lt;/strong&gt;，指向你最近一次提交后的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://git-scm.com/images/about/index1@2x.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加与提交&quot;&gt;&lt;a href=&quot;#添加与提交&quot; class=&quot;headerlink&quot; title=&quot;添加与提交&quot;&gt;&lt;/a&gt;添加与提交&lt;/h3&gt;&lt;p&gt;你可以计划改动（把它们添加到缓存区），使用如下命令：&lt;br&gt;&lt;figure class=&quot;highlight avrasm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; &amp;lt;filename&amp;gt; &lt;span class=&quot;meta&quot;&gt;# 添加单个改动的文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; * &lt;span class=&quot;meta&quot;&gt;#添加多个改动的文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这是 git 基本工作流程的第一步；使用如下命令以实际提交改动：&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;git&lt;/span&gt; commit -m &lt;span class=&quot;string&quot;&gt;&quot;代码提交信息&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在，你的改动已经提交到了 HEAD，但是还没到你的远端仓库。执行如下命令以将这些改动提交到远端仓库：&lt;br&gt;&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;origin&lt;/span&gt; master&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以把 master 换成你想要推送的任何分支&lt;br&gt;&lt;img src=&quot;https://git-scm.com/images/about/index2@2x.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;分支&quot;&gt;&lt;a href=&quot;#分支&quot; class=&quot;headerlink&quot; title=&quot;分支&quot;&gt;&lt;/a&gt;分支&lt;/h3&gt;&lt;p&gt;分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master 是“默认的”。在其他分支上进行开发，完成后再将它们合并到主分支上。&lt;br&gt;&lt;img src=&quot;https://camo.githubusercontent.com/1db631d931f4a57a439deb5f747bfc0c3c1098b2/68747470733a2f2f7777772e61746c61737369616e2e636f6d2f6769742f696d616765732f7475746f7269616c732f636f6c6c61626f726174696e672f636f6d706172696e672d776f726b666c6f77732f676974666c6f772d776f726b666c6f772f30352e737667&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;创建一个叫做“feature_x”的分支，并切换过去：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git checkout -&lt;span class=&quot;selector-tag&quot;&gt;b&lt;/span&gt; feature_x&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;切换回主分支：&lt;br&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git checkout &lt;span class=&quot;literal&quot;&gt;master&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;再把新建的分支删掉：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git branch &lt;span class=&quot;_&quot;&gt;-d&lt;/span&gt; feature_x&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt; 除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的。&lt;/p&gt;
&lt;h3 id=&quot;更新与合并&quot;&gt;&lt;a href=&quot;#更新与合并&quot; class=&quot;headerlink&quot; title=&quot;更新与合并&quot;&gt;&lt;/a&gt;更新与合并&lt;/h3&gt;&lt;p&gt;将你本地分支推送到远端仓库，执行：&lt;br&gt;&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;origin&lt;/span&gt; &amp;lt;branch&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;要更新你的本地仓库至最新改动，执行：&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;git&lt;/span&gt; pull&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;以在你的工作目录中 获取（fetch） 并 合并（merge） 远端的改动。&lt;br&gt;要合并其他分支到你的当前分支（例如 master），执行：&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git merge &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;branch&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;两种情况下，git 都会尝试去自动合并改动。不幸的是，自动合并并非次次都能成功，并可能导致 冲突（conflicts）。 这时候就需要你修改这些文件来人肉合并这些 冲突（conflicts） 了。改完之后，你需要执行如下命令以将它们标记为合并成功：&lt;br&gt;&lt;figure class=&quot;highlight vim&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;symbol&quot;&gt;&amp;lt;filename&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在合并改动之前，也可以使用如下命令查看：&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git diff &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;source_branch&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;target_branch&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果你上面的都没看懂，恭喜你可以略过前面的章节，仅看下面的 &lt;/strong&gt;可视化操作 &lt;strong&gt;就可以了。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;可视化操作&quot;&gt;&lt;a href=&quot;#可视化操作&quot; class=&quot;headerlink&quot; title=&quot;可视化操作&quot;&gt;&lt;/a&gt;可视化操作&lt;/h2&gt;&lt;p&gt;这一部分仅推荐两个，Windows 平台下推荐使用 GitHub 官方的 GitHub Desktop ，泛 Linux 下推荐使用 GitKraken 。读者可能存有疑问为什么选择这两个作为推荐，因为我本人正在使用呀～～～～&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;软件&lt;/th&gt;
&lt;th&gt;支持平台&lt;/th&gt;
&lt;th&gt;截图&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GitHub Desktop&lt;/td&gt;
&lt;td&gt;Windows, Mac&lt;/td&gt;
&lt;td&gt;&lt;img src=&quot;https://git-scm.com/images/guis/github-desktop@2x.png&quot; alt=&quot;&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GitKraken&lt;/td&gt;
&lt;td&gt;Windows, Mac, Linux&lt;/td&gt;
&lt;td&gt;&lt;img src=&quot;https://git-scm.com/images/guis/git-kraken@2x.png&quot; alt=&quot;&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;疑难杂症&quot;&gt;&lt;a href=&quot;#疑难杂症&quot; class=&quot;headerlink&quot; title=&quot;疑难杂症&quot;&gt;&lt;/a&gt;疑难杂症&lt;/h2&gt;&lt;h3 id=&quot;删除已同步到远程的commit&quot;&gt;&lt;a href=&quot;#删除已同步到远程的commit&quot; class=&quot;headerlink&quot; title=&quot;删除已同步到远程的commit&quot;&gt;&lt;/a&gt;删除已同步到远程的commit&lt;/h3&gt;&lt;p&gt;经常往GitHub上提交修改的代码，会导致提交次数很多；又或者提交了某些不应该提交测试数据，那麽我们应该如何删除这些提交记录呢？&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;## 1、启动 git shell, 切换到项目所在的空间&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; c://github/android/rubikrobot   &lt;span class=&quot;comment&quot;&gt;#例如项目位于C://GitHub/Android/RubikRobot 目录下&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;## 2、查看当前提交记录，输入 q退出日志&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;## 3、使用git reset 进行撤销操作&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git reset --hard HEAD~2                   &lt;span class=&quot;comment&quot;&gt;# 取消当前版本之前的两次提交  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git push origin HEAD --force              &lt;span class=&quot;comment&quot;&gt;# 强制提交到远程版本库，从而删除之前的两次提交数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;保持Fork的同步&quot;&gt;&lt;a href=&quot;#保持Fork的同步&quot; class=&quot;headerlink&quot; title=&quot;保持Fork的同步&quot;&gt;&lt;/a&gt;保持Fork的同步&lt;/h3&gt;&lt;p&gt;在原始Repo有新的commit后，Fork的Repo不会自动与原分支同步。&lt;/p&gt;
&lt;p&gt;前置条件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;已Fork&lt;/li&gt;
&lt;li&gt;已在本地clone了Fork&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤&lt;/p&gt;
&lt;p&gt;进入命令行，进入本地Repo目录&lt;br&gt;&lt;figure class=&quot;highlight vala&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;# 添加远程分支(仅第一次)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;remote add upstream https:&lt;span class=&quot;comment&quot;&gt;//github.com/akfish/MwCG.git&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;# 取回远程分支&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git fetch upstream&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;合并(以更新本地Dev分支为例)&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git checkout Dev&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;merge&lt;/span&gt; upstream/Dev&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;把同步后的分支push到GitHub的remote repo上（可选）&lt;/p&gt;
&lt;h2 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://git-scm.com/book/zh/v2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;git - 指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://git-scm.com/download/gui/linux&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GUI Clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://git-scm.com/book/zh/v1/Git-%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Git 分支 - 远程分支&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://git-scm.com/book/zh/v1/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;了解更多关于git 操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/akfish/MwCG/wiki/%E4%BB%BB%E5%8A%A1%EF%BC%9A%E4%BF%9D%E6%8C%81Fork%E7%9A%84%E5%90%8C%E6%AD%A5&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;保持Fork的同步&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Git 是由 Linux 之父 Linus Tovalds 为了更好地管理linux内核开发而创立的分布式版本控制／软件配置管理软件。&lt;strong&gt;简单来说，Git 是一个管理你的「代码的历史记录」的工具。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://blog.mindcont.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Ubuntu 14.04 运行 YOLO Demo 记录</title>
    <link href="http://blog.mindcont.com/2016/08/06/Run-YOLO-Demo/"/>
    <id>http://blog.mindcont.com/2016/08/06/Run-YOLO-Demo/</id>
    <published>2016-08-06T11:24:00.000Z</published>
    <updated>2016-08-22T08:48:45.406Z</updated>
    
    <content type="html">&lt;p&gt;YOLO 是一个用来在VOC 2012 数据集上检测物体的框架。它可以检测 20 类物体：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人&lt;/li&gt;
&lt;li&gt;鸟, 猫, 牛, 狗, 马, 羊&lt;/li&gt;
&lt;li&gt;飞机, 自行车, 船, 公共汽车, 小汽车, 摩托车, 火车&lt;/li&gt;
&lt;li&gt;瓶，椅子，餐桌，盆花，沙发，电视/显示器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;YOLO is joint work with &lt;a href=&quot;http://homes.cs.washington.edu/~santosh/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Santosh&lt;/a&gt;, &lt;a href=&quot;http://www.cs.berkeley.edu/~rbg/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ross&lt;/a&gt;, and &lt;a href=&quot;http://homes.cs.washington.edu/~ali/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ali&lt;/a&gt;, and is described in detail in our &lt;a href=&quot;http://arxiv.org/abs/1506.02640&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;paper&lt;/a&gt;.&lt;/p&gt;
&lt;video src=&quot;https://dn-mindcont.qbox.me/YOLO_Watches_Nature_Part_2.mp4&quot; controls=&quot;controls&quot; width=&quot;640px&quot; heigt=&quot;480px&quot; preload=&quot;none&quot; poster=&quot;/images/Object-Detection/Yolo/YOLO_Watches_Nature_Part_2.png&quot;&gt;&lt;/video&gt;

&lt;h2 id=&quot;安装-Darknet&quot;&gt;&lt;a href=&quot;#安装-Darknet&quot; class=&quot;headerlink&quot; title=&quot;安装 Darknet&quot;&gt;&lt;/a&gt;安装 Darknet&lt;/h2&gt;&lt;h3 id=&quot;下载Darknet&quot;&gt;&lt;a href=&quot;#下载Darknet&quot; class=&quot;headerlink&quot; title=&quot;下载Darknet&quot;&gt;&lt;/a&gt;下载Darknet&lt;/h3&gt;&lt;p&gt;同时按住 Alt + Ctrl + T ,打开命令行终端&lt;br&gt;&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;keyword&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;--recursive&lt;/span&gt; https://github.com/pjreddie/darknet.git&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd darknet&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;修改编译配置文件-Makefile&quot;&gt;&lt;a href=&quot;#修改编译配置文件-Makefile&quot; class=&quot;headerlink&quot; title=&quot;修改编译配置文件 Makefile&quot;&gt;&lt;/a&gt;修改编译配置文件 Makefile&lt;/h3&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;gedit&lt;/span&gt; Makefile&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;根据你的情况进行修改，例如这里我将使用 GPU 和 cuDNN 进行加速计算，故将他们置为 1&lt;br&gt;&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;GPU&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;CUDNN&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;OPENCV&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;DEBUG&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 根据你显卡的计算力确定架构。例如我的显卡是NVIDIA K2200, deviceQuery 是5.0  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;ARCH&lt;/span&gt;= --gpu-architecture=compute_50 --gpu-code=compute_50&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;编译&lt;br&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; -j4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h3&gt;&lt;p&gt;输入下面的指令进行测试Darknet 是否安装成功&lt;br&gt;&lt;figure class=&quot;highlight haskell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet  imtest &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt;/eagle.jpg&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果看到下面的画面，恭喜你安装Darknet 成功！&lt;br&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/darknet_test.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;预测&quot;&gt;&lt;a href=&quot;#预测&quot; class=&quot;headerlink&quot; title=&quot;预测&quot;&gt;&lt;/a&gt;预测&lt;/h2&gt;&lt;h3 id=&quot;下载权值文件&quot;&gt;&lt;a href=&quot;#下载权值文件&quot; class=&quot;headerlink&quot; title=&quot;下载权值文件&quot;&gt;&lt;/a&gt;下载权值文件&lt;/h3&gt;&lt;p&gt;点击下面的网址，分别下载 大中小 三个模型对应已训练好的网络权值文件&lt;br&gt;&lt;a href=&quot;http://pjreddie.com/media/files/yolo.weights&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pjreddie.com/media/files/yolo.weights&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://pjreddie.com/media/files/yolo-small.weights&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pjreddie.com/media/files/yolo-small.weights&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://pjreddie.com/media/files/yolo-tiny.weights&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pjreddie.com/media/files/yolo-tiny.weights&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;然后放到darknet/weights目录下，然后在darknet根目录下输入下面的指令&lt;/p&gt;
&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo test cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo&lt;span class=&quot;selector-class&quot;&gt;.weights&lt;/span&gt; data/dog.jpg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;日志输出&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;448&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;448&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;64&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;224&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;224&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;64&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;: Maxpool Layer: &lt;span class=&quot;number&quot;&gt;224&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;224&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;64&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; size, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; stride&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;64&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;192&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;192&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;: Maxpool Layer: &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;112&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;192&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; size, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; stride&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;192&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;128&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;128&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;128&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;6&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;: Maxpool Layer: &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; size, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; stride&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;9&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;11&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;12&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;13&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;14&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;15&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;17&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;18&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;: Maxpool Layer: &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; size, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; stride&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;21&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;22&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;23&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;25&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;26&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;27&lt;/span&gt;: Convolutional Layer: &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; filters -&amp;gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;28&lt;/span&gt;: Connected Layer: &lt;span class=&quot;number&quot;&gt;50176&lt;/span&gt; inputs, &lt;span class=&quot;number&quot;&gt;4096&lt;/span&gt; outputs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;29&lt;/span&gt;: Connected Layer: &lt;span class=&quot;number&quot;&gt;4096&lt;/span&gt; inputs, &lt;span class=&quot;number&quot;&gt;1470&lt;/span&gt; outputs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;30&lt;/span&gt;: Detection Layer&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;forced: Using default &#39;&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&#39;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Loading weights from weights/yolo.weights.&lt;span class=&quot;built_in&quot;&gt;..Done&lt;/span&gt;!&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;data/dog.jpg: Predicted in &lt;span class=&quot;number&quot;&gt;0.170866&lt;/span&gt; seconds.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;car: &lt;span class=&quot;number&quot;&gt;51&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bicycle: &lt;span class=&quot;number&quot;&gt;24&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dog: &lt;span class=&quot;number&quot;&gt;25&lt;/span&gt;%&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;init done&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;opengl support available&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/YOLO_predictions_out.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;多测试两张&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo test cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo&lt;span class=&quot;selector-class&quot;&gt;.weights&lt;/span&gt; data/person.jpg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/YOLO_person_prediction_out.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo test cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo&lt;span class=&quot;selector-class&quot;&gt;.weights&lt;/span&gt; data/horses.jpg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/YOLO_horses_prediction_out.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;实时检测&quot;&gt;&lt;a href=&quot;#实时检测&quot; class=&quot;headerlink&quot; title=&quot;实时检测&quot;&gt;&lt;/a&gt;实时检测&lt;/h3&gt;&lt;p&gt;运行这个Demo你需要编译 Darknet with CUDA and OpenCV. 你还需要选择 大中小 适当的模型和其对应的权值文件。通过 ls /dev/vi* 查看usb摄像头设备，如果输出video0则证明可用。&lt;/p&gt;
&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo demo cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo.weights&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;或者将一个小的待检测的视频文件，如test.mp4 放到darknet 根目录下&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo demo cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo&lt;span class=&quot;selector-class&quot;&gt;.weights&lt;/span&gt; test.mp4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;来实现对视频文件进行实时检测。&lt;/p&gt;
&lt;h3 id=&quot;修改显示阈值&quot;&gt;&lt;a href=&quot;#修改显示阈值&quot; class=&quot;headerlink&quot; title=&quot;修改显示阈值&quot;&gt;&lt;/a&gt;修改显示阈值&lt;/h3&gt;&lt;p&gt;YOLO 默认只显示 置信率大于0.2 的预测，可以通过参数 -thresh 0 来制定显示置信率的范围&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo test cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo&lt;span class=&quot;selector-class&quot;&gt;.weights&lt;/span&gt; data/dog&lt;span class=&quot;selector-class&quot;&gt;.jpg&lt;/span&gt; -thresh &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pjreddie.com/media/image/Screen_Shot_2015-08-14_at_11.42.02_AM.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;预测VOC2012test数据集&quot;&gt;&lt;a href=&quot;#预测VOC2012test数据集&quot; class=&quot;headerlink&quot; title=&quot;预测VOC2012test数据集&quot;&gt;&lt;/a&gt;预测VOC2012test数据集&lt;/h3&gt;&lt;p&gt;点击下面的链接，下载VOC2012test数据集&lt;br&gt;&lt;a href=&quot;http://host.robots.ox.ac.uk:8080/eval/downloads/VOC2012test.tar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://host.robots.ox.ac.uk:8080/eval/downloads/VOC2012test.tar&lt;/a&gt;&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar xf VOC2012test&lt;span class=&quot;selector-class&quot;&gt;.tar&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cp VOCdevkit/VOC2012/ImageSets/Main/test&lt;span class=&quot;selector-class&quot;&gt;.txt&lt;/span&gt; .&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;生成图片文件的全路径&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sed &lt;span class=&quot;string&quot;&gt;&#39;s?^?&#39;&lt;/span&gt;`pwd`&lt;span class=&quot;string&quot;&gt;&#39;/VOCdevkit/VOC2012/JPEGImages/?; s?$?.jpg?&#39;&lt;/span&gt; test&lt;span class=&quot;selector-class&quot;&gt;.txt&lt;/span&gt; &amp;gt; voc.&lt;span class=&quot;number&quot;&gt;2012&lt;/span&gt;.test&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;将测试文件路径复制到 darknet /data 目录下&lt;br&gt;&lt;figure class=&quot;highlight dts&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mv voc&lt;span class=&quot;number&quot;&gt;.2012&lt;/span&gt;.test &lt;span class=&quot;params&quot;&gt;&amp;lt;path-to&amp;gt;&lt;/span&gt;&lt;span class=&quot;meta-keyword&quot;&gt;/darknet/&lt;/span&gt;data&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;运行预测&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./darknet yolo valid cfg/yolo&lt;span class=&quot;selector-class&quot;&gt;.cfg&lt;/span&gt; weights/yolo.weights&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/Yolo_vaild.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/Object-Detection/Yolo/Yolo_valid_finish.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;而结果在 /darknet/results/下，打开例如 comp4_det_test_bird.txt ，可以依次看到 图片名称，置信率，方框左上角和右下角的坐标&lt;br&gt;&lt;figure class=&quot;highlight css&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;2008_000004 0&lt;span class=&quot;selector-class&quot;&gt;.008654&lt;/span&gt; 0&lt;span class=&quot;selector-class&quot;&gt;.000000&lt;/span&gt; 24&lt;span class=&quot;selector-class&quot;&gt;.913101&lt;/span&gt; 363&lt;span class=&quot;selector-class&quot;&gt;.373016&lt;/span&gt; 500&lt;span class=&quot;selector-class&quot;&gt;.000000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.009914&lt;/span&gt; 312&lt;span class=&quot;selector-class&quot;&gt;.701294&lt;/span&gt; 66&lt;span class=&quot;selector-class&quot;&gt;.039398&lt;/span&gt; 386&lt;span class=&quot;selector-class&quot;&gt;.487000&lt;/span&gt; 196&lt;span class=&quot;selector-class&quot;&gt;.171997&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.001622&lt;/span&gt; 332&lt;span class=&quot;selector-class&quot;&gt;.917145&lt;/span&gt; 88&lt;span class=&quot;selector-class&quot;&gt;.719940&lt;/span&gt; 395&lt;span class=&quot;selector-class&quot;&gt;.596405&lt;/span&gt; 176&lt;span class=&quot;selector-class&quot;&gt;.586151&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.004571&lt;/span&gt; 333&lt;span class=&quot;selector-class&quot;&gt;.134979&lt;/span&gt; 60&lt;span class=&quot;selector-class&quot;&gt;.575203&lt;/span&gt; 423&lt;span class=&quot;selector-class&quot;&gt;.763519&lt;/span&gt; 201&lt;span class=&quot;selector-class&quot;&gt;.134369&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.010197&lt;/span&gt; 410&lt;span class=&quot;selector-class&quot;&gt;.791443&lt;/span&gt; 71&lt;span class=&quot;selector-class&quot;&gt;.641754&lt;/span&gt; 485&lt;span class=&quot;selector-class&quot;&gt;.329590&lt;/span&gt; 204&lt;span class=&quot;selector-class&quot;&gt;.735779&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.002316&lt;/span&gt; 419&lt;span class=&quot;selector-class&quot;&gt;.207123&lt;/span&gt; 126&lt;span class=&quot;selector-class&quot;&gt;.652931&lt;/span&gt; 475&lt;span class=&quot;selector-class&quot;&gt;.495758&lt;/span&gt; 229&lt;span class=&quot;selector-class&quot;&gt;.286133&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.001054&lt;/span&gt; 268&lt;span class=&quot;selector-class&quot;&gt;.657776&lt;/span&gt; 188&lt;span class=&quot;selector-class&quot;&gt;.379456&lt;/span&gt; 387&lt;span class=&quot;selector-class&quot;&gt;.683960&lt;/span&gt; 288&lt;span class=&quot;selector-class&quot;&gt;.772614&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000005 0&lt;span class=&quot;selector-class&quot;&gt;.001442&lt;/span&gt; 253&lt;span class=&quot;selector-class&quot;&gt;.524567&lt;/span&gt; 235&lt;span class=&quot;selector-class&quot;&gt;.698074&lt;/span&gt; 394&lt;span class=&quot;selector-class&quot;&gt;.108795&lt;/span&gt; 343&lt;span class=&quot;selector-class&quot;&gt;.994049&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000010 0&lt;span class=&quot;selector-class&quot;&gt;.002900&lt;/span&gt; 34&lt;span class=&quot;selector-class&quot;&gt;.902084&lt;/span&gt; 5&lt;span class=&quot;selector-class&quot;&gt;.141296&lt;/span&gt; 378&lt;span class=&quot;selector-class&quot;&gt;.781433&lt;/span&gt; 371&lt;span class=&quot;selector-class&quot;&gt;.530365&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000011 0&lt;span class=&quot;selector-class&quot;&gt;.001770&lt;/span&gt; 88&lt;span class=&quot;selector-class&quot;&gt;.507141&lt;/span&gt; 60&lt;span class=&quot;selector-class&quot;&gt;.645809&lt;/span&gt; 251&lt;span class=&quot;selector-class&quot;&gt;.819916&lt;/span&gt; 128&lt;span class=&quot;selector-class&quot;&gt;.710754&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000011 0&lt;span class=&quot;selector-class&quot;&gt;.002937&lt;/span&gt; 208&lt;span class=&quot;selector-class&quot;&gt;.442169&lt;/span&gt; 72&lt;span class=&quot;selector-class&quot;&gt;.542442&lt;/span&gt; 356&lt;span class=&quot;selector-class&quot;&gt;.038971&lt;/span&gt; 139&lt;span class=&quot;selector-class&quot;&gt;.302185&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000011 0&lt;span class=&quot;selector-class&quot;&gt;.003189&lt;/span&gt; 15&lt;span class=&quot;selector-class&quot;&gt;.292969&lt;/span&gt; 49&lt;span class=&quot;selector-class&quot;&gt;.904770&lt;/span&gt; 209&lt;span class=&quot;selector-class&quot;&gt;.187149&lt;/span&gt; 158&lt;span class=&quot;selector-class&quot;&gt;.970016&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000011 0&lt;span class=&quot;selector-class&quot;&gt;.001175&lt;/span&gt; 350&lt;span class=&quot;selector-class&quot;&gt;.284515&lt;/span&gt; 88&lt;span class=&quot;selector-class&quot;&gt;.715370&lt;/span&gt; 441&lt;span class=&quot;selector-class&quot;&gt;.157318&lt;/span&gt; 154&lt;span class=&quot;selector-class&quot;&gt;.096954&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2008_000011 0&lt;span class=&quot;selector-class&quot;&gt;.005729&lt;/span&gt; 352&lt;span class=&quot;selector-class&quot;&gt;.224884&lt;/span&gt; 69&lt;span class=&quot;selector-class&quot;&gt;.389618&lt;/span&gt; 479&lt;span class=&quot;selector-class&quot;&gt;.886383&lt;/span&gt; 195&lt;span class=&quot;selector-class&quot;&gt;.413666&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://pjreddie.com/darknet/yolo/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;YOLO: Real-Time Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;YOLO 是一个用来在VOC 2012 数据集上检测物体的框架。它可以检测 20 类物体：&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.mindcont.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 操作系统之父</title>
    <link href="http://blog.mindcont.com/2016/07/31/TED-talks-Linus-Torvalds/"/>
    <id>http://blog.mindcont.com/2016/07/31/TED-talks-Linus-Torvalds/</id>
    <published>2016-07-31T13:40:27.000Z</published>
    <updated>2016-08-30T03:16:53.649Z</updated>
    
    <content type="html">&lt;p&gt;讲师：Linus Torvalds&lt;br&gt;授课语言：英文&lt;br&gt;类型：心理 艺术 计算机 历史 管理 TED 演讲 媒体 技能 其他 TED全网首播 网易公开课&lt;br&gt;课程简介：Linus Torvalds 先生带来了两次技术革新——第一次是开发出Linux内核，驱动了因特网，第二次是开发出Git，一种源代码管理系统，被全世界开发者广泛使用。在这次难得的TED演讲中，让我们一同来了解这位传奇性人物。&lt;/p&gt;
&lt;h2 id=&quot;视频&quot;&gt;&lt;a href=&quot;#视频&quot; class=&quot;headerlink&quot; title=&quot;视频&quot;&gt;&lt;/a&gt;视频&lt;/h2&gt;&lt;object width=&quot;640&quot; height=&quot;480&quot;&gt;&lt;param name=&quot;movie&quot; value=&quot;http://swf.ws.126.net/openplayer/v02/-0-2_MBPNHJU6K_MBR358639-vimg1_ws_126_net//image/snapshot_movie/2016/7/3/A/MBR35863A-1423031805654.swf?isTEDPlay=1&quot;&gt;&lt;param name=&quot;allowScriptAccess&quot; value=&quot;always&quot;&gt;&lt;param name=&quot;wmode&quot; value=&quot;transparent&quot;&gt;&lt;embed src=&quot;http://swf.ws.126.net/openplayer/v02/-0-2_MBPNHJU6K_MBR358639-vimg1_ws_126_net//image/snapshot_movie/2016/7/3/A/MBR35863A-1423031805654.swf?isTEDPlay=1&quot; type=&quot;application/x-shockwave-flash&quot; width=&quot;640&quot; height=&quot;480&quot; allowfullscreen=&quot;true&quot; wmode=&quot;transparent&quot; allowscriptaccess=&quot;always&quot;&gt;&lt;/object&gt;

&lt;h2 id=&quot;感谢&quot;&gt;&lt;a href=&quot;#感谢&quot; class=&quot;headerlink&quot; title=&quot;感谢&quot;&gt;&lt;/a&gt;感谢&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;www.ted.com&quot;&gt;TED&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;open.163.com&quot;&gt;网易公开课&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;讲师：Linus Torvalds&lt;br&gt;授课语言：英文&lt;br&gt;类型：心理 艺术 计算机 历史 管理 TED 演讲 媒体 技能 其他 TED全网首播 网易公开课&lt;br&gt;课程简介：Linus Torvalds 先生带来了两次技术革新——第一次是开发出Linux内核，驱动了因特
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Docker 实践二三事</title>
    <link href="http://blog.mindcont.com/2016/07/29/docker-learning/"/>
    <id>http://blog.mindcont.com/2016/07/29/docker-learning/</id>
    <published>2016-07-29T11:28:13.000Z</published>
    <updated>2016-07-30T01:22:14.520Z</updated>
    
    <content type="html">&lt;p&gt;Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.daocloud.io/wp-content/uploads/2015/05/vm-vs-docker-architecture1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;架构&quot;&gt;&lt;a href=&quot;#架构&quot; class=&quot;headerlink&quot; title=&quot;架构&quot;&gt;&lt;/a&gt;架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://docs.docker.com/engine/article-img/architecture.svg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;以 Ubuntu 14.04 LTS 下为例&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 更新APT镜像源&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 安装 apt-transport-https 包支持 https 协议的源。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install apt-transport-https ca-certificates&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install docker.io&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查看是否安装成功 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo docker info&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;常用命令&quot;&gt;&lt;a href=&quot;#常用命令&quot; class=&quot;headerlink&quot; title=&quot;常用命令&quot;&gt;&lt;/a&gt;常用命令&lt;/h2&gt;&lt;p&gt;Docker 命令 总的来说分为以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause]&lt;/li&gt;
&lt;li&gt;容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port]&lt;/li&gt;
&lt;li&gt;容器rootfs命令 — docker [commit|cp|diff]&lt;/li&gt;
&lt;li&gt;镜像仓库 — docker [login|pull|push|search]&lt;/li&gt;
&lt;li&gt;本地镜像管理 — docker [images|rmi|tag|build|history|save|import]&lt;/li&gt;
&lt;li&gt;其他命令 — docker [info|version]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/docker/docker.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt; 有点需要切换为root用户后进行常用docker操作，以下命令如未特殊说明，均表示在root账户下进行。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;列出机器上的镜像（images）&lt;/p&gt;
&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker images &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;REPOSITORY               &lt;span class=&quot;keyword&quot;&gt;TAG&lt;/span&gt;             &lt;span class=&quot;title&quot;&gt;IMAGE&lt;/span&gt; ID        CREATED         VIRTUAL SIZE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ubuntu                   &lt;span class=&quot;number&quot;&gt;14.10&lt;/span&gt;           &lt;span class=&quot;number&quot;&gt;2185&lt;/span&gt;fd50e2ca    &lt;span class=&quot;number&quot;&gt;13&lt;/span&gt; days ago     &lt;span class=&quot;number&quot;&gt;236.9&lt;/span&gt; MB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;…&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;其中我们可以根据REPOSITORY来判断这个镜像是来自哪个服务器，如果没有 / 则表示官方镜像，类似于username/repos_name表示Github的个人公共库，类似于regsistory.example.com:&lt;span class=&quot;number&quot;&gt;5000&lt;/span&gt;/repos_name则表示的是私服。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IMAGE ID列其实是缩写，要显示完整则带上--no-trunc选项&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在docker index中搜索image（search）&lt;/p&gt;
&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker search seanlo&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;NAME&lt;/span&gt;                DESCRIPTION           STARS     OFFICIAL   AUTOMATED&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;seanloook/centos6   sean&lt;span class=&quot;string&quot;&gt;&#39;s docker repos         0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;搜索的范围是官方镜像和所有个人公共镜像。NAME列的 / 后面是仓库的名字。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从docker registry server 中下拉image或repository（pull）&lt;/p&gt;
&lt;figure class=&quot;highlight applescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker pull centos&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;上面的命令需要注意，在docker v1&lt;span class=&quot;number&quot;&gt;.2&lt;/span&gt;版本以前，会下载官方镜像的centos仓库里的所有镜像，而从v&lt;span class=&quot;number&quot;&gt;.13&lt;/span&gt;开始官方文档里的说明变了：will pull &lt;span class=&quot;keyword&quot;&gt;the&lt;/span&gt; centos:latest image, &lt;span class=&quot;keyword&quot;&gt;its&lt;/span&gt; intermediate layers &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; any aliases &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;the&lt;/span&gt; same &lt;span class=&quot;built_in&quot;&gt;id&lt;/span&gt;，也就是只会下载tag为latest的镜像（以及同一images &lt;span class=&quot;built_in&quot;&gt;id&lt;/span&gt;的其他tag）。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;也可以明确指定具体的镜像：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker pull centos:centos6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;当然也可以从某个人的公共仓库（包括自己是私人仓库）拉取，形如docker pull username/repository&amp;lt;:tag_name&amp;gt; ：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker pull seanlook/centos:centos6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;如果你没有网络，或者从其他私服获取镜像，形如docker pull registry.domain.com:&lt;span class=&quot;number&quot;&gt;5000&lt;/span&gt;/repos:&amp;lt;tag_name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker pull dl.dockerpool.com:5000/mongo:latest&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;推送一个image或repository到registry（push）&lt;br&gt;与上面的pull对应，可以推送到Docker Hub的Public、Private以及私服，但不能推送到Top Level Repository。&lt;/p&gt;
&lt;figure class=&quot;highlight applescript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker push seanlook/mongo&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; login &lt;span class=&quot;built_in&quot;&gt;name&lt;/span&gt;: &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; password:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;login success&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从image启动一个container&lt;br&gt;当利用 docker run 来创建容器时，Docker 在后台运行的&lt;strong&gt;标准操作包括&lt;/strong&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;检查本地是否存在指定的镜像，不存在就从公有仓库下载  &lt;/li&gt;
&lt;li&gt;利用镜像创建并启动一个容器  &lt;/li&gt;
&lt;li&gt;分配一个文件系统，并在只读的镜像层外面挂载一层可读写层  &lt;/li&gt;
&lt;li&gt;从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去  &lt;/li&gt;
&lt;li&gt;从地址池配置一个 ip 地址给容器  &lt;/li&gt;
&lt;li&gt;执行用户指定的应用程序  &lt;/li&gt;
&lt;li&gt;&lt;p&gt;执行完毕后容器被终止&lt;br&gt;使用image创建container并进入交互模式(&lt;strong&gt;退出即终止&lt;/strong&gt;), 使用 &lt;strong&gt;-i -t &lt;/strong&gt;,login shell是/bin/bash&lt;/p&gt;
&lt;figure class=&quot;highlight elixir&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 创建一个根镜像为ubuntu:14.04 名字为ubuntu的交互式 容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker run -i -t --name ubuntu ubuntu:14.04 /bin/bash&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 进入容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root&lt;span class=&quot;variable&quot;&gt;@85cea785dc&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:~/&lt;/span&gt; ls&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 退出容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root&lt;span class=&quot;variable&quot;&gt;@85cea785dc&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:~/&lt;/span&gt; exit &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 启动&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root&lt;span class=&quot;variable&quot;&gt;@DeepMind&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:~/docker&lt;/span&gt; start ubuntu&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#查看当前正在运行的容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker ps &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#查看所有容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker ps -a &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 依附到正在运行的容器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root&lt;span class=&quot;variable&quot;&gt;@DeepMind&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:~/docker&lt;/span&gt; attach ubuntu&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;root&lt;span class=&quot;variable&quot;&gt;@85cea785dc&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:~/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行出一个container放到后台运行, 使用 &lt;strong&gt;-d &lt;/strong&gt;参数&lt;/p&gt;
&lt;figure class=&quot;highlight stata&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# docker &lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt; -&lt;span class=&quot;keyword&quot;&gt;d&lt;/span&gt; ubuntu /bin/&lt;span class=&quot;keyword&quot;&gt;sh&lt;/span&gt; -c &lt;span class=&quot;string&quot;&gt;&quot;while true; do echo hello world; sleep 2; done&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ae60c4b642058fefcc61ada85a610914bed9f5df0e2aa147100eab85cea785dc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;-P(大写)&lt;/strong&gt;表示随机端口，&lt;strong&gt;-p&lt;/strong&gt; 表示指定端口，如下宿主主机端口5000连接到容器34448端口&lt;br&gt;&lt;img src=&quot;/images/docker/docker_digits.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;使用Dockerfile文件 build 生成新的image（镜像）&lt;br&gt;这里给出github上的一份Dockerfile模板 &lt;a href=&quot;https://github.com/webdevops/Dockerfile/blob/develop/docker/nginx/ubuntu-14.04/Dockerfile&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ubuntu:14.04-niginx&lt;/a&gt;,类似于脚本语言，只不过用来编译镜像而已&lt;/p&gt;
&lt;figure class=&quot;highlight dockerfile&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#+++++++++++++++++++++++++++++++++++++++&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Dockerfile for webdevops/nginx:ubuntu-14.04&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#    -- automatically generated  --&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#+++++++++++++++++++++++++++++++++++++++&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 根镜像&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; webdevops/base:ubuntu-&lt;span class=&quot;number&quot;&gt;14.04&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 创建者信息&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;MAINTAINER&lt;/span&gt; info@webdevops.io&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;LABEL&lt;/span&gt; &lt;span class=&quot;bash&quot;&gt;vendor=WebDevOps.io&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;LABEL&lt;/span&gt; &lt;span class=&quot;bash&quot;&gt;io.webdevops.layout=8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;LABEL&lt;/span&gt; &lt;span class=&quot;bash&quot;&gt;io.webdevops.version=0.55.0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ENV&lt;/span&gt; WEB_DOCUMENT_ROOT  /app&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ENV&lt;/span&gt; WEB_DOCUMENT_INDEX index.php&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ENV&lt;/span&gt; WEB_ALIAS_DOMAIN   *.vm&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 安装 nginx&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;bash&quot;&gt;/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/bin/apt-install \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        nginx \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;amp;&amp;amp; /opt/docker/bin/provision run --tag bootstrap --role webdevops-nginx \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;amp;&amp;amp; /opt/docker/bin/bootstrap.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 对外开放 80 443 端口&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;EXPOSE&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;443&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用docker build -t niginx . 对当前目录下的Dockerfile文件进行编译&lt;/p&gt;
&lt;figure class=&quot;highlight haml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# docker build -t niginx .&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Sending build context to Docker daemon 73.45 MB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Sending build context to Docker daemon &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Step 0 : FROM seanlook/nginx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -&lt;span class=&quot;ruby&quot;&gt;--&amp;gt; aa8516fa0bb7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;Step 1 : EXPOSE 80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -&lt;span class=&quot;ruby&quot;&gt;--&amp;gt; Using cache&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt; -&lt;span class=&quot;ruby&quot;&gt;--&amp;gt; fece07e2b515&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;Step 2 : ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf &amp;amp;&amp;amp; /bin/bash&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -&lt;span class=&quot;ruby&quot;&gt;--&amp;gt; Running &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; e08963fd5afb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt; -&lt;span class=&quot;ruby&quot;&gt;--&amp;gt; d9bbd13f5066&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;Removing intermediate container e08963fd5afb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Successfully built d9bbd13f5066&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;删除一个或多个container、image（rm、rmi）&lt;/p&gt;
&lt;figure class=&quot;highlight livecodeserver&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker images            &amp;lt;==&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ubuntu            &lt;span class=&quot;number&quot;&gt;13.10&lt;/span&gt;        &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349       &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt; months ago       &lt;span class=&quot;number&quot;&gt;184.6&lt;/span&gt; MB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ubuntu            saucy        &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349       &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt; months ago       &lt;span class=&quot;number&quot;&gt;184.6&lt;/span&gt; MB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;seanlook/ubuntu   rm_test      &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349       &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt; months ago       &lt;span class=&quot;number&quot;&gt;184.6&lt;/span&gt; MB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;使用&lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349启动、停止一个容器后，删除这个镜像&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker rmi 195eb90b5349&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Error response &lt;span class=&quot;built_in&quot;&gt;from&lt;/span&gt; daemon: Conflict, cannot &lt;span class=&quot;built_in&quot;&gt;delete&lt;/span&gt; image &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349 because &lt;span class=&quot;keyword&quot;&gt;it&lt;/span&gt; is &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tagged &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; multiple repositories, use -f &lt;span class=&quot;built_in&quot;&gt;to&lt;/span&gt; force&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2014&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;11&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;19&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00&lt;/span&gt; Error: failed &lt;span class=&quot;built_in&quot;&gt;to&lt;/span&gt; remove &lt;span class=&quot;literal&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; more images&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;删除seanlook仓库中的tag     &amp;lt;==&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker rmi seanlook/ubuntu:rm_test&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Untagged: seanlook/ubuntu:rm_test&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;现在删除镜像，还会由于container的存在不能rmi&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker rmi 195eb90b5349&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Error response &lt;span class=&quot;built_in&quot;&gt;from&lt;/span&gt; daemon: Conflict, cannot &lt;span class=&quot;built_in&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b5349 because &lt;span class=&quot;keyword&quot;&gt;the&lt;/span&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; container eef3648a6e77 is &lt;span class=&quot;keyword&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;it&lt;/span&gt;, use -f &lt;span class=&quot;built_in&quot;&gt;to&lt;/span&gt; force&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2014&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;11&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;04&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;14&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;15&lt;/span&gt; Error: failed &lt;span class=&quot;built_in&quot;&gt;to&lt;/span&gt; remove &lt;span class=&quot;literal&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; more images&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;先删除由这个镜像启动的容器    &amp;lt;==&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker rm eef3648a6e77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;删除镜像                    &amp;lt;==&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# docker rmi 195eb90b5349&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted: &lt;span class=&quot;number&quot;&gt;195&lt;/span&gt;eb90b534950d334188c3627f860fbdf898e224d8a0a11ec54ff453175e081&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted: &lt;span class=&quot;number&quot;&gt;209&lt;/span&gt;ea56fda6dc2fb013e4d1e40cb678b2af91d1b54a71529f7df0bd867adc961&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;f4aac48388f5d65a725ccf8e7caada42f136026c566528a5ee9b02467dac90a&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted: fae16849ebe23b48f2bedcc08aaabd45408c62b531ffd8d3088592043d5e7364&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted: f127542f0b6191e99bb015b672f5cf48fa79d974784ac8090b11aeac184eaaff&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.docker.com/engine/understanding-docker/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://docs.daocloud.io/faq/docker101&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://yeasy.gitbooks.io/docker_practice/content/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker —— 从入门到实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dockone.io/article/133&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker终极指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.docker.org.cn/page/resources.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Docker 中文资源&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000000751601&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;docker常用管理命令（上）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000000759971&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;docker常用管理命令（下）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。&lt;/p&gt;
&lt;p&gt;&lt;img s
    
    </summary>
    
      <category term="Linux" scheme="http://blog.mindcont.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Nvidia Digits with Caffe 配置指南</title>
    <link href="http://blog.mindcont.com/2016/07/26/Nvidia-Digits-with-Caffe/"/>
    <id>http://blog.mindcont.com/2016/07/26/Nvidia-Digits-with-Caffe/</id>
    <published>2016-07-26T13:33:58.000Z</published>
    <updated>2016-08-22T08:30:05.440Z</updated>
    
    <content type="html">&lt;p&gt;Digits: Deep Learning GPU Training System1，是由英伟达（NVIDIA）公司开发的第一个交互式深度学习GPU训练系统。目的在于整合现有的Deep Learning开发工具，实现深度神经网络（Deep Neural Network，DNN）设计、训练和可视化等任务变得简单化。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;DIGITS是基于浏览器的接口，因而通过实时的网络行为的可视化，可以快速设计最优的DNN。DIGITS是开源软件，可在&lt;a href=&quot;https://github.com/NVIDIA/DIGITS&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;上找到，因而开发人员可以扩展和自定义DIGITS。&lt;/p&gt;
&lt;p&gt;Demo: 访问 &lt;a href=&quot;http://digits.daoapp.io&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://digits.daoapp.io&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Digits-特性&quot;&gt;&lt;a href=&quot;#Digits-特性&quot; class=&quot;headerlink&quot; title=&quot;Digits 特性&quot;&gt;&lt;/a&gt;Digits 特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;提供了友好的用户界面，只需简单的点击即完成DNNs的训练。Digits是一个Web应用，用浏览器访问，上图是典型的工作流程图。&lt;/li&gt;
&lt;li&gt;Digits用户接口提供了DNN优化工具。主控制台列出了现有的数据库和机器上可用的先前训练好的网络模型以及正在进行的训练活动。&lt;/li&gt;
&lt;li&gt;Digits使可视化网络和快速对比精度变得简单。你选择一个模型，Digits显示训练状态和精度，并提供在网络训练时或训练完毕后加载和分类图像的选项。&lt;/li&gt;
&lt;li&gt;由于Digits运行在一个web服务器上，团队用户可以很方便地分享数据库和网络配置，以及测试和分享结果。&lt;/li&gt;
&lt;li&gt;Digits集成了流行的 &lt;a href=&quot;https://github.com/BVLC/caffe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe&lt;/a&gt; (deep learning framework)，并支持使用cuDNN进行GPU加速。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 在此，我们默认你以安装好了&lt;a href=&quot;https://github.com/BVLC/caffe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe&lt;/a&gt; 或 &lt;a href=&quot;https://github.com/torch/torch7&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;torch7&lt;/a&gt;，本文以Ubuntu 14.04 LTS 环境下简述Nvidia Digits 和 caffe 相关配置，如果您在Ubuntu 下还没有配置成功 Caffe ,建议你查看我的另一篇博客 &lt;a href=&quot;http://blog.mindcont.com/2016/07/20/ubuntu1404-caffe-r3-cuda7-5-mkl/&quot;&gt;Ubuntu 14.04 64bit + Caffe rc3 + CUDA 7.5 + Intel MKL 配置说明&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;打开命令行，依次输入下面的指令&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 获取 CUDA packages&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CUDA_REPO_PKG=cuda-repo-ubuntu1404_7.5-18_amd64.deb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;CUDA_REPO_PKG&amp;#125;&lt;/span&gt; -O /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;CUDA_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo dpkg -i /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;CUDA_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rm &lt;span class=&quot;_&quot;&gt;-f&lt;/span&gt; /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;CUDA_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 获取 Nvidia Machine Learning packages&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ML_REPO_PKG=nvidia-machine-learning-repo_4.0-2_amd64.deb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1404/x86_64/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;ML_REPO_PKG&amp;#125;&lt;/span&gt; -O /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;ML_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo dpkg -i /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;ML_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rm &lt;span class=&quot;_&quot;&gt;-f&lt;/span&gt; /tmp/&lt;span class=&quot;variable&quot;&gt;$&amp;#123;ML_REPO_PKG&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Download new list of packages&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装，默认位置 /usr/share/digits 下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 安装Digits&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install digits&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 安装Nvidia caffe ，安装过 BVLC/caffe 再安装这里的 Nvidia caffe 很容易！&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; CAFFE_HOME=~/NVcaffe&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;clone&lt;/span&gt; https://github.com/NVIDIA/caffe.git &lt;span class=&quot;variable&quot;&gt;$CAFFE_HOME&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 安装 python依赖&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo pip install -r &lt;span class=&quot;variable&quot;&gt;$CAFFE_HOME&lt;/span&gt;/python/requirements.txt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 编译&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$CAFFE_HOME&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cmake ..&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make --jobs=4 &lt;span class=&quot;comment&quot;&gt;#这里指使用4线程编译，通常跟 **你的处理器的核数** 一致&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 配置，按提示执行&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo python -m digits.config.edit -v&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;开启服务&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 跳转到安装目录&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; /usr/share/digits&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查看当前目录下的文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dir &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 启动&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ./digits-devserver&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;打开浏览器，依次访问 &lt;a href=&quot;http://localhost/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost/&lt;/a&gt; (if installed from Deb packages), &lt;a href=&quot;http://localhost:5000/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:5000/&lt;/a&gt; (if using digits-devserver) or &lt;a href=&quot;http://localhost:34448/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:34448/&lt;/a&gt; (if using digits-server). 如果你看到如下画面，恭喜你，digits 已运行成功！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/digits/digits_success.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;不过一般情况下，你会看到如下画面&lt;br&gt;&lt;img src=&quot;/images/digits/digits_error.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;不要气馁，导致的原因大多因为Digits 依赖的环境与你本地的环境版本不符而导致的。&lt;br&gt;下面是官方&lt;a href=&quot;https://github.com/NVIDIA/DIGITS/blob/master/requirements.txt&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;requirements.txt&lt;/a&gt;，其中有几项必须是特定版本，如 Flask==0.10.1，lmdb==0.87等&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Pillow&amp;gt;=2.3.0,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=3.1.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;numpy&lt;/span&gt;&amp;gt;&lt;/span&gt;=1.8.1,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=1.11.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;scipy&lt;/span&gt;&amp;gt;&lt;/span&gt;=0.13.3,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=0.17.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;protobuf&lt;/span&gt;&amp;gt;&lt;/span&gt;=2.5.0,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=2.6.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;six&lt;/span&gt;&amp;gt;&lt;/span&gt;=1.5.2,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=1.10.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;requests&lt;/span&gt;&amp;gt;&lt;/span&gt;=2.2.1,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=2.9.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;gevent&lt;/span&gt;&amp;gt;&lt;/span&gt;=1.0,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=1.0.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Flask&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=0.10.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Flask-WTF&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=0.11,&amp;lt;=0.12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;wtforms&lt;/span&gt;&amp;gt;&lt;/span&gt;=2.0,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=2.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Flask-SocketIO&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=0.6.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;gunicorn&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=17.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;setuptools&lt;/span&gt;&amp;gt;&lt;/span&gt;=3.3,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=20.7.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;lmdb&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=0.87&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;h5py&lt;/span&gt;&amp;gt;&lt;/span&gt;=2.2.1,&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;=2.6.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;pydot&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;=1.0.28&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;解决方法&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 查看本地环境版本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip list&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#比对其中不合适的，进行卸载&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo pip uninstall ***&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#例如安装指定版本 lmdb==0.87&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo pip install &lt;span class=&quot;string&quot;&gt;&#39;lmdb==0.87&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;使用&quot;&gt;&lt;a href=&quot;#使用&quot; class=&quot;headerlink&quot; title=&quot;使用&quot;&gt;&lt;/a&gt;使用&lt;/h2&gt;&lt;h3 id=&quot;下载数据集&quot;&gt;&lt;a href=&quot;#下载数据集&quot; class=&quot;headerlink&quot; title=&quot;下载数据集&quot;&gt;&lt;/a&gt;下载数据集&lt;/h3&gt;&lt;p&gt;打开命令行，依次输入下面的指令,将会下载mnist数据集到 /home/你的用户名/mnist 文件夹下&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;python /usr/share/digits/tools/download_data/main.py mnist ~/mnist&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;创建数据集&quot;&gt;&lt;a href=&quot;#创建数据集&quot; class=&quot;headerlink&quot; title=&quot;创建数据集&quot;&gt;&lt;/a&gt;创建数据集&lt;/h3&gt;&lt;p&gt;依次点击 New Dataset &amp;gt; Images &amp;gt; Classification，并按下图配置&lt;br&gt;&lt;img src=&quot;/images/digits/new-dataset.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;点击 create，会看到如下画面。表示正在把下载的数据集创建为 lmdb 数据库格式。&lt;br&gt;&lt;img src=&quot;/images/digits/creating-dataset.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;当 jobs 进度条完成后，可以查看数据库中的 trian 和 test 数据库格式。其中 训练数据 占数据集的75%&lt;br&gt;&lt;img src=&quot;/images/digits/explore_mnist_train_lmdb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;测试数据 占数据集的 25%&lt;br&gt;&lt;img src=&quot;/images/digits/explore_mnist_test_lmdb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;点击 左上角 DIGITS 返回主界面&lt;br&gt;&lt;img src=&quot;/images/digits/digits_main.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;训练模型&quot;&gt;&lt;a href=&quot;#训练模型&quot; class=&quot;headerlink&quot; title=&quot;训练模型&quot;&gt;&lt;/a&gt;训练模型&lt;/h3&gt;&lt;p&gt;依次点击  New Model &amp;gt; Images &amp;gt; Classification，进入模型配置界面，并按下图配置训练模型&lt;br&gt;&lt;img src=&quot;/images/digits/new-model-top-half.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/digits/new-model-bottom-half.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击创建后，训练任务自动执行。如下图所示&lt;br&gt;&lt;img src=&quot;/images/digits/digits_real_time.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;等待训练结束，下面我们好进行测试。&lt;/p&gt;
&lt;h3 id=&quot;测试训练结果&quot;&gt;&lt;a href=&quot;#测试训练结果&quot; class=&quot;headerlink&quot; title=&quot;测试训练结果&quot;&gt;&lt;/a&gt;测试训练结果&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/digits/digits_test.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;首先测试&lt;strong&gt;单张图片&lt;/strong&gt;，点击Browse 按钮，以此选择类似于下面的路径&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_one_upload.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;之后点击 Classify One ，并候选选框，会看到如下，显示模型每层的处理情况。&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_one_res.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;测试多张图片&lt;/strong&gt;，同理打开类似下面的路径&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_many_upload.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;然后点击 Classify Many。会看到后台结果如下&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_many_service.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;测试结果如下&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_many_res.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可视化分类结果&lt;br&gt;&lt;img src=&quot;/images/digits/digits_test_many_TopN.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/NVIDIA/DIGITS/blob/master/docs/GettingStarted.md&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NVIDIA-DIGITS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/enjoyyl/article/details/47397505&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;如若明镜- NVIDIA DIGITS 学习笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Digits: Deep Learning GPU Training System1，是由英伟达（NVIDIA）公司开发的第一个交互式深度学习GPU训练系统。目的在于整合现有的Deep Learning开发工具，实现深度神经网络（Deep Neural Network，DNN）设计、训练和可视化等任务变得简单化。
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.mindcont.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Caffe" scheme="http://blog.mindcont.com/tags/Caffe/"/>
    
  </entry>
  
  <entry>
    <title>基于深度学习的目标检测研究进展</title>
    <link href="http://blog.mindcont.com/2016/07/22/Research-Progress-in-Object-Detection/"/>
    <id>http://blog.mindcont.com/2016/07/22/Research-Progress-in-Object-Detection/</id>
    <published>2016-07-22T13:03:09.000Z</published>
    <updated>2016-08-22T08:08:06.145Z</updated>
    
    <content type="html">&lt;p&gt;目标检测对于人来说是再简单不过的任务，但是对于计算机来说，它看到的是一些值为0~255的数组，因而很难直接得到图像中有人或者猫这种高层语义概念，也不清楚目标出现在图像中哪个区域。图像中的目标可能出现在任何位置，目标的形态可能存在各种各样的变化，图像的背景千差万别……，这些因素导致目标检测并不是一个容易解决的任务。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;/images/Object-Detection/1.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;开始本文内容之前，我们先来看一下上边左侧的这张图，从图中你看到了什么物体？他们在什么位置？这还不简单，图中有一个猫和一个人，具体的位置就是上图右侧图像两个边框(bounding-box)所在的位置。其实刚刚的这个过程就是目标检测，目标检测就是“给定一张图像或者视频帧，找出其中所有目标的位置，并给出每个目标的具体类别”。&lt;/p&gt;
&lt;p&gt;得益于深度学习——主要是卷积神经网络(convolution neural network: CNN)和候选区域(region proposal)算法，从2014年开始，目标检测取得了巨大的突破。本文主要对基于深度学习的目标检测算法进行剖析和总结，文章分为四个部分：第一部分大体介绍下传统目标检测的流程，第二部分介绍以R-CNN为代表的结合region proposal和CNN分类的目标检测框架(R-CNN, SPP-NET, Fast R-CNN, Faster R-CNN); 第三部分介绍以YOLO为代表的将目标检测转换为回归问题的目标检测框架(YOLO, SSD); 第四部分介绍一些可以提高目标检测性能的技巧和方法。&lt;/p&gt;
&lt;h2 id=&quot;传统目标检测方法&quot;&gt;&lt;a href=&quot;#传统目标检测方法&quot; class=&quot;headerlink&quot; title=&quot;传统目标检测方法&quot;&gt;&lt;/a&gt;传统目标检测方法&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/2.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上图所示，传统目标检测的方法一般分为三个阶段：首先在给定的图像上选择一些候选的区域，然后对这些区域提取特征，最后使用训练的分类器进行分类。下面我们对这三个阶段分别进行介绍。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;区域选择&lt;/strong&gt;&lt;br&gt;这一步是为了对目标的位置进行定位。由于目标可能出现在图像的任何位置，而且目标的大小、长宽比例也不确定，所以最初采用滑动窗口的策略对整幅图像进行遍历，而且需要设置不同的尺度，不同的长宽比。&lt;strong&gt;这种穷举的策略虽然包含了目标所有可能出现的位置，但是缺点也是显而易见的：时间复杂度太高，产生冗余窗口太多，这也严重影响后续特征提取和分类的速度和性能。&lt;/strong&gt;（实际上由于受到时间复杂度的问题，滑动窗口的长宽比一般都是固定的设置几个，所以对于长宽比浮动较大的多类别目标检测，即便是滑动窗口遍历也不能得到很好的区域）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征提取&lt;/strong&gt;&lt;br&gt;由于目标的形态多样性，光照变化多样性，背景多样性等因素使得设计一个鲁棒的特征并不是那么容易。然而提取特征的好坏直接影响到分类的准确性。（这个阶段常用的特征有&lt;strong&gt;SIFT、HOG&lt;/strong&gt;等）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分类器&lt;/strong&gt;&lt;br&gt;主要有SVM, Adaboost等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;总结：传统目标检测存在的两个主要问题：一个是基于滑动窗口的区域选择策略没有针对性，时间复杂度高，窗口冗余；二是手工设计的特征对于多样性的变化并没有很好的鲁棒性。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;基于Region-Proposal的深度学习目标检测算法&quot;&gt;&lt;a href=&quot;#基于Region-Proposal的深度学习目标检测算法&quot; class=&quot;headerlink&quot; title=&quot;基于Region Proposal的深度学习目标检测算法&quot;&gt;&lt;/a&gt;基于Region Proposal的深度学习目标检测算法&lt;/h2&gt;&lt;p&gt;对于传统目标检测任务存在的两个主要问题，我们该如何解决呢？&lt;/p&gt;
&lt;p&gt;对于滑动窗口存在的问题，region proposal提供了很好的解决方案。&lt;strong&gt;region proposal（候选区域）是预先找出图中目标可能出现的位置。&lt;/strong&gt;但由于region proposal利用了图像中的纹理、边缘、颜色等信息，可以保证在选取较少窗口（几千个甚至几百个）的情况下保持较高的召回率。这大大降低了后续操作的时间复杂度，并且获取的候选窗口要比滑动窗口的质量更高（滑动窗口固定长宽比）。比较常用的region proposal算法有&lt;strong&gt;selective Search和edge Boxes&lt;/strong&gt;，如果想具体了解region proposal可以看一下PAMI2015的“What makes for effective detection proposals？”&lt;/p&gt;
&lt;p&gt;有了候选区域，&lt;strong&gt;剩下的工作实际就是对候选区域进行图像分类的工作（特征提取+分类）。&lt;/strong&gt;对于图像分类，不得不提的是2012年ImageNet大规模视觉识别挑战赛（ILSVRC）上，机器学习泰斗Geoffrey Hinton教授带领学生Krizhevsky使用卷积神经网络将ILSVRC分类任务的Top-5 error降低到了15.3%，而使用传统方法的第二名top-5 error高达 26.2%。此后，卷积神经网络占据了图像分类任务的绝对统治地位，微软最新的ResNet和谷歌的Inception V4模型的top-5 error降到了4%以内多，这已经超越人在这个特定任务上的能力。所以目标检测得到候选区域后使用CNN对其进行图像分类是一个不错的选择。&lt;/p&gt;
&lt;p&gt;2014年，RBG（Ross B. Girshick）大神使用region proposal+CNN代替传统目标检测使用的滑动窗口+手工设计特征，设计了R-CNN框架，使得目标检测取得巨大突破，并开启了基于深度学习目标检测的热潮。&lt;/p&gt;
&lt;h3 id=&quot;R-CNN-CVPR2014-TPAMI2015&quot;&gt;&lt;a href=&quot;#R-CNN-CVPR2014-TPAMI2015&quot; class=&quot;headerlink&quot; title=&quot;R-CNN (CVPR2014, TPAMI2015)&quot;&gt;&lt;/a&gt;R-CNN (CVPR2014, TPAMI2015)&lt;/h3&gt;&lt;p&gt;(Region-based Convolution Networks for Accurate Object detection and Segmentation)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/3.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的框架图清晰的给出了&lt;strong&gt;R-CNN的目标检测流程：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight maxima&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;输入测试图像&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;利用selective search算法在图像中提取&lt;span class=&quot;number&quot;&gt;2000&lt;/span&gt;个左右的&lt;span class=&quot;built_in&quot;&gt;region&lt;/span&gt; proposal。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;将每个&lt;span class=&quot;built_in&quot;&gt;region&lt;/span&gt; proposal缩放（warp）成227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;将每个&lt;span class=&quot;built_in&quot;&gt;region&lt;/span&gt; proposal提取到的CNN特征输入到SVM进行分类。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;针对上面的框架给出几点解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上面的框架图是测试的流程图，要进行测试我们首先要训练好提取特征的CNN模型，以及用于分类的SVM：使用在ImageNet上预训练的模型（AlexNet/VGG16）进行微调得到用于特征提取的CNN模型，然后利用CNN模型对训练集提特征训练SVM。&lt;/li&gt;
&lt;li&gt;对每个region proposal缩放到同一尺度是因为CNN全连接层输入需要保证维度固定。&lt;/li&gt;
&lt;li&gt;上图少画了一个过程——对于SVM分好类的region proposal做边框回归（bounding-box regression)，边框回归是对region proposal进行纠正的线性回归算法，为了让region proposal提取到的窗口跟目标真实窗口更吻合。因为region proposal提取到的窗口不可能跟人手工标记那么准，如果region proposal跟目标位置偏移较大，即便是分类正确了，但是由于IoU(region proposal与Ground Truth的窗口的交集比并集的比值)低于0.5，那么相当于目标还是没有检测到。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;：R-CNN在PASCAL VOC2007上的检测结果从DPM HSC的34.3%直接提升到了66%(mAP)。&lt;strong&gt;如此大的提升使我们看到了region proposal+CNN的巨大优势。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但是R-CNN框架也存在着&lt;strong&gt;很多问题:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1) 训练分为多个阶段，步骤繁琐: 微调网络+训练SVM+训练边框回归器&lt;br&gt;(2) 训练耗时，占用磁盘空间大：5000张图像产生几百G的特征文件&lt;br&gt;(3) 速度慢: 使用GPU, VGG16模型处理一张图像需要47s。&lt;br&gt;针对速度慢的这个问题，SPP-NET给出了很好的解决方案。&lt;/p&gt;
&lt;h3 id=&quot;SPP-NET-ECCV2014-TPAMI2015&quot;&gt;&lt;a href=&quot;#SPP-NET-ECCV2014-TPAMI2015&quot; class=&quot;headerlink&quot; title=&quot;SPP-NET (ECCV2014, TPAMI2015)&quot;&gt;&lt;/a&gt;SPP-NET (ECCV2014, TPAMI2015)&lt;/h3&gt;&lt;p&gt;(Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition)&lt;br&gt;先看一下R-CNN为什么检测速度这么慢，一张图都需要47s！仔细看下R-CNN框架发现，对图像提完region proposal（2000个左右）之后将每个proposal当成一张图像进行后续处理(CNN提特征+SVM分类)，实际上对一张图像进行了2000次提特征和分类的过程！&lt;/p&gt;
&lt;p&gt;有没有方法提速呢？好像是有的，&lt;strong&gt;这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上&lt;/strong&gt;，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。（对于CNN来说，大部分运算都耗在卷积操作上，这样做可以节省大量时间）。现在的问题是每个region proposal的尺度不一样，直接这样输入全连接层肯定是不行的，因为全连接层输入必须是固定的长度。SPP-NET恰好可以解决这个问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上图对应的就是SPP-NET的网络结构图，任意给一张图像输入到CNN，经过卷积操作我们可以得到卷积特征（比如VGG16最后的卷积层为conv5_3，共产生512张特征图）。图中的window是就是原图一个region proposal对应到特征图的区域，只需要将这些不同大小window的特征映射到同样的维度，将其作为全连接的输入，就能保证只对图像提取一次卷积层特征。SPP-NET使用了空间金字塔采样（spatial pyramid pooling）：将每个window划分为&lt;code&gt;4*4, 2*2, 1*1&lt;/code&gt;的块，然后每个块使用max-pooling下采样，这样对于每个window经过SPP层之后都得到了一个长度为&lt;code&gt;(4*4+2*2+1)*512&lt;/code&gt;维度的特征向量，将这个作为全连接层的输入进行后续操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小结：&lt;/strong&gt;使用SPP-NET相比于R-CNN可以大大加快目标检测的速度，&lt;strong&gt;但是依然存在着很多问题：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1) 训练分为多个阶段，步骤繁琐: 微调网络+训练SVM+训练训练边框回归器&lt;br&gt;(2) SPP-NET在微调网络的时候固定了卷积层，只对全连接层进行微调，而对于一个新的任务，有必要对卷积层也进行微调。（分类的模型提取的特征更注重高层语义，而目标检测任务除了语义信息还需要目标的位置信息）&lt;br&gt;针对这两个问题，RBG又提出Fast R-CNN, 一个精简而快速的目标检测框架。&lt;/p&gt;
&lt;h3 id=&quot;Fast-R-CNN-ICCV2015&quot;&gt;&lt;a href=&quot;#Fast-R-CNN-ICCV2015&quot; class=&quot;headerlink&quot; title=&quot;Fast R-CNN(ICCV2015)&quot;&gt;&lt;/a&gt;Fast R-CNN(ICCV2015)&lt;/h3&gt;&lt;p&gt;有了前边R-CNN和SPP-NET的介绍，我们直接看Fast R-CNN的框架图：&lt;br&gt;&lt;img src=&quot;/images/Object-Detection/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;与R-CNN框架图对比，可以发现主要有两处不同：&lt;strong&gt;一是最后一个卷积层后加了一个ROI pooling layer，二是损失函数使用了多任务损失函数(multi-task loss)，将边框回归直接加入到CNN网络中训练。&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ROI pooling layer实际上是SPP-NET的一个精简版，SPP-NET对每个proposal使用了不同大小的金字塔映射，而ROI pooling layer只需要下采样到一个&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;x7的特征图。对于VGG16网络conv5_3有&lt;span class=&quot;number&quot;&gt;512&lt;/span&gt;个特征图，这样所有region proposal对应了一个&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt;*&lt;span class=&quot;number&quot;&gt;512&lt;/span&gt;维度的特征向量作为全连接层的输入。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN训练过程分为了三个阶段，而Fast &lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去region proposal提取阶段)。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Fast &lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN在网络微调的过程中，将部分卷积层也进行了微调，取得了更好的检测效果。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小结：Fast R-CNN融合了R-CNN和SPP-NET的精髓，并且引入多任务损失函数，使整个网络的训练和测试变得十分方便。&lt;/strong&gt;在Pascal VOC2007训练集上训练，在VOC2007测试的结果为66.9%(mAP)，如果使用VOC2007+2012训练集训练，在VOC2007上测试结果为70%（数据集的扩充能大幅提高目标检测性能）。使用VGG16每张图像总共需要3s左右。&lt;/p&gt;
&lt;p&gt;缺点：&lt;strong&gt;region proposal的提取使用selective search，目标检测时间大多消耗在这上面（提region proposal 2~3s，而提特征分类只需0.32s），无法满足实时应用，而且并没有实现真正意义上的端到端训练测试&lt;/strong&gt;（region proposal使用selective search先提取处来）。那么有没有可能直接使用CNN直接产生region proposal并对其分类？Faster R-CNN框架就是符合这样需要的目标检测框架。&lt;/p&gt;
&lt;h3 id=&quot;Faster-R-CNN-NIPS2015&quot;&gt;&lt;a href=&quot;#Faster-R-CNN-NIPS2015&quot; class=&quot;headerlink&quot; title=&quot;Faster R-CNN(NIPS2015)&quot;&gt;&lt;/a&gt;Faster R-CNN(NIPS2015)&lt;/h3&gt;&lt;p&gt;(Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks)&lt;br&gt;在region proposal + CNN分类的这种目标检测框架中，region proposal质量好坏直接影响到目标检测任务的精度。如果找到一种方法只提取几百个或者更少的高质量的预选窗口，而且召回率很高，这不但能加快目标检测速度，还能提高目标检测的性能（假阳例少）。RPN(Region Proposal Networks)网络应运而生。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RPN的核心思想是使用卷积神经网络直接产生region proposal，使用的方法本质上就是滑动窗口。RPN的设计比较巧妙，RPN只需在最后的卷积层上滑动一遍，因为anchor机制和边框回归可以得到多尺度多长宽比的region proposal。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们直接看上边的RPN网络结构图(使用了ZF模型)，给定输入图像(假设分辨率为&lt;code&gt;600*1000&lt;/code&gt;)，经过卷积操作得到最后一层的卷积特征图(&lt;code&gt;大小约为40*60&lt;/code&gt;)。在这个特征图上使用&lt;code&gt;3*3的卷积核&lt;/code&gt;(滑动窗口)与特征图进行卷积，最后一层卷积层共有&lt;code&gt;256个feature map&lt;/code&gt;，那么这个&lt;code&gt;3*3&lt;/code&gt;的区域卷积后可以获得一个256维的特征向量，后边接cls layer和reg layer分别用于分类和边框回归（跟Fast R-CNN类似，只不过这里的类别只有目标和背景两个类别）。&lt;code&gt;3*3滑窗&lt;/code&gt;对应的每个特征区域同时预测&lt;code&gt;输入图像3种尺度(128,256,512)，3种长宽比(1:1,1:2,2:1)&lt;/code&gt;的region proposal，这种映射的机制称为anchor。所以对于这个&lt;code&gt;40*60的feature map&lt;/code&gt;，总共有约&lt;code&gt;20000(40*60*9)个anchor&lt;/code&gt;，也就是&lt;code&gt;预测20000个region proposal&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这样设计的好处是什么呢？虽然现在也是用的滑动窗口策略，但是：滑动窗口操作是在卷积层特征图上进行的，&lt;code&gt;维度较原始图像降低了16*16倍(中间经过了4次2*2的pooling操作)&lt;/code&gt;；多尺度采用了9种anchor，对应了三种尺度和三种长宽比，加上后边接了边框回归，所以即便是这9种anchor外的窗口也能得到一个跟目标比较接近的region proposal。&lt;/p&gt;
&lt;p&gt;NIPS2015版本的Faster R-CNN使用的检测框架是&lt;strong&gt;RPN网络+Fast R-CNN网络分离进行的目标检测&lt;/strong&gt;，整体流程跟Fast R-CNN一样，只是region proposal现在是用RPN网络提取的（代替原来的selective search）。同时作者为了让RPN的网络和Fast R-CNN网络实现&lt;strong&gt;卷积层的权值共享&lt;/strong&gt;，训练RPN和Fast R-CNN的时候用了4阶段的训练方法:&lt;br&gt;&lt;figure class=&quot;highlight cos&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;使用在ImageNet上预训练的模型初始化网络参数，微调RPN网络；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;使用(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)中RPN网络提取region proposal训练Fast &lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN网络；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;使用(&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)的Fast &lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN网络重新初始化RPN, 固定卷积层进行微调；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;固定(&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)中Fast &lt;span class=&quot;keyword&quot;&gt;R&lt;/span&gt;-CNN的卷积层，使用(&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)中RPN提取的region proposal微调网络。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;权值共享后的RPN和Fast R-CNN用于目标检测精度会提高一些。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用训练好的RPN网络，给定测试图像，可以直接得到边缘回归后的region proposal，根据region proposal的类别得分对RPN网络进行排序，并选取前300个窗口作为Fast R-CNN的输入进行目标检测，使用VOC07+12训练集训练，VOC2007测试集测试mAP达到73.2%（selective search + Fast R-CNN是70%）， 目标检测的速度可以达到每秒5帧（selective search+Fast R-CNN是2~3s一张）。&lt;/p&gt;
&lt;p&gt;需要注意的是，最新的版本已经将RPN网络和Fast R-CNN网络结合到了一起——将RPN获取到的proposal直接连到ROI pooling层，这才是一个真正意义上的使用一个CNN网络实现端到端目标检测的框架。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小结：Faster R-CNN将一直以来分离的region proposal和CNN分类融合到了一起，使用端到端的网络进行目标检测，&lt;/strong&gt;无论在速度上还是精度上都得到了不错的提高。然而Faster R-CNN还是达不到实时的目标检测，预先获取region proposal，然后在对每个proposal分类计算量还是比较大。比较幸运的是YOLO这类目标检测方法的出现让实时性也变的成为可能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总的来说，&lt;/strong&gt;从R-CNN, SPP-NET, Fast R-CNN, Faster R-CNN一路走来，&lt;strong&gt;基于深度学习目标检测的流程变得越来越精简，精度越来越高，速度也越来越快。&lt;/strong&gt;可以说基于region proposal的R-CNN系列目标检测方法是当前目标最主要的一个分支。&lt;/p&gt;
&lt;h2 id=&quot;基于回归方法的深度学习目标检测算法&quot;&gt;&lt;a href=&quot;#基于回归方法的深度学习目标检测算法&quot; class=&quot;headerlink&quot; title=&quot;基于回归方法的深度学习目标检测算法&quot;&gt;&lt;/a&gt;基于回归方法的深度学习目标检测算法&lt;/h2&gt;&lt;p&gt;Faster R-CNN的方法目前是主流的目标检测方法，但是速度上并不能满足实时的要求。YOLO一类的方法慢慢显现出其重要性，这类方法使用了回归的思想，既给定输入图像，直接在图像的多个位置上回归出这个位置的目标边框以及目标类别。&lt;/p&gt;
&lt;h3 id=&quot;YOLO-CVPR2016-oral&quot;&gt;&lt;a href=&quot;#YOLO-CVPR2016-oral&quot; class=&quot;headerlink&quot; title=&quot;YOLO (CVPR2016, oral)&quot;&gt;&lt;/a&gt;YOLO (CVPR2016, oral)&lt;/h3&gt;&lt;p&gt;(You Only Look Once: Unified, Real-Time Object Detection)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们直接看上面YOLO的目标检测的流程图：&lt;br&gt;&lt;figure class=&quot;highlight gherkin&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;给个一个输入图像，首先将图像划分成7&lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt;7的网格&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;根据上一步可以预测出7&lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt;7&lt;span class=&quot;keyword&quot;&gt;*&lt;/span&gt;2个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以看到整个过程非常简单，不需要中间的region proposal在找目标，直接回归便完成了位置和类别的判定。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;那么如何才能做到直接在不同位置的网格上回归出目标的位置和类别信息呢？上面是YOLO的网络结构图，前边的网络结构跟GoogLeNet的模型比较类似，主要的是最后两层的结构，卷积层之后接了一个4096维的全连接层，然后后边又全连接到一个7*7*30维的张量上。实际上这7*7就是划分的网格数，现在要在每个网格上预测目标两个可能的位置以及这个位置的目标置信度和类别，也就是每个网格预测两个目标，每个目标的信息有4维坐标信息(中心点坐标+长宽)，1个是目标的置信度，还有类别数20(VOC上20个类别)，总共就是(4+1)*2+20 = 30维的向量。这样可以利用前边4096维的全图特征直接在每个网格上回归出目标检测需要的信息（边框信息加类别）。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;小结：&lt;strong&gt;YOLO将目标检测任务转换成一个回归问题，大大加快了检测的速度，使得YOLO可以每秒处理45张图像。&lt;/strong&gt;而且由于每个网络预测目标窗口时使用的是全图信息，使得false positive比例大幅降低（充分的上下文信息）。但是YOLO也存在问题：没有了region proposal机制，只使用7*7的网格回归会使得目标不能非常精准的定位，这也导致了YOLO的检测精度并不是很高。&lt;/p&gt;
&lt;h3 id=&quot;SSD&quot;&gt;&lt;a href=&quot;#SSD&quot; class=&quot;headerlink&quot; title=&quot;SSD&quot;&gt;&lt;/a&gt;SSD&lt;/h3&gt;&lt;p&gt;(SSD: Single Shot MultiBox Detector)&lt;br&gt;上面分析了YOLO存在的问题，使用整图特征在&lt;code&gt;7*7&lt;/code&gt;的粗糙网格内回归对目标的定位并不是很精准。那是不是可以结合region proposal的思想实现精准一些的定位？&lt;strong&gt;SSD结合YOLO的回归思想以及Faster R-CNN的anchor机制做到了这点。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Object-Detection/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上图是SSD的一个框架图，首先SSD获取目标位置和类别的方法跟YOLO一样，都是使用回归，但是YOLO预测某个位置使用的是全图的特征，SSD预测某个位置使用的是这个位置周围的特征（感觉更合理一些）。那么如何建立某个位置和其特征的对应关系呢？可能你已经想到了，使用Faster R-CNN的anchor机制。&lt;code&gt;如SSD的框架图所示，假如某一层特征图(图b)大小是8*8，那么就使用3*3的滑窗提取每个位置的特征，然后这个特征回归得到目标的坐标信息和类别信息(图c)。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;不同于Faster R-CNN，这个anchor是在多个feature map上，这样可以利用多层的特征并且自然的达到多尺度（不同层的feature map 3*3滑窗感受野不同）。&lt;/p&gt;
&lt;p&gt;小结：&lt;strong&gt;SSD结合了YOLO中的回归思想和Faster R-CNN中的anchor机制，&lt;/strong&gt;使用全图各个位置的多尺度区域特征进行回归，既保持了YOLO速度快的特性，也保证了窗口预测的跟Faster R-CNN一样比较精准。SSD在VOC2007上mAP可以达到72.1%，速度在GPU上达到58帧每秒。&lt;/p&gt;
&lt;p&gt;总结：YOLO的提出给目标检测一个新的思路，SSD的性能则让我们看到了目标检测在实际应用中真正的可能性。&lt;/p&gt;
&lt;h2 id=&quot;提高目标检测方法&quot;&gt;&lt;a href=&quot;#提高目标检测方法&quot; class=&quot;headerlink&quot; title=&quot;提高目标检测方法&quot;&gt;&lt;/a&gt;提高目标检测方法&lt;/h2&gt;&lt;p&gt;R-CNN系列目标检测框架和YOLO目标检测框架给了我们进行目标检测的两个基本框架。除此之外，研究人员基于这些框架从其他方面入手提出了一系列提高目标检测性能的方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;难分样本挖掘(hard negative mining)&lt;/strong&gt;&lt;br&gt;R-CNN在训练SVM分类器时使用了难分样本挖掘的思想，但Fast R-CNN和Faster R-CNN由于使用端到端的训练策略并没有使用难分样本挖掘（只是设置了正负样本的比例并随机抽取）。CVPR2016的Training Region-based Object Detectors with Online Hard Example Mining(oral)将难分样本挖掘(hard example mining)机制嵌入到SGD算法中，使得Fast R-CNN在训练的过程中根据region proposal的损失自动选取合适的region proposal作为正负例训练。实验结果表明使用OHEM（Online Hard Example Mining）机制可以使得Fast R-CNN算法在VOC2007和VOC2012上mAP提高 4%左右。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多层特征融合&lt;/strong&gt;&lt;br&gt;Fast R-CNN和Faster R-CNN都是利用了最后卷积层的特征进行目标检测，而由于高层的卷积层特征已经损失了很多细节信息（pooling操作），所以在定位时不是很精准。HyperNet等一些方法则利用了CNN的多层特征融合进行目标检测，这不仅利用了高层特征的语义信息，还考虑了低层特征的细节纹理信息，使得目标检测定位更精准。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用上下文信息&lt;/strong&gt;&lt;br&gt;在提取region proposal特征进行目标检测时，结合region proposal上下文信息，检测效果往往会更好一些。（Object detection via a multi-region &amp;amp; semantic segmentation-aware CNN model以及Inside-Outside Net等论文中都使用了上下文信息）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系loveholicguoguo。&lt;/p&gt;
&lt;h2 id=&quot;作者简介&quot;&gt;&lt;a href=&quot;#作者简介&quot; class=&quot;headerlink&quot; title=&quot;作者简介&quot;&gt;&lt;/a&gt;作者简介&lt;/h2&gt;&lt;p&gt;王斌(中科院计算所前瞻研究实验室跨媒体计算课题组博士生，导师张勇东研究员)&lt;br&gt;研究方向为基于深度学习的目标检测。2015年作为计算所MCG-ICT-CAS团队成员，参加ImageNet竞赛ILSVRC2015的目标检测任务获得全球第5名。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;目标检测对于人来说是再简单不过的任务，但是对于计算机来说，它看到的是一些值为0~255的数组，因而很难直接得到图像中有人或者猫这种高层语义概念，也不清楚目标出现在图像中哪个区域。图像中的目标可能出现在任何位置，目标的形态可能存在各种各样的变化，图像的背景千差万别……，这些因素导致目标检测并不是一个容易解决的任务。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.mindcont.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Ubuntu 14.04 64bit + Caffe rc3 + CUDA 7.5 + Intel MKL 配置说明</title>
    <link href="http://blog.mindcont.com/2016/07/20/ubuntu1404-caffe-r3-cuda7-5-mkl/"/>
    <id>http://blog.mindcont.com/2016/07/20/ubuntu1404-caffe-r3-cuda7-5-mkl/</id>
    <published>2016-07-20T08:24:09.000Z</published>
    <updated>2016-08-22T08:06:21.030Z</updated>
    
    <content type="html">&lt;p&gt;本步骤经笔者亲身实践，集百家所长，能实现Caffe在NVIDIA GPU下进行计算。&lt;/p&gt;
&lt;h2 id=&quot;安装开发所需的依赖包&quot;&gt;&lt;a href=&quot;#安装开发所需的依赖包&quot; class=&quot;headerlink&quot; title=&quot;安装开发所需的依赖包&quot;&gt;&lt;/a&gt;安装开发所需的依赖包&lt;/h2&gt;&lt;p&gt;安装开发所需要的一些基本包&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install build-essential  &lt;span class=&quot;comment&quot;&gt;# basic requirement&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install vim cmake git    &lt;span class=&quot;comment&quot;&gt;# tools&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler libatlas-base-dev  &lt;span class=&quot;comment&quot;&gt;#required by caffe&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装CUDA及驱动&quot;&gt;&lt;a href=&quot;#安装CUDA及驱动&quot; class=&quot;headerlink&quot; title=&quot;安装CUDA及驱动&quot;&gt;&lt;/a&gt;安装CUDA及驱动&lt;/h2&gt;&lt;h3 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h3&gt;&lt;p&gt;下文中所有资源可在&lt;strong&gt;百度云&lt;/strong&gt; 链接：&lt;a href=&quot;http://pan.baidu.com/s/1dEXPg3J&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pan.baidu.com/s/1dEXPg3J&lt;/a&gt; 密码：v19o 得到。&lt;/p&gt;
&lt;p&gt;在关闭桌面管理 lightdm 的情况下安装驱动似乎可以实现Intel 核芯显卡 来显示 + NVIDIA 显卡来计算。具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先在BIOS设置里选择用Intel显卡来显示或作为主要显示设备&lt;/li&gt;
&lt;li&gt;&lt;p&gt;进入Ubuntu， 按 ctrl+alt+F1 进入tty， 登录tty后输入如下命令&lt;/p&gt;
&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo service lightdm stop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;该命令会关闭lightdm。如果你使用 gdm或者其他的desktop manager, 请在安装NVIDIA驱动前关闭他。&lt;/p&gt;
&lt;h3 id=&quot;下载deb包及安装CUDA&quot;&gt;&lt;a href=&quot;#下载deb包及安装CUDA&quot; class=&quot;headerlink&quot; title=&quot;下载deb包及安装CUDA&quot;&gt;&lt;/a&gt;下载deb包及安装CUDA&lt;/h3&gt;&lt;p&gt;使用deb包安装CUDA及驱动能省去很多麻烦(参见&lt;a href=&quot;http://developer.download.nvidia.com/compute/cuda/6_5/rel/docs/CUDA_Getting_Started_Linux.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CUDA Starting Guide&lt;/a&gt;)。下载对应于你系统的&lt;a href=&quot;https://developer.nvidia.com/cuda-downloads&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CUDA deb包&lt;/a&gt;, 然后用下列命令添加软件源&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo dpkg -i cuda-repo-&amp;lt;distro&amp;gt;_&amp;lt;version&amp;gt;_&amp;lt;architecture&amp;gt;.deb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后用下列命令安装CUDA&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install cuda&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装完成后 reboot.&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo reboot&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装cuDNN&quot;&gt;&lt;a href=&quot;#安装cuDNN&quot; class=&quot;headerlink&quot; title=&quot;安装cuDNN&quot;&gt;&lt;/a&gt;安装cuDNN&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;(03-25: 今天下最新的caffe回来发现编译不过啊一直CUDNN报错浪费了我几个小时没搞定! 后来才发现caffe15小时前的更新开始使用cudnn v2, 但是官网上并没有明显提示!!! 坑爹啊!)&lt;/strong&gt;&lt;br&gt;cuDNN能加速caffe中conv及pooling的计算。首先下载&lt;a href=&quot;https://developer.nvidia.com/cudnn&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;cuDNN&lt;/a&gt;,需要注册。或通过在&lt;strong&gt;百度云&lt;/strong&gt; 链接：&lt;a href=&quot;http://pan.baidu.com/s/1dEXPg3J&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pan.baidu.com/s/1dEXPg3J&lt;/a&gt; 密码：v19o 得到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/cuDNN Download.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;下载完成后，然后执行下列命令解压并安装&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 需注意，切换到你自己存放 cudnn-7.5-linux-x64-v5.1-rc.tgz 文件的文件夹下进行解压&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf cudnn-7.5-linux-x64-v5.1-rc.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; cuda&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo cp lib64/* /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda/lib64/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo cp include/cudnn.h /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda/include/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/cudnn_copy.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;更新软链接&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda/lib64/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo rm -rf libcudnn.so libcudnn.so.5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ln &lt;span class=&quot;_&quot;&gt;-s&lt;/span&gt; libcudnn.so.5.1.3 libcudnn.so&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/cudnn_finish.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置环境变量&quot;&gt;&lt;a href=&quot;#设置环境变量&quot; class=&quot;headerlink&quot; title=&quot;设置环境变量&quot;&gt;&lt;/a&gt;设置环境变量&lt;/h3&gt;&lt;p&gt;安装完成后需要在&lt;code&gt;/etc/profile&lt;/code&gt;中添加环境变量,&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo gedit /etc/profile&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在文件最后添加:&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;PATH=/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda/bin:&lt;span class=&quot;variable&quot;&gt;$PATH&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PATH&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/caffe_profile.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;保存后, 执行下列命令, 使环境变量立即生效&lt;br&gt;&lt;figure class=&quot;highlight gradle&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;regexp&quot;&gt;/etc/&lt;/span&gt;profile&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;同时需要添加lib库路径： 在 &lt;code&gt;/etc/ld.so.conf.d/&lt;/code&gt;加入文件 &lt;code&gt;cuda.conf&lt;/code&gt;, 内容如下&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda/lib64&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/cuda_conf.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;保存后，执行下列命令使之立刻生效&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo ldconfig&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;测试CUDA&quot;&gt;&lt;a href=&quot;#测试CUDA&quot; class=&quot;headerlink&quot; title=&quot;测试CUDA&quot;&gt;&lt;/a&gt;测试CUDA&lt;/h2&gt;&lt;p&gt;进入&lt;code&gt;/usr/local/cuda/samples&lt;/code&gt;, 执行下列命令来build samples&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo make all -j4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;编译过程&lt;br&gt;&lt;img src=&quot;/images/caffe/cuda_samples.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;整个过程大概10分钟左右, 全部编译完成后， 进入 &lt;code&gt;samples/bin/x86_64/linux/release&lt;/code&gt;, 运行deviceQuery&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./deviceQuery&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果出现显卡信息， 则驱动及显卡安装成功：&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pi@DeepMind:/usr/local/cuda/samples/bin/x86_64/linux/&lt;span class=&quot;keyword&quot;&gt;release&lt;/span&gt;$ ./deviceQuery&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./deviceQuery &lt;span class=&quot;keyword&quot;&gt;Starting&lt;/span&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; CUDA Device &lt;span class=&quot;keyword&quot;&gt;Query&lt;/span&gt; (Runtime API) &lt;span class=&quot;keyword&quot;&gt;version&lt;/span&gt; (CUDART &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; linking)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Detected &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; CUDA Capable device(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Device &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Quadro K2200&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  CUDA Driver &lt;span class=&quot;keyword&quot;&gt;Version&lt;/span&gt; / Runtime &lt;span class=&quot;keyword&quot;&gt;Version&lt;/span&gt;          &lt;span class=&quot;number&quot;&gt;7.5&lt;/span&gt; / &lt;span class=&quot;number&quot;&gt;7.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  CUDA Capability Major/Minor &lt;span class=&quot;keyword&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;number&lt;/span&gt;:    &lt;span class=&quot;number&quot;&gt;5.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Total amount &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;memory&lt;/span&gt;:                 &lt;span class=&quot;number&quot;&gt;4095&lt;/span&gt; MBytes (&lt;span class=&quot;number&quot;&gt;4294246400&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ( &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;) Multiprocessors, (&lt;span class=&quot;number&quot;&gt;128&lt;/span&gt;) CUDA Cores/MP:     &lt;span class=&quot;number&quot;&gt;640&lt;/span&gt; CUDA Cores&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  GPU &lt;span class=&quot;keyword&quot;&gt;Max&lt;/span&gt; Clock rate:                            &lt;span class=&quot;number&quot;&gt;1124&lt;/span&gt; MHz (&lt;span class=&quot;number&quot;&gt;1.12&lt;/span&gt; GHz)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Memory&lt;/span&gt; Clock rate:                             &lt;span class=&quot;number&quot;&gt;2505&lt;/span&gt; Mhz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Memory&lt;/span&gt; Bus Width:                              &lt;span class=&quot;number&quot;&gt;128&lt;/span&gt;-&lt;span class=&quot;built_in&quot;&gt;bit&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  L2 &lt;span class=&quot;keyword&quot;&gt;Cache&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;Size&lt;/span&gt;:                                 &lt;span class=&quot;number&quot;&gt;2097152&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum Texture &lt;span class=&quot;keyword&quot;&gt;Dimension&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;Size&lt;/span&gt; (x,y,z)         &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;D=(&lt;span class=&quot;number&quot;&gt;65536&lt;/span&gt;), &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;D=(&lt;span class=&quot;number&quot;&gt;65536&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;65536&lt;/span&gt;), &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;D=(&lt;span class=&quot;number&quot;&gt;4096&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4096&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4096&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum Layered &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;D Texture &lt;span class=&quot;keyword&quot;&gt;Size&lt;/span&gt;, (&lt;span class=&quot;keyword&quot;&gt;num&lt;/span&gt;) layers  &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;D=(&lt;span class=&quot;number&quot;&gt;16384&lt;/span&gt;), &lt;span class=&quot;number&quot;&gt;2048&lt;/span&gt; layers&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum Layered &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;D Texture &lt;span class=&quot;keyword&quot;&gt;Size&lt;/span&gt;, (&lt;span class=&quot;keyword&quot;&gt;num&lt;/span&gt;) layers  &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;D=(&lt;span class=&quot;number&quot;&gt;16384&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;16384&lt;/span&gt;), &lt;span class=&quot;number&quot;&gt;2048&lt;/span&gt; layers&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Total amount &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;constant&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;memory&lt;/span&gt;:               &lt;span class=&quot;number&quot;&gt;65536&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Total amount &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;shared&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;memory&lt;/span&gt; per &lt;span class=&quot;keyword&quot;&gt;block&lt;/span&gt;:       &lt;span class=&quot;number&quot;&gt;49152&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Total &lt;span class=&quot;built_in&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; registers available per &lt;span class=&quot;keyword&quot;&gt;block&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;65536&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Warp &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt;:                                     &lt;span class=&quot;number&quot;&gt;32&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum &lt;span class=&quot;built_in&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; threads per multiprocessor:  &lt;span class=&quot;number&quot;&gt;2048&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum &lt;span class=&quot;built_in&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; threads per &lt;span class=&quot;keyword&quot;&gt;block&lt;/span&gt;:           &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Max&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;dimension&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;block&lt;/span&gt; (x,y,z): (&lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1024&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;64&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Max&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;dimension&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; a grid &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt;    (x,y,z): (&lt;span class=&quot;number&quot;&gt;2147483647&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;65535&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;65535&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Maximum &lt;span class=&quot;keyword&quot;&gt;memory&lt;/span&gt; pitch:                          &lt;span class=&quot;number&quot;&gt;2147483647&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Texture alignment:                             &lt;span class=&quot;number&quot;&gt;512&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Concurrent&lt;/span&gt; copy &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; kernel execution:          Yes &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; copy &lt;span class=&quot;keyword&quot;&gt;engine&lt;/span&gt;(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Run &lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; kernels:                     Yes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Integrated GPU sharing Host &lt;span class=&quot;keyword&quot;&gt;Memory&lt;/span&gt;:            &lt;span class=&quot;keyword&quot;&gt;No&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Support host page-&lt;span class=&quot;keyword&quot;&gt;locked&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;mapping&lt;/span&gt;:       Yes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Alignment requirement &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; Surfaces:            Yes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Device has ECC support:                        Disabled&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Device supports Unified Addressing (UVA):      Yes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Device PCI &lt;span class=&quot;keyword&quot;&gt;Domain&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ID&lt;/span&gt; / Bus &lt;span class=&quot;keyword&quot;&gt;ID&lt;/span&gt; / location &lt;span class=&quot;keyword&quot;&gt;ID&lt;/span&gt;:   &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; / &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; / &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;Compute&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;Mode&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;lt; &lt;span class=&quot;keyword&quot;&gt;Default&lt;/span&gt; (multiple host threads can &lt;span class=&quot;keyword&quot;&gt;use&lt;/span&gt; ::cudaSetDevice() &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; device simultaneously) &amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deviceQuery, CUDA Driver = CUDART, CUDA Driver &lt;span class=&quot;keyword&quot;&gt;Version&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;7.5&lt;/span&gt;, CUDA Runtime &lt;span class=&quot;keyword&quot;&gt;Version&lt;/span&gt; = &lt;span class=&quot;number&quot;&gt;7.5&lt;/span&gt;, NumDevs = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, Device0 = Quadro K2200&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;Result&lt;/span&gt; = PASS&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/deviceQuery.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Intel-MKL-或Atlas&quot;&gt;&lt;a href=&quot;#安装Intel-MKL-或Atlas&quot; class=&quot;headerlink&quot; title=&quot;安装Intel MKL 或Atlas&quot;&gt;&lt;/a&gt;安装Intel MKL 或Atlas&lt;/h2&gt;&lt;p&gt;如果没有Intel MKL， 可以用下列命令安装免费的atlas&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install libatlas-base-dev&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果有mkl安装包&lt;a href=&quot;https://software.intel.com/en-us/intel-mkl&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Intel® MKL&lt;/a&gt;需注册后会发下载链接和激活码到注册邮箱。&lt;br&gt;先注册，后再登录到此界面，选择’Get This Library for Free!’-&amp;gt;’Everyone’。&lt;br&gt;&lt;img src=&quot;/images/caffe/mkl_Download_1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择社区版本Licensing&lt;br&gt;&lt;img src=&quot;/images/caffe/mkl_Download_2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;填写信息后，会下载链接和激活码到你注册邮箱。&lt;br&gt;&lt;img src=&quot;/images/caffe/mkl_Download_3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先解压安装包，下面有一个install_GUI.sh文件， 执行该文件，会出现图形安装界面，根据说明一步一步执行即可。&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar -zxvf l_mkl_11.3.3.210.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; l_mkl_11.3.3.210&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo sh install.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/mkl_install.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/caffe/mkl_ativate.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/caffe/mkl_complete.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意&lt;/strong&gt;： 安装完成后需要添加library路径, 创建&lt;code&gt;/etc/ld.so.conf.d/intel_mkl.conf&lt;/code&gt;文件， 在文件中添加内容&lt;br&gt;&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/opt/intel/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;intel64&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/opt/intel/mkl/&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;title&quot;&gt;intel64&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/caffe/intel_mkl_conf.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;注意把路径替换成自己的安装路径。 编辑完后执行&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo ldconfig&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装OpenCV-Optional，-如果运行caffe时opencv报错，-可以重新按照此步骤安装&quot;&gt;&lt;a href=&quot;#安装OpenCV-Optional，-如果运行caffe时opencv报错，-可以重新按照此步骤安装&quot; class=&quot;headerlink&quot; title=&quot;安装OpenCV (Optional， 如果运行caffe时opencv报错， 可以重新按照此步骤安装)&quot;&gt;&lt;/a&gt;安装OpenCV (Optional， 如果运行caffe时opencv报错， 可以重新按照此步骤安装)&lt;/h2&gt;&lt;p&gt;参见我的另一篇博客&lt;a href=&quot;http://blog.mindcont.com/2016/07/16/installing-opencv-2-4-9-in-ubuntu-14-04-lts/&quot;&gt;Ubuntu 14.04安装 OpenCV 2.4.9&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Caffe所需要的Python环境&quot;&gt;&lt;a href=&quot;#安装Caffe所需要的Python环境&quot; class=&quot;headerlink&quot; title=&quot;安装Caffe所需要的Python环境&quot;&gt;&lt;/a&gt;安装Caffe所需要的Python环境&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install python-numpy python-scipy python-matplotlib python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-nose python-pandas python-gflags Cython ipython python-pydot&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install protobuf-c-compiler protobuf-compiler&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;安装MATLAB&quot;&gt;&lt;a href=&quot;#安装MATLAB&quot; class=&quot;headerlink&quot; title=&quot;安装MATLAB&quot;&gt;&lt;/a&gt;安装MATLAB&lt;/h2&gt;&lt;p&gt;Caffe提供了MATLAB接口，有需要用MATLAB的同学可以额外安装MATLAB。安装教程同Windows 下类似,首先下载 MATLAB for Linux、解压。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo sh ./install.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;弹出图形界面，之后同在Windows下一样进行破解激活。windows下安装和激活 Matlab参加我的另一篇博客&lt;a href=&quot;http://blog.mindcont.com/2016/05/18/Microsoft-Kinect-V2-with-Matlab/&quot;&gt;Matlab连接Kinect V2&lt;/a&gt;  。安装完成后可&lt;a href=&quot;http://www.linuxidc.com/Linux/2011-01/31632.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;添加图标&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo vi /usr/share/applications/Matlab.desktop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;输入以下内容&lt;/p&gt;
&lt;figure class=&quot;highlight ini&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;section&quot;&gt;[Desktop Entry]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Type&lt;/span&gt;=Application&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Name&lt;/span&gt;=Matlab&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;GenericName&lt;/span&gt;=Matlab R2015b&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Comment&lt;/span&gt;=Matlab:The Language of Technical Computing&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Exec&lt;/span&gt;=sh /usr/local/MATLAB/R2015b/bin/matlab -desktop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Icon&lt;/span&gt;=/usr/local/MATLAB/Matlab.png&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Terminal&lt;/span&gt;=&lt;span class=&quot;literal&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;Categories&lt;/span&gt;=Development;Matlab;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里我的Matlab安装位置为默认，如下所示&lt;br&gt;&lt;img src=&quot;/images/caffe/matlab_location.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;编译Caffe&quot;&gt;&lt;a href=&quot;#编译Caffe&quot; class=&quot;headerlink&quot; title=&quot;编译Caffe&quot;&gt;&lt;/a&gt;编译Caffe&lt;/h2&gt;&lt;h3 id=&quot;编译主程序&quot;&gt;&lt;a href=&quot;#编译主程序&quot; class=&quot;headerlink&quot; title=&quot;编译主程序&quot;&gt;&lt;/a&gt;编译主程序&lt;/h3&gt;&lt;p&gt;终于完成了所有环境的配置，可以愉快的编译Caffe了！&lt;strong&gt;需要注意的是，这里我采用的是caffe-rc3.zip(on 30 Jan 2016)。&lt;/strong&gt; 进入caffe根目录， 首先复制一份&lt;code&gt;Makefile.config&lt;/code&gt;,&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cp Makefile.config.example Makefile.config&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt; 然后修改里面的内容，主要需要修改的参数包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU_ONLY 是否只使用CPU模式，没有GPU没安装CUDA的同学可以打开这个选项&lt;/li&gt;
&lt;li&gt;BLAS (使用intel mkl还是atlas)&lt;/li&gt;
&lt;li&gt;MATLAB_DIR 如果需要使用MATLAB wrapper的同学需要指定matlab的安装路径, 如我的路径为 &lt;code&gt;/usr/local/MATLAB/R2015b&lt;/code&gt; (注意该目录下需要包含bin文件夹，bin文件夹里应该包含mex二进制程序)&lt;/li&gt;
&lt;li&gt;DEBUG 是否使用debug模式，打开此选项则可以在eclipse或者NSight中debug程序&lt;/li&gt;
&lt;li&gt;CUDA_ARCH 可根据你自己显卡对应的计算力&lt;a href=&quot;https://developer.nvidia.com/cuda-gpus&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;/a&gt;改相应的 -gencode arch=compute_xx,code=compute_xx 。例如我的显卡是 NVIDIA K2200 对应的计算力是 5.0，所以我相应的设置为 -gencode arch=compute_50,code=compute_50 &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里是我的配置：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;109&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;## Refer to http://caffe.berkeleyvision.org/installation.html&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Contributions simplifying and improving our build system are welcome!&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# cuDNN acceleration switch (uncomment to build with cuDNN).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; USE_CUDNN := 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CPU-only switch (uncomment to build without GPU support).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CPU_ONLY := 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# uncomment to disable IO dependencies and corresponding data layers&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; USE_OPENCV := 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; USE_LEVELDB := 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; USE_LMDB := 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#	You should not set this flag if you will be reading LMDBs with any&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#	possibility of simultaneous read and write&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# ALLOW_LMDB_NOLOCK := 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Uncomment if you&#39;re using OpenCV 3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# OPENCV_VERSION := 3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# To customize your choice of compiler, uncomment and set the following.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# N.B. the default for Linux is g++ and the default for OSX is clang++&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CUSTOM_CXX := g++&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CUDA directory contains bin/ and lib/ directories that we need.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; CUDA_DIR := /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/cuda&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# On Ubuntu 14.04, if cuda tools are installed via&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# &quot;sudo apt-get install nvidia-cuda-toolkit&quot; then use this instead:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CUDA_DIR := /usr&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# CUDA architecture setting: going with all of them.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# For CUDA &amp;lt; 6.0, comment the *_50 lines for compatibility.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; CUDA_ARCH := -gencode arch=compute_50,code=sm_50 \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		-gencode arch=compute_50,code=compute_50 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# BLAS choice:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# atlas for ATLAS (default)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# mkl for MKL&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# open for OpenBlas&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; BLAS := mkl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Leave commented to accept the defaults for your choice of BLAS&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# (which should work)!&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; BLAS_INCLUDE := /opt/intel/mkl/include&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; BLAS_LIB := /opt/intel/mkl/lib/intel64 \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	     /opt/intel/lib/intel64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Homebrew puts openblas in a directory that is not on the standard search path&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# BLAS_INCLUDE := $(shell brew --prefix openblas)/include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# BLAS_LIB := $(shell brew --prefix openblas)/lib&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# This is required only if you will compile the matlab interface.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# MATLAB directory should contain the mex binary in /bin.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; MATLAB_DIR := /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/MATLAB/R2015b&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# MATLAB_DIR := /Applications/MATLAB_R2012b.app&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# &lt;span class=&quot;doctag&quot;&gt;NOTE:&lt;/span&gt; this is required only if you will compile the python interface.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# We need to be able to find Python.h and numpy/arrayobject.h.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PYTHON_INCLUDE := /usr/include/python2.7 \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		/usr/lib/python2.7/dist-packages/numpy/core/include&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Anaconda Python distribution is quite popular. Include path:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Verify anaconda location, sometimes it&#39;s in root.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# ANACONDA_HOME := $(HOME)/anaconda&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_INCLUDE := $(ANACONDA_HOME)/include \&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;# $(ANACONDA_HOME)/include/python2.7 \&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;# $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Uncomment to use Python 3 (default is Python 2)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_LIBRARIES := boost_python3 python3.5m&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_INCLUDE := /usr/include/python3.5m \&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#                 /usr/lib/python3.5/dist-packages/numpy/core/include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# We need to be able to find libpythonX.X.so or .dylib.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PYTHON_LIB := /usr/lib&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_LIB := $(ANACONDA_HOME)/lib&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Homebrew installs numpy in a non standard path (keg only)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_INCLUDE += $(dir $(shell python -c &#39;import numpy.core; print(numpy.core.__file__)&#39;))/include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# PYTHON_LIB += $(shell brew --prefix numpy)/lib&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Uncomment to support layers written in Python (will link against Python libs)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# WITH_PYTHON_LAYER := 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Whatever else you find you need goes here.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/include&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;LIBRARY_DIRS := $(PYTHON_LIB) /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/lib /usr/lib&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# INCLUDE_DIRS += $(shell brew --prefix)/include&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# LIBRARY_DIRS += $(shell brew --prefix)/lib&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Uncomment to use `pkg-config` to specify OpenCV library paths.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# USE_PKG_CONFIG := 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# N.B. both build and distribute dirs are cleared on `make clean`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;BUILD_DIR := build&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;DISTRIBUTE_DIR := distribute&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# DEBUG := 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# The ID of the GPU that &#39;make runtest&#39; will use to run unit tests.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; TEST_GPUID := 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# enable pretty build (comment to see full commands)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q ?= @&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;完成设置后， 开始编译&lt;br&gt;&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;make all -j4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make &lt;span class=&quot;built_in&quot;&gt;test&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make runtest&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt; &lt;code&gt;-j4&lt;/code&gt; 是指使用几个线程来同时编译， 可以加快速度， j后面的数字可以根据CPU core的个数来决定， 我的CPU使4核， 所以-j4.&lt;br&gt;&lt;img src=&quot;/images/caffe/makeruntest_begin.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/caffe/makeruntest_finish.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;编译Matlab-wrapper&quot;&gt;&lt;a href=&quot;#编译Matlab-wrapper&quot; class=&quot;headerlink&quot; title=&quot;编译Matlab wrapper&quot;&gt;&lt;/a&gt;编译Matlab wrapper&lt;/h3&gt;&lt;p&gt;执行如下命令&lt;br&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; matcaffe&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后就可以跑官方的matlab demo啦。&lt;/p&gt;
&lt;h3 id=&quot;编译Python-wrapper&quot;&gt;&lt;a href=&quot;#编译Python-wrapper&quot; class=&quot;headerlink&quot; title=&quot;编译Python wrapper&quot;&gt;&lt;/a&gt;编译Python wrapper&lt;/h3&gt;&lt;figure class=&quot;highlight gauss&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;make&lt;/span&gt; pycaffe&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 这里生成caffe 的 python 还不能够直接使用，建议输入下面的指令，将其加入到当前用户的用户变量中。&lt;br&gt;&lt;figure class=&quot;highlight nginx&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;regexp&quot;&gt;~&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gedit&lt;/span&gt; .bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在打开的文件中，输入&lt;br&gt;&lt;figure class=&quot;highlight xquery&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;export PYTHONPATH=/home/pi/caffe/python:$PYTHONPATH&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;保存后关闭，然后在命令行下输入&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;source&lt;/span&gt; .bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;打开一个新的终端或同时按住（Ctrl + Alt + T）,输入&lt;br&gt;&lt;figure class=&quot;highlight qml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;string&quot;&gt; caffe&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果看到如下内容&lt;br&gt;&lt;figure class=&quot;highlight ruby&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pi@DeepMind&lt;span class=&quot;symbol&quot;&gt;:~&lt;/span&gt;$ python&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Python &lt;span class=&quot;number&quot;&gt;2.7&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;6&lt;/span&gt; (default, Jun &lt;span class=&quot;number&quot;&gt;22&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2015&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;58&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;13&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[GCC &lt;span class=&quot;number&quot;&gt;4.8&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;] on linux2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Type &lt;span class=&quot;string&quot;&gt;&quot;help&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;copyright&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;credits&quot;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;license&quot;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; more information.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&amp;gt; import caffe&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后基本就全部安装完拉。接下来大家尽情地跑demo吧～&lt;/p&gt;
&lt;h2 id=&quot;参考链接&quot;&gt;&lt;a href=&quot;#参考链接&quot; class=&quot;headerlink&quot; title=&quot;参考链接&quot;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://caffe.berkeleyvision.org/install_apt.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/BVLC/caffe/wiki/Ubuntu-16.04-or-15.10-Installation-Guide&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu 16.04 or 15.10 Installation Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/bearpaw/c38ef18ec45ba6548ec0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Caffe + Ubuntu 12.04 64bit + CUDA 6.5 配置说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/platero/p/3993877.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;普兒的技术传送门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/u013476464/article/details/38071075&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;浙商大嵌入式实验室-凉水煮茶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://zzfei.com/archives/process-solving-a-compilation-problem.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;记一个编译问题的解决过程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/brightming/article/details/51106629&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;caffe的配置过程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/rbgirshick/py-faster-rcnn/issues/2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;error == cudaSuccess (8 vs. 0) &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;转载务必注明&lt;/strong&gt; 来自&lt;a href=&quot;http://blog.mindcont.com/2016/07/20/ubuntu1404-caffe-cuda7-5-mkl/&quot;&gt;微记元-Ubuntu 14.04 64bit + Caffe + CUDA 7.5 + Intel MKL 配置说明&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;本步骤经笔者亲身实践，集百家所长，能实现Caffe在NVIDIA GPU下进行计算。&lt;/p&gt;
&lt;h2 id=&quot;安装开发所需的依赖包&quot;&gt;&lt;a href=&quot;#安装开发所需的依赖包&quot; class=&quot;headerlink&quot; title=&quot;安装开发所需的依赖包&quot;&gt;&lt;/a&gt;安装开发所需
    
    </summary>
    
      <category term="深度学习" scheme="http://blog.mindcont.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Caffe" scheme="http://blog.mindcont.com/tags/Caffe/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 14.04安装 OpenCV 2.4.9</title>
    <link href="http://blog.mindcont.com/2016/07/16/installing-opencv-2-4-9-in-ubuntu-14-04-lts/"/>
    <id>http://blog.mindcont.com/2016/07/16/installing-opencv-2-4-9-in-ubuntu-14-04-lts/</id>
    <published>2016-07-16T07:27:45.000Z</published>
    <updated>2016-08-22T08:11:15.055Z</updated>
    
    <content type="html">&lt;p&gt;OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式识别程序。该程序库也可以使用英特尔公司的IPP进行加速处理。&lt;br&gt;在本指南中，我将告诉你如何在ubuntu14.04(lts)中安装OpenCV。ok,让我们开始吧～&lt;/p&gt;
&lt;h2 id=&quot;更新源&quot;&gt;&lt;a href=&quot;#更新源&quot; class=&quot;headerlink&quot; title=&quot;更新源&quot;&gt;&lt;/a&gt;更新源&lt;/h2&gt;&lt;p&gt;首先将源更新为阿里云源&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak         &lt;span class=&quot;comment&quot;&gt;#备份&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo gedit /etc/apt/sources.list                                &lt;span class=&quot;comment&quot;&gt;#修改&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;##添加如下内容，点击保存后关闭文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;##更新系统&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get upgrade&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载依赖环境&quot;&gt;&lt;a href=&quot;#下载依赖环境&quot; class=&quot;headerlink&quot; title=&quot;下载依赖环境&quot;&gt;&lt;/a&gt;下载依赖环境&lt;/h2&gt;&lt;p&gt;现在，你需要安装很多相关性，比如支持读取和写入图像文件，在屏幕上绘制，一些必要的工具，其他图书馆，等等…这一步是很容易的，你只需要在终端上写下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install build-essential libgtk2.0-dev libjpeg-dev libtiff4-dev libjasper-dev libopenexr-dev cmake python-dev python-numpy python-tk libtbb-dev libeigen3-dev yasm libfaac-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev libx264-dev libqt4-dev libqt4-opengl-dev sphinx-common texlive-latex-extra libv4l-dev libdc1394-22-dev libavcodec-dev libavformat-dev libswscale-dev default-jdk ant libvtk5-qt4-dev&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载OpenCV&quot;&gt;&lt;a href=&quot;#下载OpenCV&quot; class=&quot;headerlink&quot; title=&quot;下载OpenCV&quot;&gt;&lt;/a&gt;下载OpenCV&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#切换到家目录&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; ~ &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#使用wget下载 Opencv-2.4.9&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.9/opencv-2.4.9.zip   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#解压          &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;unzip opencv-2.4.9.zip      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#转到解压目录    &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; opencv-2.4.9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;编译&quot;&gt;&lt;a href=&quot;#编译&quot; class=&quot;headerlink&quot; title=&quot;编译&quot;&gt;&lt;/a&gt;编译&lt;/h2&gt;&lt;p&gt;现在我们通过使用cmake生成Makefile文件。在这里我们可以定义我们要编译OpenCV的哪个部位。既然我们要使用的即模块，Python和Java的，TBB时，OpenGL，QT，与视频接口的调用等等，这里是我们需要来设置。而就在终端执行以下命令行来创建相应的Makefile文件。请注意，有在该行的最后两个点，它是为cmake的程序参数，这意味着父目录（因为我们是build目录里面，我们要参考OpenCV的目录，这是它的父目录）。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#创建编译目录&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mkdir build &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#转到编译目录下    &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; build  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#设置编译参数          &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cmake -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D WITH_VTK=ON -D CUDA_GENERATION=Auto ..&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;检查上面的命令不会产生错误，并且特别是报告FFMPEG为YES。如果不是这种情况下，你将无法读取或写入视频。检查使用Java，Python，TBB，OpenGL的，V4L，OpenGL和Qt的都正确检测。&lt;br&gt;&lt;img src=&quot;/images/OpenCV/cmake1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;确保你向上滚动，并检查了将要构建的模块是这些：core flann imgproc highgui features2d calib3d ml video legacy objdetect photo gpu ocl nonfree contrib java python stitching superres ts videostab viz.&lt;br&gt;&lt;img src=&quot;/images/OpenCV/cmake2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;好，万事俱备，开始编译OpenCV-2.4.9。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;make&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo make install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果这里报如下错误的话&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Building NVCC (Device) &lt;span class=&quot;selector-tag&quot;&gt;object&lt;/span&gt; modules/core/CMakeFiles/cuda_compile.dir/src/cuda/Debug/cuda_compile_generated_gpu_mat&lt;span class=&quot;selector-class&quot;&gt;.cu&lt;/span&gt;&lt;span class=&quot;selector-class&quot;&gt;.obj&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;nvcc fatal : Unsupported gpu architecture &lt;span class=&quot;string&quot;&gt;&#39;compute_11&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 你需要用这个参数 &lt;strong&gt;CUDA_GENERATION&lt;/strong&gt; 来指定GPU显卡的架构，例如你的显卡是 Titan显卡（包括GTX 900系列）的架构是比较新的Maxwell架构，应该在cmake 参数命令中增加 ‘-D CUDA_GENERATION=Kepler’ 虽然Kepler架构是Maxwell架构的上一代，但是这样配置也可以成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;中途可能会报错&lt;br&gt;&lt;figure class=&quot;highlight vbnet&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;opencv&lt;span class=&quot;number&quot;&gt;-2.4&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.9&lt;/span&gt;/modules/gpu/src/nvidia/core/NCVPixelOperations.hpp(&lt;span class=&quot;number&quot;&gt;51&lt;/span&gt;): &lt;span class=&quot;keyword&quot;&gt;error&lt;/span&gt;: a storage &lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; allowed &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; an &lt;span class=&quot;keyword&quot;&gt;explicit&lt;/span&gt; specialization&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;解决方法在此：&lt;a href=&quot;http://code.opencv.org/issues/3814&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://code.opencv.org/issues/3814&lt;/a&gt;  下载 &lt;a href=&quot;http://code.opencv.org/projects/opencv/repository/revisions/feb74b125d7923c0bc11054b66863e1e9f753141/raw/modules/gpu/src/nvidia/core/NCVPixelOperations.hpp&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NCVPixelOperations.hpp&lt;/a&gt; 替换掉opencv2.4.9内’/modules/gpu/src/nvidia/core/‘下重名文件， 重新build。&lt;/p&gt;
&lt;h2 id=&quot;配置环境变量&quot;&gt;&lt;a href=&quot;#配置环境变量&quot; class=&quot;headerlink&quot; title=&quot;配置环境变量&quot;&gt;&lt;/a&gt;配置环境变量&lt;/h2&gt;&lt;p&gt;配置OpenCV库引用(类似于windows环境变量)&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo gedit /etc/ld.so.conf.d/opencv.conf&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;添加下面一行在文件末尾（它可能是一个空文件，这是确定的），然后将其保存：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/lib&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/opencv-conf.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入下面的命令使其生效&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo ldconfig&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在打开另一个文件&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo gedit /etc/bash.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;添加这两行的文件的末尾并保存：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;PKG_CONFIG_PATH=&lt;span class=&quot;variable&quot;&gt;$PKG_CONFIG_PATH&lt;/span&gt;:/usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/lib/pkgconfig&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PKG_CONFIG_PATH&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/bashrc.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt; 关闭控制台，打开一个新的终端，或者重新启动计算机或注销，然后重新登录。不然OpenCV将无法正常工作。现在你有OpenCV的2.4.9安装在您的计算机三维可视化，Python和Java的，TBB，OpenGL的，视频和Qt支持。&lt;/p&gt;
&lt;h2 id=&quot;运行Demo&quot;&gt;&lt;a href=&quot;#运行Demo&quot; class=&quot;headerlink&quot; title=&quot;运行Demo&quot;&gt;&lt;/a&gt;运行Demo&lt;/h2&gt;&lt;p&gt;现在，让我们来编译运行OpenCV包中的一些例子，输入下面的命令&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; ~/opencv-2.4.9/samples/c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;chmod +x build_all.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;./build_all.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这些例子使用了旧版本的 C 接口，&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;./facedetect --cascade=&lt;span class=&quot;string&quot;&gt;&quot;/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml&quot;&lt;/span&gt; --nested-cascade=&lt;span class=&quot;string&quot;&gt;&quot;/usr/local/share/OpenCV/haarcascades/haarcascade_eye.xml&quot;&lt;/span&gt; --scale=1.5 lena.jpg&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/demo1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;鼠标滚轮滑动，可以直接看到图像像素对应的RGB数值。&lt;br&gt;&lt;img src=&quot;/images/OpenCV/QT-tools.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;再运行一个例子，输入下面的指令&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;~/opencv-2.4.9/build/bin/cpp-example-calibration_artific&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/demo2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考&quot;&gt;&lt;/a&gt;参考&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Installing OpenCV 2.4.9 in Ubuntu 14.04 LTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/xzd1575/p/5555523.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu下多个版本OpenCV管理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式
    
    </summary>
    
    
      <category term="OpenCV" scheme="http://blog.mindcont.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 14.04 安装 Nvidia 私有驱动并进行双显卡切换</title>
    <link href="http://blog.mindcont.com/2016/07/15/ubuntu1404-nvidia-graphics-driver/"/>
    <id>http://blog.mindcont.com/2016/07/15/ubuntu1404-nvidia-graphics-driver/</id>
    <published>2016-07-15T07:55:36.000Z</published>
    <updated>2016-07-20T08:13:04.830Z</updated>
    
    <content type="html">&lt;p&gt;笔者最近弄Caffe不小心有把nvidia显卡驱动弄坏了，现在将ubuntu14.04 双显卡切换记录如下。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;硬件&lt;/td&gt;
&lt;td&gt;GeForce GT640M&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;系统版本&lt;/td&gt;
&lt;td&gt;3.13.0-37-generic #64-Ubuntu x86_64 GNU/Linux&lt;/td&gt;
&lt;td&gt;输入&lt;code&gt;uname -a&lt;/code&gt;查看&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;首先 彻底卸载原有Nvidia驱动&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get purge nvidia*&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;清理无关项&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get autoremove&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;使用如下命令添加Graphic Drivers PPA&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo add-apt-repository ppa:graphics-drivers/ppa&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo add-apt-repository ppa:nilarimogard/webupd8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;安装特定版本的nvidia 专有驱动和设置工具&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install nvidia-340 nvidia-settings nvidia-prime prime-indicator&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;重启,同windows一样，驱动需要重启后生效。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo reboot&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/ubuntu/nvidia_success.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;笔者最近弄Caffe不小心有把nvidia显卡驱动弄坏了，现在将ubuntu14.04 双显卡切换记录如下。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;

    
    </summary>
    
      <category term="Linux" scheme="http://blog.mindcont.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Houston, we have a problem</title>
    <link href="http://blog.mindcont.com/2016/06/29/Website-under-attack/"/>
    <id>http://blog.mindcont.com/2016/06/29/Website-under-attack/</id>
    <published>2016-06-29T08:13:22.000Z</published>
    <updated>2016-06-29T08:54:18.380Z</updated>
    
    <content type="html">&lt;p&gt;今天登录网站服务器，本来想看看硬盘存储空间被日志占用的还剩多少，谁知打开nginx的access.log 文件，发现15万9千条来自俄罗斯 ‘195.2.252.223’’195.2.252.67’’195.88.208.232’这3个IP地址利用 xmlrpc.php文件 POST数据，持续时间 从2016年6月6号到7号，初步确定想利用WordPress 的xmlrpc.php 漏洞 POST 用户名和密码来暴力破解。&lt;/p&gt;
&lt;p&gt;部分记录如下:&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:40:53 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:53 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:53 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.88.208.232 - - [06/Jun/2016:03:40:53 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:40:54 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:54 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:55 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:40:56 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:40:56 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:57 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:57 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:40:58 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:58 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:58 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:58 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:59 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.88.208.232 - - [06/Jun/2016:03:40:59 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:40:59 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:41:00 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:41:00 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:41:00 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:41:00 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:41:01 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.223 - - [06/Jun/2016:03:41:01 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:41:03 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;195.2.252.67 - - [06/Jun/2016:03:41:03 -0400] &lt;span class=&quot;string&quot;&gt;&quot;POST /xmlrpc.php HTTP/1.0&quot;&lt;/span&gt; 499 0 &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;Mozilla/4.0 (compatible: MSIE 7.0; Windows NT 6.0)&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;解决办法&quot;&gt;&lt;a href=&quot;#解决办法&quot; class=&quot;headerlink&quot; title=&quot;解决办法&quot;&gt;&lt;/a&gt;解决办法&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;删除xmlrpc.php或重命名为xmlrpc.php.backup&lt;/li&gt;
&lt;li&gt;设置其权限为不可访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;暴力猜解攻击是我们至今为止在互联网上看到的最古老而常见的攻击之一。黑客可以通过SSH和FTP协议，暴力猜解攻击你的WEB服务器。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;传统暴力猜解攻击&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  这些攻击一般都不是很复杂，而且理论上是比较容易遏制的。但是，它们仍然拥有存在的价值，因为人们并不习惯采用强密码，而且不是每个人都拥有良好的登录习惯。&lt;/p&gt;
&lt;p&gt;  然而可惜的是，暴力猜解攻击有个致命的弱点。通常来说，如果黑客需要尝试500个不同的密码，他将尝试发送500次不同的请求到服务器上。通过限制登录次数，可以在一定层面上遏制暴力猜解攻击。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;放大型暴力猜解攻击&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  黑客可以减少攻击次数么，他们能否一次请求，就能进行多次登陆尝试？请想象一下，如果你一次攻击请求能尝试500个密码，那么登录次数限制神马的，不都是战斗力5的渣渣了？&lt;/p&gt;
&lt;p&gt;  这种手法有点类似于咱们以前的DDoS放大攻击，一个核心指挥服务器，能够利用DNS或者NTP协议回应进行放大攻击，增加原本攻击强度50-100倍。无论是任何类型的放大型攻击，都将让黑客倍加受益。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过Wordpress XML-RPC进行暴力猜解放大攻击&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  XML-RPC的隐藏特性之一，则是你可以使用system.multicall方法，在单个请求中进行多次尝试，这是非常有用的。它允许应用程序通过一条HTTP请求，执行多个命令。&lt;/p&gt;
&lt;p&gt;  &lt;strong&gt;XML-RPC是一个通过HTTP方法进行远程调用的，非常简单易用的玩意儿。它支持Perl、Java、Python、C、C++、PHP，以及许多其他编程语言。&lt;/strong&gt;Wordpress和Drupal，以及许多其他内容管理系统都支持XML-RPC。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，&lt;strong&gt;任何好的技术都是双刃剑。&lt;/strong&gt;在XML-RPC技术被普通程序开发者所喜爱的同时，也成了黑客手中的利器。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;背景来源：SU、TA，编译/dawner，转载请注明来自FreeBuf黑客与极客（FreeBuf.COM）&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;今天登录网站服务器，本来想看看硬盘存储空间被日志占用的还剩多少，谁知打开nginx的access.log 文件，发现15万9千条来自俄罗斯 ‘195.2.252.223’’195.2.252.67’’195.88.208.232’这3个IP地址利用 xmlrpc.php文件
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>中间件技术</title>
    <link href="http://blog.mindcont.com/2016/06/27/Middleware-Technology/"/>
    <id>http://blog.mindcont.com/2016/06/27/Middleware-Technology/</id>
    <published>2016-06-27T04:25:33.000Z</published>
    <updated>2016-06-27T06:58:18.352Z</updated>
    
    <content type="html">&lt;p&gt;最早具有中间件技术思想及功能的软件是IBM60年代开发的CICS（Customer Information Control System）。80年代初期，Sun Microsystems开发了一种最早的中间件，座位其开发网络体系结构的一部分，这种中间件是基于RPC协议的，但由于CICS不是分布式环境的产物，而Sun Microsystems开发的不是完整的中间件产品，因此人们一般把Tuxedo座位第一个严格意义上的中间件产品，Tuxedo作为第一个严格意义上的中间件产品，Tuxedo是在1984年由AT&amp;amp;T的贝尔实验室开发完成的。到90年代，中间件技术得到了巨大的发展和广泛的应用，出现了大量具有广泛影响的中间件产品，如OMG的Corba、Microsoft的DCOM/COM+、IBM的MQS等。&lt;/p&gt;
&lt;p&gt;中间件是基础软件，处于操作系统（或网络协议）与分布式应用之间，从而屏蔽操作系统（或网络协议）的差异，实现分布式异构系统之间的互操作。目前，对中间件还没形成一个统一的定义，比较公认的IDC的定义是：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和网络通信。&lt;/p&gt;
&lt;h2 id=&quot;分类&quot;&gt;&lt;a href=&quot;#分类&quot; class=&quot;headerlink&quot; title=&quot;分类&quot;&gt;&lt;/a&gt;分类&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;消息中间件&lt;/strong&gt;（MOM:Message-Oriented Middleware）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据库中间件&lt;/strong&gt;（Database Middleware）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;远程过程调用中间件&lt;/strong&gt;（RPC:Remote Process Call）：若一台机器的处理能力不能完成相应的计算，需要多个机器协同工作。工作中一台机器读取另一台机器的结果，这之间的数据交换需要一个标准。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对象请求代理中间件&lt;/strong&gt;（ORB：Remote Process Call）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CORBA&lt;/strong&gt;即Common Object Request Broker Architecture（公用对象请求代管者体系结构）是一种由公共管理组织（OMG)定义的一种语言无关的面向对象的模型即一种标准。CORBA程序接口包括C++和JAVA两种ORB（Object Request Broker对象请求代理）。一种ORB就是一个库，它能够使得CORBA对象与其它的ORB进行沟通与定位。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事物处理中间件&lt;/strong&gt;（TP Monitor:Transaction Process Monitor）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;J2EE中间件&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;软件开发技术的发展&quot;&gt;&lt;a href=&quot;#软件开发技术的发展&quot; class=&quot;headerlink&quot; title=&quot;软件开发技术的发展&quot;&gt;&lt;/a&gt;软件开发技术的发展&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;基于主机的系统  &lt;/li&gt;
&lt;li&gt;两层的Client/Server系统  &lt;/li&gt;
&lt;li&gt;三层(n层)体系架构(表示层、业务逻辑层、数据层)&lt;/li&gt;
&lt;li&gt;基于Web的三层(n层)体系架构  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;企业级应用的要求&quot;&gt;&lt;a href=&quot;#企业级应用的要求&quot; class=&quot;headerlink&quot; title=&quot;企业级应用的要求&quot;&gt;&lt;/a&gt;企业级应用的要求&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;分布式&lt;/li&gt;
&lt;li&gt;可移植&lt;/li&gt;
&lt;li&gt;面向Web体系&lt;/li&gt;
&lt;li&gt;满足企业计算要求 (一致性、事务性、安全性)&lt;/li&gt;
&lt;li&gt;好的特性 (可伸缩、可扩展、易维护)&lt;/li&gt;
&lt;li&gt;遗留系统集成&lt;br&gt;以上要求需要一个良好的基础架构支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;什么是J2EE&quot;&gt;&lt;a href=&quot;#什么是J2EE&quot; class=&quot;headerlink&quot; title=&quot;什么是J2EE&quot;&gt;&lt;/a&gt;什么是J2EE&lt;/h2&gt;&lt;p&gt;即Java 2 Platform,Enterprise Edition&lt;br&gt;Open and standard based platform for developing,deploying and managing n-tier,Web-enabled,server-centric,and component-based enterprise applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 运用Java技术开发企业应用的标准，包括了：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多层应用开发模型&lt;/li&gt;
&lt;li&gt;开发平台-APIs和服务&lt;/li&gt;
&lt;li&gt;测试软件包&lt;/li&gt;
&lt;li&gt;参考实现&lt;/li&gt;
&lt;li&gt;将所有企业技术集合在一个体系结构下的平台&lt;/li&gt;
&lt;li&gt;特定版本下的EJB,Servlet,JSP&lt;/li&gt;
&lt;li&gt;Java Web Server&lt;/li&gt;
&lt;li&gt;JNDI，JDBC，JTA，JMS，JavaMail，CORBA……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/hibernate/j2ee.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;J2EE可以为开发者和用户带来:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更短的开发时间(可重用的组件、JSP、EJB)&lt;/li&gt;
&lt;li&gt;自由的选择(基于开放的标准)&lt;/li&gt;
&lt;li&gt;简化的连接(XML JDBC RMI-IIOP Web-Service)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;J2EE技术架构&quot;&gt;&lt;a href=&quot;#J2EE技术架构&quot; class=&quot;headerlink&quot; title=&quot;J2EE技术架构&quot;&gt;&lt;/a&gt;J2EE技术架构&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/hibernate/j2ee_1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/hibernate/j2ee_2.png&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
&lt;h3 id=&quot;J2EE-主要技术概览&quot;&gt;&lt;a href=&quot;#J2EE-主要技术概览&quot; class=&quot;headerlink&quot; title=&quot;J2EE 主要技术概览&quot;&gt;&lt;/a&gt;J2EE 主要技术概览&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;展示层-Servlet/JSP&lt;/li&gt;
&lt;li&gt;中间层-EJB&lt;/li&gt;
&lt;li&gt;中间层可用的企业服务( 事务服务&lt;jta&gt;、目录服务&lt;jndi&gt;、消息服务&lt;jms&gt;、异步组件&lt;message-driven ejb=&quot;&quot;&gt;)&lt;/message-driven&gt;&lt;/jms&gt;&lt;/jndi&gt;&lt;/jta&gt;&lt;/li&gt;
&lt;li&gt;数据层-JDBC&lt;/li&gt;
&lt;li&gt;远程调用 RMI-IIOP&lt;/li&gt;
&lt;li&gt;使用现有资源-JCA&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Hibernate&quot;&gt;&lt;a href=&quot;#Hibernate&quot; class=&quot;headerlink&quot; title=&quot;Hibernate&quot;&gt;&lt;/a&gt;Hibernate&lt;/h2&gt;&lt;p&gt;Hibernate是一个&lt;strong&gt;开放源代码的对象关系映射框架&lt;/strong&gt;，它对&lt;strong&gt;JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系&lt;/strong&gt;，是一个全自动的&lt;strong&gt;orm&lt;/strong&gt;框架，hibernate可以&lt;strong&gt;自动生成SQL语句，自动执行&lt;/strong&gt;，使得Java程序员可以&lt;strong&gt;随心所欲的使用对象编程思维来操纵数据库&lt;/strong&gt;。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。&lt;/p&gt;
&lt;p&gt;POJO（Plain Ordinary Java Object）简单的Java对象，实际就是普通JavaBeans，是为了避免和EJB混淆所创造的简称。&lt;/p&gt;
&lt;p&gt;使用POJO名称是为了避免和EJB混淆起来, 而且简称比较直接. 其中有一些属性及其getter setter方法的类,没有业务逻辑，有时可以作为VO(value -object)或dto(Data Transform Object)来使用.当然,如果你有一个简单的运算属性也是可以的,但不允许有业务方法,也不能携带有connection之类的方法。&lt;/p&gt;
&lt;h3 id=&quot;Hibernate-Hello&quot;&gt;&lt;a href=&quot;#Hibernate-Hello&quot; class=&quot;headerlink&quot; title=&quot;Hibernate Hello&quot;&gt;&lt;/a&gt;Hibernate Hello&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!DOCTYPE hibernate-configuration PUBLIC &lt;span class=&quot;string&quot;&gt;&quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;session-factory name=&lt;span class=&quot;string&quot;&gt;&quot;foo&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;connection.driver_class&quot;&lt;/span&gt;&amp;gt;com.mysql.jdbc.Driver&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;connection.url&quot;&lt;/span&gt;&amp;gt;jdbc:mysql://localhost:3306/hibernate&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;connection.username&quot;&lt;/span&gt;&amp;gt;root&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;connection.password&quot;&lt;/span&gt;&amp;gt;123456&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;dialect&quot;&lt;/span&gt;&amp;gt;org.hibernate.dialect.MySQL5Dialect&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;show_sql&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hbm2ddl.atuo&quot;&lt;/span&gt;&amp;gt;update&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;mapping resource=&lt;span class=&quot;string&quot;&gt;&quot;edu/dldx/hibernate/model/User.hbm.xml&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;!--&amp;lt;class-cache class=&lt;span class=&quot;string&quot;&gt;&quot;org.hibernate.test.legacy.Simple&quot;&lt;/span&gt; region=&lt;span class=&quot;string&quot;&gt;&quot;Simple&quot;&lt;/span&gt; usage=&lt;span class=&quot;string&quot;&gt;&quot;read-write&quot;&lt;/span&gt;/&amp;gt; --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/session-factory&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;?xml version=&lt;span class=&quot;string&quot;&gt;&quot;1.0&quot;&lt;/span&gt;?&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!DOCTYPE hibernate-mapping PUBLIC &lt;span class=&quot;string&quot;&gt;&quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&quot;http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt; table=&lt;span class=&quot;string&quot;&gt;&quot;t_user&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;column name=&lt;span class=&quot;string&quot;&gt;&quot;u_id&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;native&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt; column=&lt;span class=&quot;string&quot;&gt;&quot;u_name&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;Hibernate的CDRU&quot;&gt;&lt;a href=&quot;#Hibernate的CDRU&quot; class=&quot;headerlink&quot; title=&quot;Hibernate的CDRU&quot;&gt;&lt;/a&gt;Hibernate的CDRU&lt;/h3&gt;&lt;p&gt;(1)映射文件&lt;br&gt;(2)注解&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;public class HibernateUtil &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	private static final SessionFactory sf;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	static &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;dddd&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Configuration config = new Configuration().configure();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		ServiceRegistry sr = new StandardServiceRegistryBuilder()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				.applySettings(config.getProperties()).build();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		sf = config.buildSessionFactory(sr);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public static SessionFactory &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;title&quot;&gt;getSessionFactory&lt;/span&gt;&lt;/span&gt;()&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;built_in&quot;&gt;return&lt;/span&gt; sf;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hibernate-的OID&quot;&gt;&lt;a href=&quot;#Hibernate-的OID&quot; class=&quot;headerlink&quot; title=&quot;Hibernate 的OID&quot;&gt;&lt;/a&gt;Hibernate 的OID&lt;/h3&gt;&lt;h3 id=&quot;Hibernate-OID的生成策略&quot;&gt;&lt;a href=&quot;#Hibernate-OID的生成策略&quot; class=&quot;headerlink&quot; title=&quot;Hibernate OID的生成策略&quot;&gt;&lt;/a&gt;Hibernate OID的生成策略&lt;/h3&gt;&lt;p&gt;业务主键和代理主键  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1) native：根据底层数据库对自动生成标识符的支持能力，自动选择用，increment，identity，sequcence    &lt;/li&gt;
&lt;li&gt;(2) increment：hibernate的自增长方式     &lt;/li&gt;
&lt;li&gt;(3) identity：底层数据库生成    &lt;/li&gt;
&lt;li&gt;(4) sequcence：由hibernate根据底层数据库的序列自动生成，适用代理主键    &lt;/li&gt;
&lt;li&gt;(5) hilo：hibernate根据hight/low算法来生成标识符，适用代理主键    &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;一对多的映射关系&quot;&gt;&lt;a href=&quot;#一对多的映射关系&quot; class=&quot;headerlink&quot; title=&quot;一对多的映射关系&quot;&gt;&lt;/a&gt;一对多的映射关系&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;many-to-one name=&lt;span class=&quot;string&quot;&gt;&quot;类的成员变量名&quot;&lt;/span&gt; class=&lt;span class=&quot;string&quot;&gt;&quot;类名&quot;&lt;/span&gt; column=&lt;span class=&quot;string&quot;&gt;&quot;数据表中外键字段名&quot;&lt;/span&gt;/&amp;gt;   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cascade=&lt;span class=&quot;string&quot;&gt;&quot;save-update&quot;&lt;/span&gt;  级联保存，自动保存一的那一端。默认为none&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;Junit-Test&quot;&gt;&lt;a href=&quot;#Junit-Test&quot; class=&quot;headerlink&quot; title=&quot;Junit Test&quot;&gt;&lt;/a&gt;Junit Test&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;@BeforeClass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//类初始化前调用&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public static void &lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt;UpBeforeClass() throws Exception &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	@AfterClass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//类初始化后调用&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public static void tearDownAfterClass() throws Exception &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	@Before&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//测试方法前使用&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public void &lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt;Up() throws Exception &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	@After&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;//测试方法后使用&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public void tearDown() throws Exception &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;多对一的映射关系&quot;&gt;&lt;a href=&quot;#多对一的映射关系&quot; class=&quot;headerlink&quot; title=&quot;多对一的映射关系&quot;&gt;&lt;/a&gt;多对一的映射关系&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt; name=&lt;span class=&quot;string&quot;&gt;&quot;多的成员变量名&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;key column=&lt;span class=&quot;string&quot;&gt;&quot;关联的外键名称(数据库表里的)&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;lt;one-to-many class=&lt;span class=&quot;string&quot;&gt;&quot;一那一端的类的名称&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;inverse属性，查出一个没有关联的，然后set的时候&lt;br&gt;级联删除&lt;br&gt;自身一对多&lt;/p&gt;
&lt;h3 id=&quot;hibernate中四中对象状态&quot;&gt;&lt;a href=&quot;#hibernate中四中对象状态&quot; class=&quot;headerlink&quot; title=&quot;hibernate中四中对象状态&quot;&gt;&lt;/a&gt;hibernate中四中对象状态&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;(1)、临时（瞬态）状态 transient:刚用new语句创建，还没有被持久化，并且不处于session的缓存中。&lt;/li&gt;
&lt;li&gt;(2)、持久化状态 persistent:已经被持久化，并且加入到session的缓存中。&lt;/li&gt;
&lt;li&gt;(3)、删除状态 removed:不再处于session的缓存中，并且session已经计划将其从数据库中删除。&lt;/li&gt;
&lt;li&gt;(4)、游离状态 detached:已经被持久化，但不再处于session的缓存中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;一对一的映射关系&quot;&gt;&lt;a href=&quot;#一对一的映射关系&quot; class=&quot;headerlink&quot; title=&quot;一对一的映射关系&quot;&gt;&lt;/a&gt;一对一的映射关系&lt;/h3&gt;&lt;p&gt;（1）一对一主键关联&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;column name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;assigned&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;one-to-one name=&lt;span class=&quot;string&quot;&gt;&quot;card&quot;&lt;/span&gt; class=&lt;span class=&quot;string&quot;&gt;&quot;IdCard&quot;&lt;/span&gt; cascade=&lt;span class=&quot;string&quot;&gt;&quot;all&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;IdCard&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;num&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;column name=&lt;span class=&quot;string&quot;&gt;&quot;num&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;foreign&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				&amp;lt;param name=&lt;span class=&quot;string&quot;&gt;&quot;property&quot;&lt;/span&gt;&amp;gt;user&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;/generator&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;address&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;expiryDate&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;one-to-one name=&lt;span class=&quot;string&quot;&gt;&quot;user&quot;&lt;/span&gt; class=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt; constrained=&lt;span class=&quot;string&quot;&gt;&quot;true&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）一对一外键关联&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;assigned&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;many-to-one name=&lt;span class=&quot;string&quot;&gt;&quot;card&quot;&lt;/span&gt; class=&lt;span class=&quot;string&quot;&gt;&quot;IdCard&quot;&lt;/span&gt; cascade=&lt;span class=&quot;string&quot;&gt;&quot;all&quot;&lt;/span&gt; unique=&lt;span class=&quot;string&quot;&gt;&quot;true&quot;&lt;/span&gt; column=&lt;span class=&quot;string&quot;&gt;&quot;cardNum&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;IdCard&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;num&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;assigned&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;address&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;expiryDate&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;one-to-one name=&lt;span class=&quot;string&quot;&gt;&quot;user&quot;&lt;/span&gt; class=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt; property-ref=&lt;span class=&quot;string&quot;&gt;&quot;card&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;多对多&quot;&gt;&lt;a href=&quot;#多对多&quot; class=&quot;headerlink&quot; title=&quot;多对多&quot;&gt;&lt;/a&gt;多对多&lt;/h3&gt;&lt;p&gt;（1）多对多单项关联&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;Role&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;native&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;hibernate-mapping package=&lt;span class=&quot;string&quot;&gt;&quot;edu.dldx.hibernate.model&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;native&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt; name=&lt;span class=&quot;string&quot;&gt;&quot;roles&quot;&lt;/span&gt; table=&lt;span class=&quot;string&quot;&gt;&quot;user_role&quot;&lt;/span&gt; cascade=&lt;span class=&quot;string&quot;&gt;&quot;save-update&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;key column=&lt;span class=&quot;string&quot;&gt;&quot;userId&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;many-to-many class=&lt;span class=&quot;string&quot;&gt;&quot;Role&quot;&lt;/span&gt; column=&lt;span class=&quot;string&quot;&gt;&quot;roleId&quot;&lt;/span&gt;&amp;gt;&amp;lt;/many-to-many&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/hibernate-mapping&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;（2）多对多双向关联&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;class name=&lt;span class=&quot;string&quot;&gt;&quot;Role&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;id name=&lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;generator class=&lt;span class=&quot;string&quot;&gt;&quot;native&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/id&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt; name=&lt;span class=&quot;string&quot;&gt;&quot;users&quot;&lt;/span&gt; table=&lt;span class=&quot;string&quot;&gt;&quot;user_role&quot;&lt;/span&gt; inverse=&lt;span class=&quot;string&quot;&gt;&quot;true&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;key column=&lt;span class=&quot;string&quot;&gt;&quot;roleId&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&amp;lt;many-to-many class=&lt;span class=&quot;string&quot;&gt;&quot;User&quot;&lt;/span&gt; column=&lt;span class=&quot;string&quot;&gt;&quot;userId&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;/&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/class&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;数据库连接池&quot;&gt;&lt;a href=&quot;#数据库连接池&quot; class=&quot;headerlink&quot; title=&quot;数据库连接池&quot;&gt;&lt;/a&gt;数据库连接池&lt;/h3&gt;&lt;p&gt;访问数据库，需要不断的创建和释放连接，假如访问量大的话，效率比较低，服务器消耗大；使用连接池，可以根据实际项目的情况，定义连接池的连接个数，从而可以实现从连接池获取连接，用完放回到连接池。从而有效的提高系统的执行效率。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 指定连接池里的最大连接数 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.c3p0.maxsize&quot;&lt;/span&gt;&amp;gt;20&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 指定连接池里最小连接数 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.minsize&quot;&lt;/span&gt;&amp;gt;1&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 指定连接池里的超时时常 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.timeout&quot;&lt;/span&gt;&amp;gt;5000&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 指定连接池里最大缓存多少个Statement对象 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.max_statements&quot;&lt;/span&gt;&amp;gt;100&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 多少时间间隔去检测是否有需要利用timeout得情况发生 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.idle_test_period&quot;&lt;/span&gt;&amp;gt;3000&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.acquire_increment&quot;&lt;/span&gt;&amp;gt;2&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;hibernate.cp30.validate&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;阿里巴巴开发的德鲁伊（Druid）连接池，能够提供强大的监控和扩展功能&lt;br&gt;&lt;a href=&quot;https://github.com/alibaba/druid/wiki/常见问题&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/alibaba/druid/wiki/常见问题&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;log4j-日志处理&quot;&gt;&lt;a href=&quot;#log4j-日志处理&quot; class=&quot;headerlink&quot; title=&quot;log4j 日志处理&quot;&gt;&lt;/a&gt;log4j 日志处理&lt;/h3&gt;&lt;p&gt;Log4j是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件，甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt;4j.rootCategory=INFO, stdout , R&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;此句为将等级为INFO的日志信息输出到stdout和R这两个目的地，stdout和R的定义在下面的代码，可以任意起名。等级可分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL，如果配置OFF则不打出任何信息，如果配置为INFO这样只显示INFO、WARN、ERROR的log信息，而DEBUG信息不会被显示，具体讲解可参照第三部分定义配置文件中的logger。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt;4j.appender.stdout=org.apache.log4j.ConsoleAppender&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;此句为定义名为stdout的输出端是哪种类型，可以是:&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.ConsoleAppender（控制台），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.FileAppender（文件），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt;4j.appender.stdout.layout=org.apache.log4j.PatternLayout&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;此句为定义名为stdout的输出端的layout是哪种类型，可以是:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.HTMLLayout（以HTML表格形式布局），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.PatternLayout（可以灵活地指定布局模式），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;%m 输出代码中指定的消息；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%M 输出打印该条日志的方法名；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%r 输出自应用启动到输出该&lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt;信息耗费的毫秒数；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%c 输出所属的类目，通常就是所在类的全名；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%t 输出产生该日志事件的线程名；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%n 输出一个回车换行符，Windows平台为&lt;span class=&quot;string&quot;&gt;&quot;rn”，Unix平台为&quot;&lt;/span&gt;n”；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&amp;#123;yyyy-MM-dd HH:mm:ss,SSS&amp;#125;，输出类似：2002-10-18 22:10:28,921；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;%l 输出日志事件的发生位置，及在代码中的行数；&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;二级缓存&quot;&gt;&lt;a href=&quot;#二级缓存&quot; class=&quot;headerlink&quot; title=&quot;二级缓存&quot;&gt;&lt;/a&gt;二级缓存&lt;/h3&gt;&lt;p&gt;缓存是介于物理数据源于应用程序之间，是对数据库中的数据复制一份临时放在内存或者硬盘中的容器，其作用是为了减少应用程序对物理数据源的访问次数，从而提高了应用程序的运行性能。Hibernate再进行读取数据的时候，更具缓存机制在相应的缓存中查询，如果在缓存中找到了需要的数据，则就直接把找到的数据作为结果加以利用，避免了大量发送SQL语句到数据库查询的性能损耗。&lt;/p&gt;
&lt;h4 id=&quot;Session缓存&quot;&gt;&lt;a href=&quot;#Session缓存&quot; class=&quot;headerlink&quot; title=&quot;Session缓存&quot;&gt;&lt;/a&gt;Session缓存&lt;/h4&gt;&lt;h4 id=&quot;SessionFactory缓存（应用缓存），需要第三方支持&quot;&gt;&lt;a href=&quot;#SessionFactory缓存（应用缓存），需要第三方支持&quot; class=&quot;headerlink&quot; title=&quot;SessionFactory缓存（应用缓存），需要第三方支持&quot;&gt;&lt;/a&gt;SessionFactory缓存（应用缓存），需要第三方支持&lt;/h4&gt;&lt;p&gt;EHCache,OSCache,SwarmCache,jBossCache2&lt;/p&gt;
&lt;h4 id=&quot;什么数据适合放置到二级缓存中：&quot;&gt;&lt;a href=&quot;#什么数据适合放置到二级缓存中：&quot; class=&quot;headerlink&quot; title=&quot;什么数据适合放置到二级缓存中：&quot;&gt;&lt;/a&gt;什么数据适合放置到二级缓存中：&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;经常访问&lt;/li&gt;
&lt;li&gt;改动不大&lt;/li&gt;
&lt;li&gt;数量有限&lt;/li&gt;
&lt;li&gt;不是很重要的数据，允许出现偶尔并发的数据    &lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 启用二级缓存 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;cache.use_second_level_cache&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 启用查询缓存 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;cache.use_query_cache&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;!-- 二级缓存所使用的产品 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property name=&lt;span class=&quot;string&quot;&gt;&quot;cache.region.factory_class&quot;&lt;/span&gt;&amp;gt;org.hibernate.cache.ehcache.EhCacheRegionFactory&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;cache usage=&lt;span class=&quot;string&quot;&gt;&quot;read-only&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;最早具有中间件技术思想及功能的软件是IBM60年代开发的CICS（Customer Information Control System）。80年代初期，Sun Microsystems开发了一种最早的中间件，座位其开发网络体系结构的一部分，这种中间件是基于RPC协议的，但
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>电视剧《长征》观后感</title>
    <link href="http://blog.mindcont.com/2016/06/21/The-Long-March/"/>
    <id>http://blog.mindcont.com/2016/06/21/The-Long-March/</id>
    <published>2016-06-21T10:49:49.000Z</published>
    <updated>2016-06-21T11:49:41.707Z</updated>
    
    <content type="html">&lt;p&gt;背景：第五次反围剿失败，博古、李德失去了中央红军的控制力，在遵义会议后确定了周恩来、毛泽东同志的领导。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/The-Long-March_1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;恩来&lt;/strong&gt;：刚才伯承同志向政治局报告了有关的敌情，这说明敌人的主力虽然被我们吸引到了川滇黔边境，但是尚未构成包围之势，所以在这个紧要关头，请政治局讨论，决定我们红军下一步的行动方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;伯承&lt;/strong&gt;：我们可否从敌人的动态当中得出这样的结论，我们原计划从扎西揮戈北进，出其不意的北渡长江的计划变成不可能了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;朱德&lt;/strong&gt;：那恐怕不行，不仅不能实现北渡长江的计划，如果我们在扎西再滞留几天的话，那就又回到以前被动挨打的局面上去啦&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;泽东&lt;/strong&gt;：我的方案很简单，十二个字，挥师东进，再渡赤水，重占遵义。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;伯承&lt;/strong&gt;：再渡赤水，为什么，有这个必要吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;恩来&lt;/strong&gt;：我看，还是请泽东同志详细的讲一讲，他提出的挥师东进，再渡赤水，重占遵义的方案吧&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;泽东&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一 敌人的主力，已经被我们调到了川、滇、黔三省交界处，&lt;strong&gt;现在赤水河以东的黔北已经成为敌人最薄弱的地区&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;第二 我们可以利用敌人的错觉，以为红军要北渡长江，实际上我们突然挥师东进杀个回马枪，&lt;strong&gt;从不利的战局中寻找有利的因素，变被动为主动&lt;/strong&gt;。换句话说 我们可以从消极避战变成主动调动敌人&lt;/li&gt;
&lt;li&gt;第三 在主动调敌的过程中，我们应该寻找有利战机，&lt;strong&gt;集中优势兵力发扬我军”运动战”的特长&lt;/strong&gt;，去主动消灭敌人&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;来大家看，这里是遵义，这是娄山关 我们二渡赤水抢占娄山关之后，进逼遵义…..&lt;/p&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-video-camera&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;  &lt;a href=&quot;http://v.youku.com/v_show/id_XMTE0MjQwNzM2.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://v.youku.com/v_show/id_XMTE0MjQwNzM2.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;附：长征路线图&quot;&gt;&lt;a href=&quot;#附：长征路线图&quot; class=&quot;headerlink&quot; title=&quot;附：长征路线图&quot;&gt;&lt;/a&gt;附：长征路线图&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/The-Long-March_2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;背景：第五次反围剿失败，博古、李德失去了中央红军的控制力，在遵义会议后确定了周恩来、毛泽东同志的领导。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/The-Long-March_1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;恩来&lt;/strong&gt;：刚才伯承同志向
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>CCTV9记录-《高考》</title>
    <link href="http://blog.mindcont.com/2016/06/06/Chinese-college-entrance-examination/"/>
    <id>http://blog.mindcont.com/2016/06/06/Chinese-college-entrance-examination/</id>
    <published>2016-06-06T11:30:48.000Z</published>
    <updated>2016-06-07T09:01:14.522Z</updated>
    
    <content type="html">&lt;p&gt;高考，一场影响亿万中国人命运的考试。六集纪录片《高考》选取深具代­表性的不同社会横断面，记录个人故事、观照社会热点，从多个侧面走近并记录2014年­高考，为我们留下这个时代意味深长的社会现实记忆。&lt;/p&gt;
&lt;p&gt;第一集 ：毛坦厂的日与夜(上)&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=1&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;

&lt;p&gt;第二集 ：毛坦厂的日与夜(下)&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=2&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;

&lt;p&gt;第三集：久牵的孩子们&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=3&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;

&lt;p&gt;第四集：走出大山&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=4&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;

&lt;p&gt;第五集：留学大潮下&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=5&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;

&lt;p&gt;第六集：校长的选择&lt;/p&gt;
&lt;embed height=&quot;415&quot; width=&quot;544&quot; quality=&quot;high&quot; allowfullscreen=&quot;true&quot; type=&quot;application/x-shockwave-flash&quot; src=&quot;http://static.hdslb.com/miniloader.swf&quot; flashvars=&quot;aid=3584431&amp;page=6&quot; pluginspage=&quot;http://www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash&quot;&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;高考，一场影响亿万中国人命运的考试。六集纪录片《高考》选取深具代­表性的不同社会横断面，记录个人故事、观照社会热点，从多个侧面走近并记录2014年­高考，为我们留下这个时代意味深长的社会现实记忆。&lt;/p&gt;
&lt;p&gt;第一集 ：毛坦厂的日与夜(上)&lt;/p&gt;
&lt;embed heig
    
    </summary>
    
      <category term="随笔日记" scheme="http://blog.mindcont.com/categories/%E9%9A%8F%E7%AC%94%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>OpenCV 2.4.9 模块简介</title>
    <link href="http://blog.mindcont.com/2016/05/28/OpenCV-2-4-9-Module-Introduction/"/>
    <id>http://blog.mindcont.com/2016/05/28/OpenCV-2-4-9-Module-Introduction/</id>
    <published>2016-05-28T01:49:51.000Z</published>
    <updated>2016-08-22T08:11:01.614Z</updated>
    
    <content type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/OpenCV_Logo.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV是由英特尔公司发起并参与开发，以BSD许可证授权发行，可以在商业和研究领域中免费使用。OpenCV可用于开发实时的图像处理、计算机视觉以及模式识别程序。该程序库也可以使用英特尔公司的IPP进行加速处理。   &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;th&gt;—&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;原作者&lt;/td&gt;
&lt;td&gt;英特尔公司&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;初始版本&lt;/td&gt;
&lt;td&gt;2010年6月&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;稳定版本&lt;/td&gt;
&lt;td&gt;3.1.0（2015年12月18日，​5个月前）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;操作系统&lt;/td&gt;
&lt;td&gt;跨平台&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;类型&lt;/td&gt;
&lt;td&gt;开发库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;许可协议&lt;/td&gt;
&lt;td&gt;BSD许可证&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;网站&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;http://opencvlibrary.sourceforge.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://opencvlibrary.sourceforge.net/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;模块介绍&quot;&gt;&lt;a href=&quot;#模块介绍&quot; class=&quot;headerlink&quot; title=&quot;模块介绍&quot;&gt;&lt;/a&gt;模块介绍&lt;/h1&gt;&lt;p&gt;在此我们管中窥豹，通过opencv安装路径下include目录里面头文件的分类存放，来一窥OpenCV这些年迅猛发展起来的庞杂组件架构。  &lt;/p&gt;
&lt;p&gt;我们先进入OpenCV的安装路径，例如我的是E:\Program Files\OpenCV\OpenCV-2.4.9\build\include目录，可以看到有opencv和opencv2这两个文件夹。显然，opencv这个文件夹里面包含着旧版的头文件。而opencv2这个文件夹里面包含着具有时代意义的新版OpenCV2系列的头文件。&lt;br&gt;&lt;img src=&quot;/images/OpenCV/OpenCV-Module-1.png&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
&lt;p&gt;在opencv这个文件夹里面，也就是E:\Program Files\OpenCV\OpenCV-2.4.9\build\include\opencv目录下，可以看到如下的各种头文件。这里面大概就是opencv 1.0最核心的，而且保留下来的内容的头文件，可以把它们整体理解为一个组件。&lt;br&gt;&lt;img src=&quot;/images/OpenCV/OpenCV-Module-2.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;p&gt;再来看看我们重点关注的opencv2这边，在E:\Program Files\OpenCV\OpenCV-2.4.9\build\include\opencv2目录下，我们可以看到这些文件夹&lt;br&gt;&lt;img src=&quot;/images/OpenCV/OpenCV-Module-3.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;p&gt;我们灵机一动，发现下面有个叫opencv_modules.hpp的hpp文件，一看就知道里面存放的是opencv2中的新模块构造相关的说明代码，打开一看，果不其然，定义的是OpenCV2所有组件的宏：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/*&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; *     ** File generated automatically, do not modify **&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; *This file defines the list of modules available in current build configuration&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; *&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_CALIB3D&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_CONTRIB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_CORE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_FEATURES2D&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_FLANN&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_GPU&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_HIGHGUI&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_IMGPROC&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_LEGACY&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_ML&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_NONFREE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_OBJDETECT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_OCL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_PHOTO&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_STITCHING&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_SUPERRES&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_TS&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_VIDEO&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#define HAVE_OPENCV_VIDEOSTAB&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;下面就是OpenCV的所有模块介绍  &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块名称&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;calib3d&lt;/td&gt;
&lt;td&gt;其实就是就是Calibration（校准）加3D这两个词的组合缩写。这个模块主要是相机校准和三维重建相关的内容&lt;/td&gt;
&lt;td&gt;基本的多视角几何算法&lt;br&gt;单个立体摄像头标定&lt;br&gt;物体姿态估计&lt;br&gt;立体相似性算法&lt;br&gt;3D信息的重建等等。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;contrib&lt;/td&gt;
&lt;td&gt;也就是Contributed/Experimental Stuf的缩写， 该模块包含了一些最近添加的不太稳定的可选功能，不用去多管&lt;/td&gt;
&lt;td&gt;2.4.8里的这个模块有新型人脸识别，立体匹配，人工视网膜模型等技术。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;core&lt;/td&gt;
&lt;td&gt;核心功能模块&lt;/td&gt;
&lt;td&gt;OpenCV基本数据结构、动态数据结构、绘图函数、数组操作相关函数、辅助功能与系统函数和宏、与OpenGL的互操作。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;features2d&lt;/td&gt;
&lt;td&gt;也就是Features2D， 2D功能框架&lt;/td&gt;
&lt;td&gt;特征检测和描述&lt;br&gt;特征检测器（Feature Detectors）通用接口&lt;br&gt;描述符提取器（Descriptor Extractors）通用接口&lt;br&gt;描述符匹配器（Descriptor Matchers）通用接口&lt;br&gt;通用描述符（Generic Descriptor）匹配器通用接口&lt;br&gt;关键点绘制函数和匹配功能绘制函数。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;flann&lt;/td&gt;
&lt;td&gt;Fast Library for Approximate Nearest Neighbors，高维的近似近邻快速搜索算法库&lt;/td&gt;
&lt;td&gt;快速近似最近邻搜索、聚类。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;gpu&lt;/td&gt;
&lt;td&gt;运用GPU加速的计算机视觉模块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;highgui&lt;/td&gt;
&lt;td&gt;也就是high gui，高层GUI图形用户界面&lt;/td&gt;
&lt;td&gt;包含媒体的I / O输入输出，视频捕捉、图像和视频的编码解码、图形交互界面的接口等内容。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;imgproc&lt;/td&gt;
&lt;td&gt;Image和Processing这两个单词的缩写组合。图像处理模块&lt;/td&gt;
&lt;td&gt;线性和非线性的图像滤波、图像的几何变换、其它（Miscellaneous）图像转换、直方图相关、结构分析和形状描述、运动分析和对象跟踪、特征检测、目标检测等内容。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;legacy&lt;/td&gt;
&lt;td&gt;一些已经废弃的代码库，保留下来作为向下兼容&lt;/td&gt;
&lt;td&gt;运动分析&lt;br&gt;期望最大化&lt;br&gt;直方图&lt;br&gt;平面细分（C API）&lt;br&gt;特征检测和描述（Feature Detection and 通用描述符（Generic Descriptor Matchers）的常用接口&lt;br&gt;匹配器。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ml&lt;/td&gt;
&lt;td&gt;机器学习模块&lt;/td&gt;
&lt;td&gt;Machine Learning，基本上是统计模型和分类算法，例如：&lt;br&gt;一般贝叶斯分类器 （Normal Bayes Classifier）&lt;br&gt;K-近邻 （K-NearestNeighbors）&lt;br&gt;支持向量机 （Support Vector Machines）&lt;br&gt;决策树 （Decision Trees）&lt;br&gt;提升（Boosting）&lt;br&gt;梯度提高树（Gradient Boosted Trees）&lt;br&gt;随机树 （Random Trees）&lt;br&gt;超随机树 （Extremely randomized trees）&lt;br&gt;期望最大化 （Expectation Maximization）&lt;br&gt;神经网络 （Neural Networks）&lt;br&gt;MLData。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nonfree&lt;/td&gt;
&lt;td&gt;也就是一些具有专利的算法模块&lt;/td&gt;
&lt;td&gt;包含特征检测和GPU相关的内容。最好不要商用，可能会被告哦&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;objdetect&lt;/td&gt;
&lt;td&gt;目标检测模块&lt;/td&gt;
&lt;td&gt;包含Cascade Classification（级联分类）和Latent SVM这两个部分&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ocl&lt;/td&gt;
&lt;td&gt;运用OpenCL加速的计算机视觉组件模块&lt;/td&gt;
&lt;td&gt;即OpenCL-accelerated Computer Vision&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;photo&lt;/td&gt;
&lt;td&gt;图像修复和图像去噪&lt;/td&gt;
&lt;td&gt;Computational Photography&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;stitching&lt;/td&gt;
&lt;td&gt;图像拼接模块&lt;/td&gt;
&lt;td&gt;images stitching，拼接流水线&lt;br&gt;特点寻找和匹配图像&lt;br&gt;估计旋转&lt;br&gt;自动校准&lt;br&gt;图片歪斜&lt;br&gt;接缝估测&lt;br&gt;曝光补偿&lt;br&gt;图片混合。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;superres&lt;/td&gt;
&lt;td&gt;超分辨率技术的相关功能模块&lt;/td&gt;
&lt;td&gt;SuperResolution&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ts&lt;/td&gt;
&lt;td&gt;opencv测试相关代码&lt;/td&gt;
&lt;td&gt;不用去管他&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;video&lt;/td&gt;
&lt;td&gt;视频分析组件&lt;/td&gt;
&lt;td&gt;该模块包括运动估计，背景分离，对象跟踪等视频处理相关内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;videostab&lt;/td&gt;
&lt;td&gt;视频稳定相关的组件&lt;/td&gt;
&lt;td&gt;Video stabilization，官方文档中没有多作介绍，不管它了&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考&quot;&gt;&lt;/a&gt;参考&lt;/h1&gt;&lt;p&gt;[1] &lt;a href=&quot;http://docs.opencv.org/2.4/modules/core/doc/intro.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.opencv.org/2.4/modules/core/doc/intro.html&lt;/a&gt;&lt;br&gt;[2] [中文维基.OpenCV]&lt;a href=&quot;https://zh.wikipedia.org/wiki/OpenCV&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zh.wikipedia.org/wiki/OpenCV&lt;/a&gt;&lt;br&gt;[3] &lt;a href=&quot;http://blog.csdn.net/poem_qianmo/article/details/19925819&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/poem_qianmo/article/details/19925819&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenCV/OpenCV_Logo.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;OpenCV的全称是Open Source Computer Vision Library，是一个跨平台的计算机视觉库。OpenCV
    
    </summary>
    
    
      <category term="OpenCV" scheme="http://blog.mindcont.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>Matlab连接Kinect V2</title>
    <link href="http://blog.mindcont.com/2016/05/18/Microsoft-Kinect-V2-with-Matlab/"/>
    <id>http://blog.mindcont.com/2016/05/18/Microsoft-Kinect-V2-with-Matlab/</id>
    <published>2016-05-18T12:09:55.000Z</published>
    <updated>2016-05-18T13:44:47.228Z</updated>
    
    <content type="html">&lt;p&gt;如何让matlab支持Kinect呢？通过搜索在&lt;a href=&quot;http://cn.mathworks.com/hardware-support/kinect-windows.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mathworks 中国&lt;/a&gt;得知，只有最新版的 matlab 2016a 才支持 Kinect v2 。具体信息如下表，&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;MATLAB Release&lt;/th&gt;
&lt;th&gt;Kinect for Windows Runtime&lt;/th&gt;
&lt;th&gt;Platform&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Kinect for Windows v1&lt;/td&gt;
&lt;td&gt;R2013a and later&lt;/td&gt;
&lt;td&gt;1.6 (Installed by support package)&lt;/td&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kinect v2&lt;/td&gt;
&lt;td&gt;R2016a and later&lt;/td&gt;
&lt;td&gt;2.0 (Installed by support package)&lt;/td&gt;
&lt;td&gt;Windows 8 and later&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;获取matlab-2016a&quot;&gt;&lt;a href=&quot;#获取matlab-2016a&quot; class=&quot;headerlink&quot; title=&quot;获取matlab 2016a&quot;&gt;&lt;/a&gt;获取matlab 2016a&lt;/h1&gt;&lt;p&gt;从百度云下载 matlab2016a ,大约7.6个g。值得注意的是：从2016开始 matlab不再支持win32平台。 &lt;/p&gt;
&lt;p&gt;原版2016a 光盘镜像ISO&lt;br&gt;链接: &lt;a href=&quot;http://pan.baidu.com/s/1YOrl8&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pan.baidu.com/s/1YOrl8&lt;/a&gt; 密码: 8k7u&lt;br&gt;2016a 破解文档及安装说明&lt;br&gt;链接: &lt;a href=&quot;http://pan.baidu.com/s/1kUyozNx&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pan.baidu.com/s/1kUyozNx&lt;/a&gt; 密码: fygw&lt;/p&gt;
&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;h2 id=&quot;加载镜像&quot;&gt;&lt;a href=&quot;#加载镜像&quot; class=&quot;headerlink&quot; title=&quot;加载镜像&quot;&gt;&lt;/a&gt;加载镜像&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装-1&quot;&gt;&lt;a href=&quot;#安装-1&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;选择安装方法&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-2.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入安装说明中的密钥。 在破解文档readme.txt中。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-3.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择安装位置&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-4.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择组件。 第一个是分布式计算，用不到的朋友建议取消勾选，其余用不到的工具箱也建议不要安装，这样可以减少安装目录的大小，加快安装速度和运行时速度。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-5.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;勾选 将快捷方式添加到桌面选项，否则桌面上将不会出现matlab 2016a的启动快捷方式，还要的手动到安装目录下 /bin文件下寻找。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-6.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;安装完成&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;破解&quot;&gt;&lt;a href=&quot;#破解&quot; class=&quot;headerlink&quot; title=&quot;破解&quot;&gt;&lt;/a&gt;破解&lt;/h2&gt;&lt;p&gt;破解方式如同matlab之前的版本那样，这里我们简要的介绍一下。&lt;br&gt;运行MATLAB R2016a，进行授权lic注册&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-8.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-9.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;授权在破解文件夹内，根据自己安装时候选择的安装模式进行lic注册。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-10.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;激活完成，值得注意的是:现在破解还没有完成，现在运行会出错。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-11.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;替换原文件&lt;/strong&gt; 将破解文件夹中的Matlab_2016a win64_Crack\R2016a下的两个文件夹 bin 和 toolbox复制到matlab的文件路径下.&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-12.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;恭喜，此时，安装和激活全部完成，现在可以运行！&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/matlab-2016a-13.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;下载kinect支持包&quot;&gt;&lt;a href=&quot;#下载kinect支持包&quot; class=&quot;headerlink&quot; title=&quot;下载kinect支持包&quot;&gt;&lt;/a&gt;下载kinect支持包&lt;/h1&gt;&lt;p&gt;首先输入下面的这行命令&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;source.vid = videoinput(&lt;span class=&quot;string&quot;&gt;&#39;kinect&#39;&lt;/span&gt;,1); &lt;span class=&quot;comment&quot;&gt;#设置视频的输入方式和相应的格式&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在没有安装kinect 支持包的时候，会报下面的错误&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/kinect-v2-1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;用鼠标单击图中所示，会打开一个安装扩展支持包的界面&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/kinect-v2-2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;把图中标红的两项都要安装，其中一个是kinect v2 的支持包，一个是系统通用视频接口的支持包(支持笔记本摄像头)。值得注意的是：安装过程中需要去mathworks 官网注册一个帐号。&lt;/p&gt;
&lt;h1 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h1&gt;&lt;p&gt;查看安装信息，输入下面的指令。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;imaqhwinfo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果显示下面的信息，说明安装完成。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/kinect-v2-3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;还可以通过matlab 提供的工具箱进行测试。在菜单栏 “应用程序” 》 “Image Acquisition” 选项中双击打开。&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/kinect-v2-4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以在侧边栏看到 硬件信息，选择其中一项如Depth_512*424 ,点击中部的预览 ，看见上面的预览窗口显示深度画面即表示matlab 连接 kinect v2 成功！！！&lt;br&gt;&lt;img src=&quot;/images/matlab-2016a/kinect-v2-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者:&lt;a href=&quot;https://github.com/mindcont&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mindcont&lt;/a&gt;  2016-05-18 第一次编辑&lt;br&gt;&lt;strong&gt;转载注明出处 &lt;a href=&quot;http://blog.mindcont.com/2016/05/18/Microsoft-Kinect-V2-with-Matlab/&quot;&gt;http://blog.mindcont.com/2016/05/18/Microsoft-Kinect-V2-with-Matlab/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;如何让matlab支持Kinect呢？通过搜索在&lt;a href=&quot;http://cn.mathworks.com/hardware-support/kinect-windows.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mathworks 中
    
    </summary>
    
      <category term="Kinect" scheme="http://blog.mindcont.com/categories/Kinect/"/>
    
    
      <category term="matlab" scheme="http://blog.mindcont.com/tags/matlab/"/>
    
  </entry>
  
  <entry>
    <title>计算机视觉开源项目</title>
    <link href="http://blog.mindcont.com/2016/05/13/Open-Source-Computer-Vision/"/>
    <id>http://blog.mindcont.com/2016/05/13/Open-Source-Computer-Vision/</id>
    <published>2016-05-13T05:40:08.000Z</published>
    <updated>2016-08-22T08:11:40.172Z</updated>
    
    <content type="html">&lt;p&gt;笔者日前在搜索计算机视觉方面的代码,偶然发现这个,不敢独享,随整理发表于此,希望可以帮助到有关学习计算机视觉的朋友们!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/NASA_Mars_Rover.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;特征提取Feature-Extraction&quot;&gt;&lt;a href=&quot;#特征提取Feature-Extraction&quot; class=&quot;headerlink&quot; title=&quot;特征提取Feature Extraction&quot;&gt;&lt;/a&gt;特征提取Feature Extraction&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SIFT&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Demo program]&lt;a href=&quot;http://www.cs.ubc.ca/~lowe/keypoints/siftDemoV4.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.ubc.ca/~lowe/keypoints/siftDemoV4.zip&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[SIFT Library ] &lt;a href=&quot;http://blogs.oregonstate.edu/hess/code/sift/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blogs.oregonstate.edu/hess/code/sift/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[VLFeat] &lt;a href=&quot;http://www.vlfeat.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vlfeat.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;PCA-SIFT&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.cmu.edu/~yke/pcasift/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.cmu.edu/~yke/pcasift/&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Affine-SIFT&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ipol.im/pub/algo/my_affine_sift/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ipol.im/pub/algo/my_affine_sift/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SURF&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[OpenSURF]&lt;a href=&quot;http://www.chrisevansdev.com/computer-vision-opensurf.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.chrisevansdev.com/computer-vision-opensurf.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab Wrapper]&lt;a href=&quot;http://www.maths.lth.se/matematiklth/personal/petter/surfmex.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.maths.lth.se/matematiklth/personal/petter/surfmex.php&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Affine Covariant Features&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Oxford project]&lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/research/affine/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/research/affine/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;MSER&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Oxford project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/research/affine/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/research/affine/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[VLFeat]&lt;a href=&quot;http://www.vlfeat.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vlfeat.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Geometric Blur&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code]&lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/MKL/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/MKL/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Local Self-Similarity Descriptor&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Oxford implementation]&lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/SelfSimilarity/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/SelfSimilarity/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Global and Efficient Self-Similarity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.vision.ee.ethz.ch/~calvin/gss/selfsim_release1.0.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.ee.ethz.ch/~calvin/gss/selfsim_release1.0.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Histogram of Oriented Graidents&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[INRIA Object Localization Toolkit] &lt;a href=&quot;http://www.navneetdalal.com/software&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.navneetdalal.com/software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[OLT toolkit for Windows] &lt;a href=&quot;http://www.computing.edu.au/~12482661/hog.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.computing.edu.au/~12482661/hog.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;GIST &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project]&lt;a href=&quot;http://people.csail.mit.edu/torralba/code/spatialenvelope/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/torralba/code/spatialenvelope/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Shape Context &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/sc_digits.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/sc_digits.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Color Descriptor &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://koen.me/research/colordescriptors/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://koen.me/research/colordescriptors/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Pyramids of Histograms of Oriented Gradients &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/research/caltech/phog/phog.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/research/caltech/phog/phog.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Space-Time Interest Points (STIP)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.nada.kth.se/cvap/abstracts/cvap284.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.nada.kth.se/cvap/abstracts/cvap284.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code]&lt;a href=&quot;http://www.irisa.fr/vista/Equipe/People/Laptev/download/stip-1.1-winlinux.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.irisa.fr/vista/Equipe/People/Laptev/download/stip-1.1-winlinux.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Boundary Preserving Dense Local Regions &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.cs.utexas.edu/projects/bplr/bplr.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.cs.utexas.edu/projects/bplr/bplr.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Weighted Histogram&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/whistc.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/whistc.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Histogram-based Interest Points Detectors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.cs.nthu.edu.tw/~htchen/hipd_cvpr09.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.nthu.edu.tw/~htchen/hipd_cvpr09.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://740-2.cs.nthu.edu.tw/~htchen/hipd/hist_corner.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://740-2.cs.nthu.edu.tw/~htchen/hipd/hist_corner.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;An OpenCV - C++ implementation of Local Self Similarity Descriptors &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://intuitionlogic.com/post/2011/04/11/A-OpenCV-C++-implementation-of-Local-Self-Similarity-Descriptors.aspx&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://intuitionlogic.com/post/2011/04/11/A-OpenCV-C++-implementation-of-Local-Self-Similarity-Descriptors.aspx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Fast Sparse Representation with Prototypes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/cvpr10_fsr.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/cvpr10_fsr.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Corner Detection &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://kiwi.cs.dal.ca/~dparks/CornerDetection/index.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://kiwi.cs.dal.ca/~dparks/CornerDetection/index.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;AGAST Corner Detector: faster than FAST and even FAST-ER&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www6.in.tum.de/Main/ResearchAgast&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www6.in.tum.de/Main/ResearchAgast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Real-time Facial Feature Detection using Conditional Regression Forests&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/facialfeatures/facialfeatures.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/facialfeatures/facialfeatures.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Global and Efficient Self-Similarity for Object Classification and Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/gss/selfsim_release1.0.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/gss/selfsim_release1.0.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;WαSH: Weighted α-Shapes for Local Feature Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://image.ntua.gr/iva/research/wash/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://image.ntua.gr/iva/research/wash/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;HOG&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://soc.fudan.edu.cn/vip/projects/gradproj/wiki/HOG%E4%BB%A3%E7%A0%81&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://soc.fudan.edu.cn/vip/projects/gradproj/wiki/HOG%E4%BB%A3%E7%A0%81&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Online Selection of Discriminative Tracking Features&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.ucla.edu/~roozbehm/cs7495/report.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.ucla.edu/~roozbehm/cs7495/report.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像分割Image-Segmentation&quot;&gt;&lt;a href=&quot;#图像分割Image-Segmentation&quot; class=&quot;headerlink&quot; title=&quot;图像分割Image Segmentation&quot;&gt;&lt;/a&gt;图像分割Image Segmentation&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Normalized Cut &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code]&lt;a href=&quot;http://www.cis.upenn.edu/~jshi/software/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cis.upenn.edu/~jshi/software/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Gerg Mori’ Superpixel code&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code]&lt;a href=&quot;http://www.cs.sfu.ca/~mori/research/superpixels/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.sfu.ca/~mori/research/superpixels/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Efficient Graph-based Image Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[C++ code] &lt;a href=&quot;http://people.cs.uchicago.edu/~pff/segment/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.cs.uchicago.edu/~pff/segment/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab wrapper]&lt;a href=&quot;http://www.mathworks.com/matlabcentral/fileexchange/25866-efficient-graph-based-image-segmentation&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mathworks.com/matlabcentral/fileexchange/25866-efficient-graph-based-image-segmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Mean-Shift Image Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[EDISON C++ code] &lt;a href=&quot;http://coewww.rutgers.edu/riul/research/code/EDISON/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://coewww.rutgers.edu/riul/research/code/EDISON/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab wrapper]&lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/edison_matlab_interface.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/edison_matlab_interface.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;OWT-UCM Hierarchical Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Resources]&lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Turbepixels&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code 32bit] &lt;a href=&quot;http://www.cs.toronto.edu/~babalex/turbopixels_code.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~babalex/turbopixels_code.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab code 64bit] &lt;a href=&quot;http://www.cs.toronto.edu/~babalex/TurboPixels64.rar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~babalex/TurboPixels64.rar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Updated code] &lt;a href=&quot;http://www.cs.toronto.edu/~babalex/superpixels_update.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~babalex/superpixels_update.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Quick-Shift&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[VLFeat] &lt;a href=&quot;http://www.vlfeat.org/overview/quickshift.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vlfeat.org/overview/quickshift.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SLIC Superpixels&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ivrgwww.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ivrgwww.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Segmentation by Minimum Code Length&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://perception.csl.uiuc.edu/coding/image_segmentation/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://perception.csl.uiuc.edu/coding/image_segmentation/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Biased Normalized Cut&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.berkeley.edu/~smaji/projects/biasedNcuts/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.berkeley.edu/~smaji/projects/biasedNcuts/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Segmentation Tree&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.ai.uiuc.edu/segmentation&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.ai.uiuc.edu/segmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Entropy Rate Superpixel Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.umiacs.umd.edu/~mingyliu/src/ers_matlab_wrapper_v0.1.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.umiacs.umd.edu/~mingyliu/src/ers_matlab_wrapper_v0.1.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Fast Approximate Energy Minimization via Graph Cuts&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.csd.uwo.ca/faculty/olga/Papers/pami01_final.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.csd.uwo.ca/faculty/olga/Papers/pami01_final.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.csd.uwo.ca/code/gco-v3.0.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.csd.uwo.ca/code/gco-v3.0.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Efﬁcient Planar Graph Cuts with Applications in Computer Vision&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.csd.uwo.ca/~schmidtf/pdf/schmidt_et_al_cvpr09.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.csd.uwo.ca/~schmidtf/pdf/schmidt_et_al_cvpr09.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.csd.uwo.ca/code/PlanarCut-v1.0.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.csd.uwo.ca/code/PlanarCut-v1.0.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Isoperimetric Graph Partitioning for Image Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.cns.bu.edu/~lgrady/grady2006isoperimetric.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cns.bu.edu/~lgrady/grady2006isoperimetric.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cns.bu.edu/~lgrady/grady2006isoperimetric_code.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cns.bu.edu/~lgrady/grady2006isoperimetric_code.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Random Walks for Image Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.cns.bu.edu/~lgrady/grady2006random.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cns.bu.edu/~lgrady/grady2006random.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cns.bu.edu/~lgrady/random_walker_matlab_code.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cns.bu.edu/~lgrady/random_walker_matlab_code.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Blossom V: A new implementation of a minimum cost perfect matching algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://pub.ist.ac.at/~vnk/software/blossom5-v2.03.src.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pub.ist.ac.at/~vnk/software/blossom5-v2.03.src.tar.gz&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Computer Vision&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.csd.uwo.ca/~yuri/Papers/pami04.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.csd.uwo.ca/~yuri/Papers/pami04.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://pub.ist.ac.at/~vnk/software/maxflow-v3.01.src.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pub.ist.ac.at/~vnk/software/maxflow-v3.01.src.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Geodesic Star Convexity for Interactive Image Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/iseg/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/iseg/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Contour Detection and Image Segmentation Resources&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_source.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_source.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Biased Normalized Cuts&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/biasedNcuts/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/biasedNcuts/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Max-flow/min-cut&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.csd.uwo.ca/code/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.csd.uwo.ca/code/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Chan-Vese Segmentation using Level Set&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ipol.im/pub/art/2012/g-cv/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ipol.im/pub/art/2012/g-cv/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Toolbox of Level Set Methods&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.ubc.ca/~mitchell/ToolboxLS/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.ubc.ca/~mitchell/ToolboxLS/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Re-initialization Free Level Set Evolution via Reaction Diffusion&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cslzhang/RD/RD.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cslzhang/RD/RD.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Improved C-V active contour model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.rar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICV.rar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Variational Multiphase Level Set Approach to Simultaneous Segmentation and Bias Correction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICIP10_SVMLS.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/ICIP10_SVMLS.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/SVMLS_v0.rar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cskhzhang/J_papers/SVMLS_v0.rar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Level Set Method Research by Chunming Li&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.engr.uconn.edu/~cmli/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.engr.uconn.edu/~cmli/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;ClassCut for Unsupervised Class Segmentation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/classcut/ClassCut-release_v1.0.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/classcut/ClassCut-release_v1.0.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SEEDS: Superpixels Extracted via Energy-Driven Sampling &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.ee.ethz.ch/~vamichae/seeds/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.ee.ethz.ch/~vamichae/seeds/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[other] &lt;a href=&quot;http://www.mvdblive.org/seeds/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mvdblive.org/seeds/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;目标检测Object-Detection&quot;&gt;&lt;a href=&quot;#目标检测Object-Detection&quot; class=&quot;headerlink&quot; title=&quot;目标检测Object Detection&quot;&gt;&lt;/a&gt;目标检测Object Detection&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A simple object detector with boosting &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/torralba/shortCourseRLOC/boosting/boosting.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;INRIA Object Detection and Localization Toolkit&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://pascal.inrialpes.fr/soft/olt/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pascal.inrialpes.fr/soft/olt/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Discriminatively Trained Deformable Part Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.eecs.berkeley.edu/~rbg/latent/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.eecs.berkeley.edu/~rbg/latent/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Cascade Object Detection with Deformable Part Models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.cs.uchicago.edu/~rbg/star-cascade/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.cs.uchicago.edu/~rbg/star-cascade/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Poselet&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/~lbourdev/poselets/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/~lbourdev/poselets/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Implicit Shape Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.ee.ethz.ch/~bleibe/code/ism.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.ee.ethz.ch/~bleibe/code/ism.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Bayesian Modelling of Dyanmic Scenes for Object Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://vision.eecs.ucf.edu/papers/01512057.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/papers/01512057.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.eecs.ucf.edu/Code/Background.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/Code/Background.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Hand detection using multiple proposals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/hands/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/hands/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Color Constancy, Intrinsic Images, and Shape Estimation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/BarronMalikECCV2012.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/BarronMalikECCV2012.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cs.berkeley.edu/~barron/BarronMalikECCV2012_code.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.berkeley.edu/~barron/BarronMalikECCV2012_code.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Discriminatively trained deformable part models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.cs.uchicago.edu/~rbg/latent/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.cs.uchicago.edu/~rbg/latent/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Gradient Response Maps for Real-Time Detection of Texture-Less Objects: LineMOD &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://campar.cs.tum.edu/Main/StefanHinterstoisser&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://campar.cs.tum.edu/Main/StefanHinterstoisser&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Image Processing On Line&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ipol.im/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ipol.im/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Robust Optical Flow Estimation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ipol.im/pub/pre/21/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ipol.im/pub/pre/21/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Where’s Waldo: Matching People in Images of Crowds&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://homes.cs.washington.edu/~rahul/data/WheresWaldo.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://homes.cs.washington.edu/~rahul/data/WheresWaldo.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Scalable Multi-class Object Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/houghMC/houghMC.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/houghMC/houghMC.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Class-Specific Hough Forests for Object Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/houghforest/houghforest.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/houghforest/houghforest.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Deformed Lattice Detection In Real-World Images&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.cse.psu.edu/data/data.shtml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.cse.psu.edu/data/data.shtml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Discriminatively trained deformable part models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.cs.uchicago.edu/~rbg/latent/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.cs.uchicago.edu/~rbg/latent/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;显著性检测Saliency-Detection&quot;&gt;&lt;a href=&quot;#显著性检测Saliency-Detection&quot; class=&quot;headerlink&quot; title=&quot;显著性检测Saliency Detection&quot;&gt;&lt;/a&gt;显著性检测Saliency Detection&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Itti, Koch, and Niebur’ saliency detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.saliencytoolbox.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.saliencytoolbox.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Frequency-tuned salient region detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ivrgwww.epfl.ch/supplementary_material/RK_CVPR09/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ivrgwww.epfl.ch/supplementary_material/RK_CVPR09/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Saliency detection using maximum symmetric surround&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ivrg.epfl.ch/supplementary_material/RK_ICIP2010/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ivrg.epfl.ch/supplementary_material/RK_ICIP2010/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Attention via Information Maximization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.cse.yorku.ca/~neil/AIM.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cse.yorku.ca/~neil/AIM.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Context-aware saliency detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://webee.technion.ac.il/labs/cgm/Computer-Graphics-Multimedia/Software/Saliency/Saliency.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://webee.technion.ac.il/labs/cgm/Computer-Graphics-Multimedia/Software/Saliency/Saliency.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Graph-based visual saliency&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.klab.caltech.edu/~harel/share/gbvs.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.klab.caltech.edu/~harel/share/gbvs.php&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Saliency detection: A spectral residual approach.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.klab.caltech.edu/~xhou/projects/spectralResidual/spectralresidual.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.klab.caltech.edu/~xhou/projects/spectralResidual/spectralresidual.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Segmenting salient objects from images and videos.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.cse.oulu.fi/MVG/Downloads/saliency&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cse.oulu.fi/MVG/Downloads/saliency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Saliency Using Natural statistics.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://cseweb.ucsd.edu/~l6zhang/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://cseweb.ucsd.edu/~l6zhang/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Discriminant Saliency for Visual Recognition from Cluttered Scenes.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.svcl.ucsd.edu/projects/saliency/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.svcl.ucsd.edu/projects/saliency/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning to Predict Where Humans Look&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Global Contrast based Salient Region Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Bayesian Saliency via Low and Mid Level Cues&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ice.dlut.edu.cn/lu/Project/TIP_scm/TIP_scm.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ice.dlut.edu.cn/lu/Project/TIP_scm/TIP_scm.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Top-Down Visual Saliency via Joint CRF and Dictionary Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/cvpr12a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/cvpr12a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/top-down-saliency.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/top-down-saliency.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Saliency Detection: A Spectral Residual Approach&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.klab.caltech.edu/~xhou/projects/dva/dva.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.klab.caltech.edu/~xhou/projects/dva/dva.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像分类、聚类Image-Classification-Clustering&quot;&gt;&lt;a href=&quot;#图像分类、聚类Image-Classification-Clustering&quot; class=&quot;headerlink&quot; title=&quot;图像分类、聚类Image Classification, Clustering&quot;&gt;&lt;/a&gt;图像分类、聚类Image Classification, Clustering&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Pyramid Match&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/jjl/libpmk/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/jjl/libpmk/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Spatial Pyramid Matching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cs.unc.edu/~lazebnik/research/SpatialPyramid.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.unc.edu/~lazebnik/research/SpatialPyramid.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Locality-constrained Linear Coding&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ifp.illinois.edu/~jyang29/LLC.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ifp.illinois.edu/~jyang29/LLC.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.ifp.illinois.edu/~jyang29/codes/CVPR10-LLC.rar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ifp.illinois.edu/~jyang29/codes/CVPR10-LLC.rar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Sparse Coding&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ifp.illinois.edu/~jyang29/ScSPM.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ifp.illinois.edu/~jyang29/ScSPM.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.ifp.illinois.edu/~jyang29/codes/CVPR09-ScSPM.rar&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ifp.illinois.edu/~jyang29/codes/CVPR09-ScSPM.rar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Texture Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/research/texclass/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/research/texclass/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Multiple Kernels for Image Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/MKL/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/MKL/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Feature Combination&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.ee.ethz.ch/~pgehler/projects/iccv09/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.ee.ethz.ch/~pgehler/projects/iccv09/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SuperParsing &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cs.unc.edu/~jtighe/Papers/ECCV10/eccv10-jtighe-code.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.unc.edu/~jtighe/Papers/ECCV10/eccv10-jtighe-code.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Large Scale Correlation Clustering Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab code] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/LargeScaleCC1.0.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/LargeScaleCC1.0.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Detecting and Sketching the Common&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~vision/SketchTheCommon&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~vision/SketchTheCommon&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Self-Tuning Spectral Clustering&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.caltech.edu/lihi/Demos/SelfTuningClustering.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.caltech.edu/lihi/Demos/SelfTuningClustering.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.vision.caltech.edu/lihi/Demos/SelfTuning/ZPclustering.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.caltech.edu/lihi/Demos/SelfTuning/ZPclustering.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;User Assisted Separation of Reflections from a Single Image Using a Sparsity Prior&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~levina/papers/assisted-eccv04.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~levina/papers/assisted-eccv04.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~levina/papers/reflections.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~levina/papers/reflections.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Filters for Texture Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html#download&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html#download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Multiple Kernel Learning for Image Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/MKL/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/MKL/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SLIC Superpixels&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;抠图Image-Matting&quot;&gt;&lt;a href=&quot;#抠图Image-Matting&quot; class=&quot;headerlink&quot; title=&quot;抠图Image Matting&quot;&gt;&lt;/a&gt;抠图Image Matting&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Closed Form Solution to Natural Image Matting&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://people.csail.mit.edu/alevin/matting.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/alevin/matting.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Spectral Matting &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.huji.ac.il/SpectralMatting/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.huji.ac.il/SpectralMatting/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning-based Matting &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.mathworks.com/matlabcentral/fileexchange/31412&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mathworks.com/matlabcentral/fileexchange/31412&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;目标跟踪Object-Tracking&quot;&gt;&lt;a href=&quot;#目标跟踪Object-Tracking&quot; class=&quot;headerlink&quot; title=&quot;目标跟踪Object Tracking&quot;&gt;&lt;/a&gt;目标跟踪Object Tracking&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Forest of Sensors - Tracking Adaptive Background Mixture Models &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ai.mit.edu/projects/vsam/Tracking/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ai.mit.edu/projects/vsam/Tracking/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Object Tracking via Partial Least Squares Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/tip12_pls_tracking.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/tip12_pls_tracking.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/PLS_tracker_tip.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/PLS_tracker_tip.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Robust Object Tracking with Online Multiple Instance Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/pami11b.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/pami11b.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Online Visual Tracking with Histograms and Articulating Blocks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cise.ufl.edu/~smshahed/tracking.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cise.ufl.edu/~smshahed/tracking.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Incremental Learning for Robust Visual Tracking&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Real-time Compressive Tracking&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www4.comp.polyu.edu.hk/~cslzhang/CT/CT.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www4.comp.polyu.edu.hk/~cslzhang/CT/CT.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Robust Object Tracking via Sparsity-based Collaborative Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/project/cvpr12_scm.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/project/cvpr12_scm.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Visual Tracking via Adaptive Structural Local Sparse Appearance Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/project/cvpr12_jia_project.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/project/cvpr12_jia_project.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Online Discriminative Object Tracking with Local Sparse Representation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/wacv12a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/wacv12a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/wacv12a_code.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/wacv12a_code.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Superpixel Tracking&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/iccv11a.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/iccv11a.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning Hierarchical Image Representation with Sparsity, Saliency and Locality&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/bmvc11a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/bmvc11a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/BMVC11-HSSL-package.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/BMVC11-HSSL-package.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Online Multiple Support Instance Tracking &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/fg11a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/fg11a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/fg11_omsit.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/fg11_omsit.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Visual Tracking with Online Multiple Instance Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Object detection and recognition&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://c2inet.sce.ntu.edu.sg/Jianxin/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://c2inet.sce.ntu.edu.sg/Jianxin/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Compressive Sensing Resources&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://dsp.rice.edu/cs&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dsp.rice.edu/cs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Robust Real-Time Visual Tracking using Pixel-Wise Posteriors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~cbibby/index.shtml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~cbibby/index.shtml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Tracking-Learning-Detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://info.ee.surrey.ac.uk/Personal/Z.Kalal/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://info.ee.surrey.ac.uk/Personal/Z.Kalal/&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;[OpenTLD/C++ Code] &lt;a href=&quot;https://github.com/arthurv/OpenTLD&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/arthurv/OpenTLD&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;the HandVu：vision-based hand gesture interface&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ilab.cs.ucsb.edu/index.php/component/content/article/12/29&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ilab.cs.ucsb.edu/index.php/component/content/article/12/29&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/stochGPLVM/stochGPLVM.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/stochGPLVM/stochGPLVM.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Kinect&quot;&gt;&lt;a href=&quot;#Kinect&quot; class=&quot;headerlink&quot; title=&quot;Kinect&quot;&gt;&lt;/a&gt;Kinect&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Kinect toolbox&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://kinecttoolbox.codeplex.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://kinecttoolbox.codeplex.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;OpenNI&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.openni.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.openni.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;zouxy09 CSDN Blog&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Resource] &lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8145688&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/zouxy09/article/details/8145688&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;FingerTracker 手指跟踪&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://makematics.com/code/FingerTracker/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://makematics.com/code/FingerTracker/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;3D相关&quot;&gt;&lt;a href=&quot;#3D相关&quot; class=&quot;headerlink&quot; title=&quot;3D相关&quot;&gt;&lt;/a&gt;3D相关&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;3D Reconstruction of a Moving Object&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~ronen/papers/Simakov&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~ronen/papers/Simakov&lt;/a&gt; Frolova Basri - Dense Shape Reconstruction Under Arbitrary Unknown Lighting.pdf&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/SFB_matlab1.0.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/SFB_matlab1.0.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Shape From Shading Using Linear Approximation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.eecs.ucf.edu/shadsrc.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/shadsrc.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Combining Shape from Shading and Stereo Depth Maps&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.eecs.ucf.edu/combsrc.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/combsrc.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.eecs.ucf.edu/projects/ShapeFromShading/combine.tar.Z&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/projects/ShapeFromShading/combine.tar.Z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Shape from Shading: A Survey&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://vision.eecs.ucf.edu/papers/shah/99/ZTCS99.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/papers/shah/99/ZTCS99.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://vision.eecs.ucf.edu/projects/ShapeFromShading/SFS_Survey_1_00.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.eecs.ucf.edu/projects/ShapeFromShading/SFS_Survey_1_00.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Spatio-Temporal Descriptor based on 3D Gradients (HOG3D)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://lear.inrialpes.fr/people/klaeser/research_hog3d&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/klaeser/research_hog3d&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://lear.inrialpes.fr/people/klaeser/software_3d_video_descriptor&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/klaeser/software_3d_video_descriptor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Multi-camera Scene Reconstruction via Graph Cuts&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.cs.cornell.edu/~rdz/papers/kz-eccv02-recon.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.cornell.edu/~rdz/papers/kz-eccv02-recon.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://pub.ist.ac.at/~vnk/software/match-v3.4.src.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://pub.ist.ac.at/~vnk/software/match-v3.4.src.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Fast Marching Formulation of Perspective Shape from Shading under Frontal Illumination&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.cs.ucf.edu/~vision&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.ucf.edu/~vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.ee.cityu.edu.hk/~syyuen/Public/SfS/PRL_Perspective_FMM.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ee.cityu.edu.hk/~syyuen/Public/SfS/PRL_Perspective_FMM.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Reconstruction:3D Shape, Illumination, Shading, Reflectance, Texture&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/reconstruction/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Monocular Tracking of 3D Human Motion with a Coordinated Mixture of Factor Analyzers&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/PackagedTrackingCode.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/PackagedTrackingCode.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning 3-D Scene Structure from a Single Still Image&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ai.stanford.edu/~asaxena/reconstruction3d/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ai.stanford.edu/~asaxena/reconstruction3d/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;机器学习算法&quot;&gt;&lt;a href=&quot;#机器学习算法&quot; class=&quot;headerlink&quot; title=&quot;机器学习算法&quot;&gt;&lt;/a&gt;机器学习算法&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Matlab class for computing Approximate Nearest Nieghbor (ANN) &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab class providing interface toANN library] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/ann_wrapper_Mar2012.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/ann_wrapper_Mar2012.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Random Sampling&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/weight_sample.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.wisdom.weizmann.ac.il/~bagon/matlab_code/weight_sample.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Probabilistic Latent Semantic Analysis (pLSA)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/pLSA/pLSA_demo.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/pLSA/pLSA_demo.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;FASTANN and FASTCLUSTER for approximate k-means (AKM)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/fastann/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/fastann/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Fast Intersection / Additive Kernel SVMs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.berkeley.edu/~smaji/projects/fiksvm/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.berkeley.edu/~smaji/projects/fiksvm/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SVM&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://osmot.cs.cornell.edu/svm_light/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://osmot.cs.cornell.edu/svm_light/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Ensemble learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://c2inet.sce.ntu.edu.sg/Jianxin/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://c2inet.sce.ntu.edu.sg/Jianxin/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Deep Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Net] &lt;a href=&quot;http://deeplearning.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://deeplearning.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Deep Learning Methods for Vision&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Neural Network for Recognition of Handwritten Digits&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.codeproject.com/KB/library/NeuralNetRecognition.aspx&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.codeproject.com/KB/library/NeuralNetRecognition.aspx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Training a deep autoencoder or a classifier on MNIST digits&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;THE MNIST DATABASE of handwritten digits&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://yann.lecun.com/exdb/mnist/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Ersatz：deep neural networks in the cloud&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ersatz1.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ersatz1.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Deep Learning &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.nyu.edu/~yann/research/deep/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.nyu.edu/~yann/research/deep/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;sparseLM : Sparse Levenberg-Marquardt nonlinear least squares in C/C++&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ics.forth.gr/~lourakis/sparseLM/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ics.forth.gr/~lourakis/sparseLM/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Weka 3: Data Mining Software in Java&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.waikato.ac.nz/ml/weka/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.waikato.ac.nz/ml/weka/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Invited talk “A Tutorial on Deep Learning” by Dr. Kai Yu (余凯)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Video] &lt;a href=&quot;http://vipl.ict.ac.cn/News/academic-report-tutorial-deep-learning-dr-kai-yu&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vipl.ict.ac.cn/News/academic-report-tutorial-deep-learning-dr-kai-yu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;CNN - Convolutional neural network class&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Matlab Tool] &lt;a href=&quot;http://www.mathworks.cn/matlabcentral/fileexchange/24291&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mathworks.cn/matlabcentral/fileexchange/24291&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Yann LeCun’s Publications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Wedsite] &lt;a href=&quot;http://yann.lecun.com/exdb/publis/index.html#lecun-98&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://yann.lecun.com/exdb/publis/index.html#lecun-98&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;LeNet-5, convolutional neural networks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://yann.lecun.com/exdb/lenet/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://yann.lecun.com/exdb/lenet/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Training a deep autoencoder or a classifier on MNIST digits&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Deep Learning 大牛Geoffrey E. Hinton’s HomePage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Website] &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.toronto.edu/~hinton/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Multiple Instance Logistic Discriminant-based Metric Learning (MildML) and Logistic Discriminant-based Metric Learning (LDML)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://lear.inrialpes.fr/people/guillaumin/code.php#mildml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/guillaumin/code.php#mildml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Sparse coding simulation software&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://redwood.berkeley.edu/bruno/sparsenet/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://redwood.berkeley.edu/bruno/sparsenet/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Visual Recognition and Machine Learning Summer School&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Software] &lt;a href=&quot;http://lear.inrialpes.fr/software&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/software&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;目标、行为识别Object-Action-Recognition&quot;&gt;&lt;a href=&quot;#目标、行为识别Object-Action-Recognition&quot; class=&quot;headerlink&quot; title=&quot;目标、行为识别Object, Action Recognition&quot;&gt;&lt;/a&gt;目标、行为识别Object, Action Recognition&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Action Recognition by Dense Trajectories&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://lear.inrialpes.fr/people/wang/dense_trajectories&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/wang/dense_trajectories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://lear.inrialpes.fr/people/wang/download/dense_trajectory_release.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/wang/download/dense_trajectory_release.tar.gz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Action Recognition Using a Distributed Representation of Pose and Appearance&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/action/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/action/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Recognition Using Regions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam-cvpr09.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam-cvpr09.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam_cvpr09_v2.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/glam_cvpr09_v2.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;2D Articulated Human Pose Estimation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vision.ee.ethz.ch/~calvin/articulated_human_pose_estimation_code/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vision.ee.ethz.ch/~calvin/articulated_human_pose_estimation_code/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Fast Human Pose Estimation Using Appearance and Motion via Multi-Dimensional Boosting Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/cvpr07a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/cvpr07a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://www.cise.ufl.edu/~smshahed/cvpr07_fast_human_pose.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cise.ufl.edu/~smshahed/cvpr07_fast_human_pose.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Estimating Human Pose from Occluded Images&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/papers/accv09a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/papers/accv09a.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://faculty.ucmerced.edu/mhyang/code/accv09_pose.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://faculty.ucmerced.edu/mhyang/code/accv09_pose.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Quasi-dense wide baseline matching&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ee.oulu.fi/~jkannala/quasidense/quasidense.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ee.oulu.fi/~jkannala/quasidense/quasidense.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;ChaLearn Gesture Challenge: Principal motion: PCA-based reconstruction of motion histograms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://gesture.chalearn.org/data/sample-code&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://gesture.chalearn.org/data/sample-code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Real Time Head Pose Estimation with Random Regression Forests&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/RFhead/RFhead.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/RFhead/RFhead.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;2D Action Recognition Serves 3D Human Pose Estimation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/ARforPose/ARforPose.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/ARforPose/ARforPose.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Hough Transform-Based Voting Framework for Action Recognition&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://files.is.tue.mpg.de/jgall/projects/houghAR/houghAR.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://files.is.tue.mpg.de/jgall/projects/houghAR/houghAR.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Motion Interchange Patterns for Action Recognition in Unconstrained Videos&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.openu.ac.il/home/hassner/projects/MIP/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.openu.ac.il/home/hassner/projects/MIP/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;2D articulated human pose estimation software&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/articulated_human_pose_estimation_code/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/articulated_human_pose_estimation_code/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning and detecting shape models&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/release-learn-shapes-v1.3.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/release-learn-shapes-v1.3.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Progressive Search Space Reduction for Human Pose Estimation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/software/UpperBody/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.robots.ox.ac.uk/~vgg/software/UpperBody/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Learning Non-Rigid 3D Shape from 2D Motion&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://movement.stanford.edu/learning-nr-shape/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://movement.stanford.edu/learning-nr-shape/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像处理&quot;&gt;&lt;a href=&quot;#图像处理&quot; class=&quot;headerlink&quot; title=&quot;图像处理&quot;&gt;&lt;/a&gt;图像处理&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Distance Transforms of Sampled Functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://cs.brown.edu/~pff/dt/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://cs.brown.edu/~pff/dt/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The Computer Vision Homepage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.cmu.edu/~cil/vision.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.cmu.edu/~cil/vision.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Efficient appearance distances between windows&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/efficientAppDistances/releaseEfficientAppDistances.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/efficientAppDistances/releaseEfficientAppDistances.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Image Exploration algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://groups.inf.ed.ac.uk/calvin/ReleasedCode/image_exploration_v1.1.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://groups.inf.ed.ac.uk/calvin/ReleasedCode/image_exploration_v1.1.tgz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Motion Magnification 运动放大 &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/celiu/motionmag/motionmag.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/celiu/motionmag/motionmag.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Bilateral Filtering for Gray and Color Images 双边滤波器 &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Fast Approximation of the Bilateral Filter using a Signal Processing Approach &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/sparis/bf/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/sparis/bf/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;一些实用工具&quot;&gt;&lt;a href=&quot;#一些实用工具&quot; class=&quot;headerlink&quot; title=&quot;一些实用工具&quot;&gt;&lt;/a&gt;一些实用工具&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;EGT: a Toolbox for Multiple View Geometry and Visual Servoing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project]  &lt;a href=&quot;http://egt.dii.unisi.it/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://egt.dii.unisi.it/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://egt.dii.unisi.it/download/EGT_v1p3.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://egt.dii.unisi.it/download/EGT_v1p3.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;a development kit of matlab mex functions for OpenCV library&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.cs.stonybrook.edu/~kyamagu/mexopencv/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cs.stonybrook.edu/~kyamagu/mexopencv/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Fast Artificial Neural Network Library&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://leenissen.dk/fann/wp/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://leenissen.dk/fann/wp/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;人手及指尖检测与识别&quot;&gt;&lt;a href=&quot;#人手及指尖检测与识别&quot; class=&quot;headerlink&quot; title=&quot;人手及指尖检测与识别&quot;&gt;&lt;/a&gt;人手及指尖检测与识别&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;finger-detection-and-gesture-recognition &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://code.google.com/p/finger-detection-and-gesture-recognition/downloads/list&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://code.google.com/p/finger-detection-and-gesture-recognition/downloads/list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Hand and Finger Detection using JavaCV&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.javacodegeeks.com/2012/12/hand-and-finger-detection-using-javacv.html?utm_source=feedburner&amp;amp;utm_medium=feed&amp;amp;utm_campaign=Feed%3A+JavaCodeGeeks+%28Java+Code+Geeks%29&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.javacodegeeks.com/2012/12/hand-and-finger-detection-using-javacv.html?utm_source=feedburner&amp;amp;utm_medium=feed&amp;amp;utm_campaign=Feed%3A+JavaCodeGeeks+%28Java+Code+Geeks%29&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;strong&gt;Hand and fingers detection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Code] &lt;a href=&quot;http://forum.openframeworks.cc/index.php?topic=1916.0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://forum.openframeworks.cc/index.php?topic=1916.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;场景解释&quot;&gt;&lt;a href=&quot;#场景解释&quot; class=&quot;headerlink&quot; title=&quot;场景解释&quot;&gt;&lt;/a&gt;场景解释&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Nonparametric Scene Parsing via Label Transfer &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/celiu/LabelTransfer/code.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/celiu/LabelTransfer/code.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;光流Optical-flow&quot;&gt;&lt;a href=&quot;#光流Optical-flow&quot; class=&quot;headerlink&quot; title=&quot;光流Optical flow&quot;&gt;&lt;/a&gt;光流Optical flow&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;High accuracy optical flow using a theory for warping &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://perception.inrialpes.fr/~chari/myweb/Software/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://perception.inrialpes.fr/~chari/myweb/Software/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Dense Trajectories Video Description &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://lear.inrialpes.fr/people/wang/dense_trajectories&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lear.inrialpes.fr/people/wang/dense_trajectories&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;SIFT Flow: Dense Correspondence across Scenes and its Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/celiu/SIFTflow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/celiu/SIFTflow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;KLT: An Implementation of the Kanade-Lucas-Tomasi Feature Tracker &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ces.clemson.edu/~stb/klt/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ces.clemson.edu/~stb/klt/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Tracking Cars Using Optical Flow&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.mathworks.cn/cn/help/vision/examples/tracking-cars-using-optical-flow.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mathworks.cn/cn/help/vision/examples/tracking-cars-using-optical-flow.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Secrets of optical flow estimation and their principles&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ps.is.tue.mpg.de/person/black#tabs-code&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ps.is.tue.mpg.de/person/black#tabs-code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;implmentation of the Black and Anandan dense optical flow method&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://ps.is.tue.mpg.de/person/black#tabs-code&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ps.is.tue.mpg.de/person/black#tabs-code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Optical Flow Computation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;https://www.ceremade.dauphine.fr/~peyre/numerical-tour/tours/multidim_5_opticalflow/#37&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.ceremade.dauphine.fr/~peyre/numerical-tour/tours/multidim_5_opticalflow/#37&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Beyond Pixels: Exploring New Representations and Applications for Motion Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/celiu/OpticalFlow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/celiu/OpticalFlow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Database and Evaluation Methodology for Optical Flow&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.middlebury.edu/flow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.middlebury.edu/flow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;optical flow relative&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://lmb.informatik.uni-freiburg.de/resources/software.php&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://lmb.informatik.uni-freiburg.de/resources/software.php&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Robust Optical Flow Estimation&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.ipol.im/pub/pre/21/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ipol.im/pub/pre/21/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;optical flow&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.jonathanmugan.com/GraphicsProject/OpticalFlow/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.jonathanmugan.com/GraphicsProject/OpticalFlow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像检索Image-Retrieval&quot;&gt;&lt;a href=&quot;#图像检索Image-Retrieval&quot; class=&quot;headerlink&quot; title=&quot;图像检索Image Retrieval&quot;&gt;&lt;/a&gt;图像检索Image Retrieval&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Semi-Supervised Distance Metric Learning for Collaborative Image Retrieval &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Paper] &lt;a href=&quot;http://www.ee.columbia.edu/~wliu/CVPR08_ssml.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ee.columbia.edu/~wliu/CVPR08_ssml.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[code] &lt;a href=&quot;http://www.ee.columbia.edu/~wliu/SSMetric.zip&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ee.columbia.edu/~wliu/SSMetric.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;马尔科夫随机场Markov-Random-Fields&quot;&gt;&lt;a href=&quot;#马尔科夫随机场Markov-Random-Fields&quot; class=&quot;headerlink&quot; title=&quot;马尔科夫随机场Markov Random Fields&quot;&gt;&lt;/a&gt;马尔科夫随机场Markov Random Fields&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Markov Random Fields for Super-Resolution &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://people.csail.mit.edu/billf/project&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://people.csail.mit.edu/billf/project&lt;/a&gt; pages/sresCode/Markov Random Fields for Super-Resolution.html&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://vision.middlebury.edu/MRF/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://vision.middlebury.edu/MRF/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;运动检测Motion-detection&quot;&gt;&lt;a href=&quot;#运动检测Motion-detection&quot; class=&quot;headerlink&quot; title=&quot;运动检测Motion detection&quot;&gt;&lt;/a&gt;运动检测Motion detection&lt;/h1&gt;&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Moving Object Extraction, Using Models or Analysis of Regions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.visionbib.com/bibliography/motion-i763.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.visionbib.com/bibliography/motion-i763.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Background Subtraction: Experiments and Improvements for ViBe&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www2.ulg.ac.be/telecom/publi/publications/mvd/VanDroogenbroeck2012Background/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www2.ulg.ac.be/telecom/publi/publications/mvd/VanDroogenbroeck2012Background/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;A Self-Organizing Approach to Background Subtraction for Visual Surveillance Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.na.icar.cnr.it/~maddalena.l/MODLab/SoftwareSOBS.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.na.icar.cnr.it/~maddalena.l/MODLab/SoftwareSOBS.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;changedetection.net: A new change detection benchmark dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.changedetection.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.changedetection.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;ViBe - a powerful technique for background detection and subtraction in video sequences&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www2.ulg.ac.be/telecom/research/vibe/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www2.ulg.ac.be/telecom/research/vibe/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Background Subtraction Program&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.umiacs.umd.edu/~knkim/UMD-BGS/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.umiacs.umd.edu/~knkim/UMD-BGS/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Motion Detection Algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.codeproject.com/Articles/10248/Motion-Detection-Algorithms&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.codeproject.com/Articles/10248/Motion-Detection-Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Stuttgart Artificial Background Subtraction Dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.vis.uni-stuttgart.de/index.php?id=sabs&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.vis.uni-stuttgart.de/index.php?id=sabs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i class=&quot;fa fa-folder-o&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;strong&gt;Object Detection, Motion Estimation, and Tracking&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Project] &lt;a href=&quot;http://www.mathworks.cn/cn/help/vision/motion-analysis-and-tracking.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.mathworks.cn/cn/help/vision/motion-analysis-and-tracking.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;来源:网络 编辑:&lt;a href=&quot;https://github.com/mindcont&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mindcont&lt;/a&gt;  2016-05-13 第一次编辑&lt;br&gt;&lt;strong&gt;转载注明出处 &lt;a href=&quot;http://blog.mindcont.com/2016/05/13/Open-Source-Computer-Vision/&quot;&gt;http://blog.mindcont.com/2016/05/13/Open-Source-Computer-Vision/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;笔者日前在搜索计算机视觉方面的代码,偶然发现这个,不敢独享,随整理发表于此,希望可以帮助到有关学习计算机视觉的朋友们!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/NASA_Mars_Rover.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;特征提取Feature
    
    </summary>
    
    
      <category term="OpenCV" scheme="http://blog.mindcont.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>win10连结ubuntu 远程桌面</title>
    <link href="http://blog.mindcont.com/2016/05/12/win10-ubuntu-remote-desktop/"/>
    <id>http://blog.mindcont.com/2016/05/12/win10-ubuntu-remote-desktop/</id>
    <published>2016-05-12T03:02:23.000Z</published>
    <updated>2016-07-25T01:26:44.833Z</updated>
    
    <content type="html">&lt;p&gt;笔者最近需要查看实验室另一台装有ubuntu 14.04 LTS 版本系统的电脑，并进行远程可视化操作。通过搜索有关ubuntu 远程桌面大量信息并亲身实践，现总结如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;实验平台&lt;/th&gt;
&lt;th&gt;操作系统&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;笔记本&lt;/td&gt;
&lt;td&gt;win10(10240)&lt;/td&gt;
&lt;td&gt;IP:192.168.0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;待连结电脑&lt;/td&gt;
&lt;td&gt;ubuntu 14.04 lts&lt;/td&gt;
&lt;td&gt;IP:192.168.0.100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;例如 192.168.0.66 —&amp;gt;192.168.0.100&lt;/td&gt;
&lt;td&gt;需要保证两台电脑IPv4地址中，第3位数字一样&lt;/td&gt;
&lt;td&gt;Windows下打开cmd命令行，ping 你的ubuntu 主机IP地址 有回应,&lt;strong&gt;方可进入下一步&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&quot;ubuntu-配置&quot;&gt;&lt;a href=&quot;#ubuntu-配置&quot; class=&quot;headerlink&quot; title=&quot;ubuntu 配置&quot;&gt;&lt;/a&gt;ubuntu 配置&lt;/h1&gt;&lt;h2 id=&quot;安装xrdp-和相关组件&quot;&gt;&lt;a href=&quot;#安装xrdp-和相关组件&quot; class=&quot;headerlink&quot; title=&quot;安装xrdp 和相关组件&quot;&gt;&lt;/a&gt;安装xrdp 和相关组件&lt;/h2&gt;&lt;p&gt;因为win 系统采用xrdp 协议，所以我们在ubuntu下安装 xrdp 和相关组件。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install xrdp vnc4server xbase-clients&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装dconf-editor&quot;&gt;&lt;a href=&quot;#安装dconf-editor&quot; class=&quot;headerlink&quot; title=&quot;安装dconf-editor&quot;&gt;&lt;/a&gt;安装dconf-editor&lt;/h2&gt;&lt;p&gt;现在我们还不能直接， 因为win下加密验证方式和linux下不同，所以接着我们安装 dconf-editor 用来去除gnome 远程桌面的密码验证。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install dconf-editor&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后 输入 dconf-editor ,以此在 org &amp;gt; gnome &amp;gt; desktop &amp;gt; remote-access&lt;br&gt;&lt;img src=&quot;/images/ubuntu-dconf-editor.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;设置远程桌面选项&quot;&gt;&lt;a href=&quot;#设置远程桌面选项&quot; class=&quot;headerlink&quot; title=&quot;设置远程桌面选项&quot;&gt;&lt;/a&gt;设置远程桌面选项&lt;/h2&gt;&lt;p&gt;打开搜索，输入桌面，点击&lt;strong&gt;桌面共享&lt;/strong&gt;。这里我们要对桌面共享首选项进行设置。&lt;br&gt;&lt;img src=&quot;/images/ubuntu-share-desktop.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;输入远程登录用户的密码并允许查看和控制，&lt;strong&gt;特别注意的是 在”安全”选项下 将每次访问进行确认的对号去掉&lt;/strong&gt;，否则每次远程登录都要在待连接设备ubuntu 这边进行允许确认。&lt;br&gt;&lt;img src=&quot;/images/ubunt-share-desktop-config.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;win10-连接&quot;&gt;&lt;a href=&quot;#win10-连接&quot; class=&quot;headerlink&quot; title=&quot;win10 连接&quot;&gt;&lt;/a&gt;win10 连接&lt;/h1&gt;&lt;h2 id=&quot;打开远程桌面&quot;&gt;&lt;a href=&quot;#打开远程桌面&quot; class=&quot;headerlink&quot; title=&quot;打开远程桌面&quot;&gt;&lt;/a&gt;打开远程桌面&lt;/h2&gt;&lt;p&gt;同时安装 Win + R 键打开命令行输入 mstsc ，打开远程桌面。或通过搜索 “远程桌面” 的方式打开。输入ubuntu在内网下的IP 地址和用户名。如果不清楚，可在ubuntu下输入&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ifconfig &lt;span class=&quot;comment&quot;&gt;# 在ubuntu下输入，可以在ipv4一行中查看其IP地址。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/win-remote-desktop.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;选择为console的方式&quot;&gt;&lt;a href=&quot;#选择为console的方式&quot; class=&quot;headerlink&quot; title=&quot;选择为console的方式&quot;&gt;&lt;/a&gt;选择为console的方式&lt;/h2&gt;&lt;p&gt;按连接后，会打开如下界面。点击下三角，选择为console的方式,输入我们刚才在ubuntu下配置的远程访问密码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/win-mstsc-xrdp-console.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;恭喜，远程桌面连接成功！&lt;br&gt;&lt;img src=&quot;/images/ubuntu-remote-desktop.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;作者:&lt;a href=&quot;https://github.com/mindcont&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;mindcont&lt;/a&gt;  2016-05-12 第一次编辑 2016-07-25 第二次编辑&lt;br&gt;&lt;strong&gt;转载注明出处 &lt;a href=&quot;http://blog.mindcont.com/2016/05/12/win10-ubuntu-remote-desktop/&quot;&gt;http://blog.mindcont.com/2016/05/12/win10-ubuntu-remote-desktop/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;笔者最近需要查看实验室另一台装有ubuntu 14.04 LTS 版本系统的电脑，并进行远程可视化操作。通过搜索有关ubuntu 远程桌面大量信息并亲身实践，现总结如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;实验平台&lt;/th&gt;
&lt;th&gt;操作系统&lt;/th
    
    </summary>
    
      <category term="Linux" scheme="http://blog.mindcont.com/categories/Linux/"/>
    
    
  </entry>
  
</feed>
